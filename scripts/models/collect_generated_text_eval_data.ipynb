{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect generated text for evaluation data\n",
    "We need to collect text generated by the model for the following two evaluation tasks:\n",
    "\n",
    "1. Is reader-aware text (1) more relevant and (2) more likely to elicit interesting information from the author, than non-aware text?\n",
    "2. Is it just as easy to differentiate different reader groups in the generated text as it is for the real text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ianbstew/miniconda3/envs/py3/lib/python3.8/site-packages/nlp/utils/py_utils.py:191: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return function(data_struct)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51302, 8)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "val_data = torch.load('../../data/reddit_data/combined_data_test_data.pt', map_location='cpu')\n",
    "# convert to data frame because easier\n",
    "import pandas as pd\n",
    "val_data = pd.DataFrame(list(val_data))\n",
    "data_cols = ['article_id', 'author_has_subreddit_embed', 'author_has_text_embed', 'reader_token_str', 'source_text', 'target_text', 'subreddit_embed', 'text_embed']\n",
    "val_data = val_data.loc[:, data_cols]\n",
    "print(val_data.shape)\n",
    "# get metadata\n",
    "import pandas as pd\n",
    "post_metadata = pd.read_csv('../../data/reddit_data/combined_data_question_data.gz', sep='\\t', compression='gzip', usecols=['article_id', 'subreddit'])\n",
    "# add subreddit info\n",
    "val_data = pd.merge(val_data, post_metadata, on=['article_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data for no-reader and reader-aware generated questions\n",
    "After generating text with `test_question_generation.py`, we can filter for questions generated by no-reader and reader-aware models (additional condition: question should have some reader information attached)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "no_reader_pred_text = list(map(lambda x: x.strip(), gzip.open('../../data/reddit_data/text_only_model/test_data_output_text.gz', 'rt')))\n",
    "reader_aware_pred_text = list(map(lambda x: x.strip(), gzip.open('../../data/reddit_data/author_text_data/test_data_output_text.gz', 'rt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25495/51302 output that are different across models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>reader_token_str</th>\n",
       "      <th>source_text</th>\n",
       "      <th>text_only_model_pred_text</th>\n",
       "      <th>reader_model_pred_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22989</th>\n",
       "      <td>bc5yeu</td>\n",
       "      <td>&lt;NONUS_AUTHOR&gt;</td>\n",
       "      <td>My sister is 34 and I'm 40, but since our earl...</td>\n",
       "      <td>Why did you even make this post?</td>\n",
       "      <td>Why would you do that to someone you're overre...</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22991</th>\n",
       "      <td>cbjgh5</td>\n",
       "      <td>&lt;RESPONSE_TIME_1_AUTHOR&gt;</td>\n",
       "      <td>Is it considered retaliation on my landlords p...</td>\n",
       "      <td>Do you have a lease or are you month to month?</td>\n",
       "      <td>Whose name is on the lease?</td>\n",
       "      <td>legaladvice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22992</th>\n",
       "      <td>a9wlwo</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>Like, I’m talking, age 30, at least 20 yrs of ...</td>\n",
       "      <td>Do you have an adult in your life that you tru...</td>\n",
       "      <td>Do you have an adult in your life that you tru...</td>\n",
       "      <td>Advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22994</th>\n",
       "      <td>98f4o1</td>\n",
       "      <td>&lt;US_AUTHOR&gt;</td>\n",
       "      <td>I’m hoping someone can give me advice on how t...</td>\n",
       "      <td>What is their income?</td>\n",
       "      <td>Do they have home insurance?</td>\n",
       "      <td>personalfinance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22995</th>\n",
       "      <td>98f4o1</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>I’m hoping someone can give me advice on how t...</td>\n",
       "      <td>What is their income?</td>\n",
       "      <td>Do they have home insurance?</td>\n",
       "      <td>personalfinance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id          reader_token_str  \\\n",
       "22989     bc5yeu            <NONUS_AUTHOR>   \n",
       "22991     cbjgh5  <RESPONSE_TIME_1_AUTHOR>   \n",
       "22992     a9wlwo     <EXPERT_PCT_0_AUTHOR>   \n",
       "22994     98f4o1               <US_AUTHOR>   \n",
       "22995     98f4o1     <EXPERT_PCT_0_AUTHOR>   \n",
       "\n",
       "                                             source_text  \\\n",
       "22989  My sister is 34 and I'm 40, but since our earl...   \n",
       "22991  Is it considered retaliation on my landlords p...   \n",
       "22992  Like, I’m talking, age 30, at least 20 yrs of ...   \n",
       "22994  I’m hoping someone can give me advice on how t...   \n",
       "22995  I’m hoping someone can give me advice on how t...   \n",
       "\n",
       "                               text_only_model_pred_text  \\\n",
       "22989                   Why did you even make this post?   \n",
       "22991     Do you have a lease or are you month to month?   \n",
       "22992  Do you have an adult in your life that you tru...   \n",
       "22994                              What is their income?   \n",
       "22995                              What is their income?   \n",
       "\n",
       "                                  reader_model_pred_text        subreddit  \n",
       "22989  Why would you do that to someone you're overre...    AmItheAsshole  \n",
       "22991                        Whose name is on the lease?      legaladvice  \n",
       "22992  Do you have an adult in your life that you tru...           Advice  \n",
       "22994                       Do they have home insurance?  personalfinance  \n",
       "22995                       Do they have home insurance?  personalfinance  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "test_data = torch.load('../../data/reddit_data/combined_data_val_data.pt')\n",
    "# convert to dataframe\n",
    "test_data = test_data.data.to_pandas()\n",
    "test_data = test_data.loc[:, ['article_id', 'reader_token_str', 'source_text']]\n",
    "# add predicted text\n",
    "test_data = test_data.assign(**{\n",
    "    'text_only_model_pred_text' : no_reader_pred_text,\n",
    "    'reader_model_pred_text' : reader_aware_pred_text,\n",
    "})\n",
    "## add subreddit data\n",
    "import pandas as pd\n",
    "submission_data = pd.read_csv('../../data/reddit_data/subreddit_submissions_2018-01_2019-12.gz', sep='\\t', compression='gzip', usecols=['id', 'subreddit'])\n",
    "submission_data.rename(columns={'id' : 'article_id'}, inplace=True)\n",
    "test_data = pd.merge(test_data, submission_data, on='article_id', how='left')\n",
    "## limit to data where output is different!!\n",
    "output_diff_test_data = test_data[test_data.loc[:, 'text_only_model_pred_text']!=test_data.loc[:, 'reader_model_pred_text']]\n",
    "print(f'{output_diff_test_data.shape[0]}/{test_data.shape[0]} output that are different across models')\n",
    "display(output_diff_test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 sample data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>reader_token_str</th>\n",
       "      <th>source_text</th>\n",
       "      <th>text_only_model_pred_text</th>\n",
       "      <th>reader_model_pred_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23949</th>\n",
       "      <td>8phwx3</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>I’m 30, have a well-paying job in Silicon Vall...</td>\n",
       "      <td>And how would I feel if I did the same?</td>\n",
       "      <td>Do I like the taste of the relationship?</td>\n",
       "      <td>Advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26453</th>\n",
       "      <td>8lygi5</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>I'm on a trip currently, and my boyfriend and ...</td>\n",
       "      <td>Do you have any idea what the issue is?</td>\n",
       "      <td>Do you have any pictures or video of the trip?</td>\n",
       "      <td>Advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37479</th>\n",
       "      <td>8oxseg</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>well there is a female i know, like im not fri...</td>\n",
       "      <td>Did you ever ask her why she dislikes you?</td>\n",
       "      <td>How does she react when you don't invite her?</td>\n",
       "      <td>Advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38656</th>\n",
       "      <td>b0ycks</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>So i have recently started writing a book and ...</td>\n",
       "      <td>What book is it?</td>\n",
       "      <td>Does the book give any information about what ...</td>\n",
       "      <td>Advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42544</th>\n",
       "      <td>d1gl4d</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>I’m not sure what exactly I’m asking for by po...</td>\n",
       "      <td>How can people say that a rape victim?</td>\n",
       "      <td>Have you tried talking to a counselor about this?</td>\n",
       "      <td>Advice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id       reader_token_str  \\\n",
       "23949     8phwx3  <EXPERT_PCT_0_AUTHOR>   \n",
       "26453     8lygi5  <EXPERT_PCT_0_AUTHOR>   \n",
       "37479     8oxseg  <EXPERT_PCT_0_AUTHOR>   \n",
       "38656     b0ycks  <EXPERT_PCT_0_AUTHOR>   \n",
       "42544     d1gl4d  <EXPERT_PCT_0_AUTHOR>   \n",
       "\n",
       "                                             source_text  \\\n",
       "23949  I’m 30, have a well-paying job in Silicon Vall...   \n",
       "26453  I'm on a trip currently, and my boyfriend and ...   \n",
       "37479  well there is a female i know, like im not fri...   \n",
       "38656  So i have recently started writing a book and ...   \n",
       "42544  I’m not sure what exactly I’m asking for by po...   \n",
       "\n",
       "                        text_only_model_pred_text  \\\n",
       "23949     And how would I feel if I did the same?   \n",
       "26453     Do you have any idea what the issue is?   \n",
       "37479  Did you ever ask her why she dislikes you?   \n",
       "38656                            What book is it?   \n",
       "42544      How can people say that a rape victim?   \n",
       "\n",
       "                                  reader_model_pred_text subreddit  \n",
       "23949           Do I like the taste of the relationship?    Advice  \n",
       "26453     Do you have any pictures or video of the trip?    Advice  \n",
       "37479      How does she react when you don't invite her?    Advice  \n",
       "38656  Does the book give any information about what ...    Advice  \n",
       "42544  Have you tried talking to a counselor about this?    Advice  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>reader_token_str</th>\n",
       "      <th>post</th>\n",
       "      <th>text_only_model_pred_text</th>\n",
       "      <th>reader_model_pred_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text_1</th>\n",
       "      <th>system_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>system_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23949</th>\n",
       "      <td>8phwx3</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>I’m 30, have a well-paying job in Silicon Vall...</td>\n",
       "      <td>And how would I feel if I did the same?</td>\n",
       "      <td>Do I like the taste of the relationship?</td>\n",
       "      <td>Advice</td>\n",
       "      <td>And how would I feel if I did the same?</td>\n",
       "      <td>text_only_model_pred_text</td>\n",
       "      <td>Do I like the taste of the relationship?</td>\n",
       "      <td>reader_model_pred_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26453</th>\n",
       "      <td>8lygi5</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>I'm on a trip currently, and my boyfriend and ...</td>\n",
       "      <td>Do you have any idea what the issue is?</td>\n",
       "      <td>Do you have any pictures or video of the trip?</td>\n",
       "      <td>Advice</td>\n",
       "      <td>Do you have any pictures or video of the trip?</td>\n",
       "      <td>reader_model_pred_text</td>\n",
       "      <td>Do you have any idea what the issue is?</td>\n",
       "      <td>text_only_model_pred_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37479</th>\n",
       "      <td>8oxseg</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>well there is a female i know, like im not fri...</td>\n",
       "      <td>Did you ever ask her why she dislikes you?</td>\n",
       "      <td>How does she react when you don't invite her?</td>\n",
       "      <td>Advice</td>\n",
       "      <td>Did you ever ask her why she dislikes you?</td>\n",
       "      <td>text_only_model_pred_text</td>\n",
       "      <td>How does she react when you don't invite her?</td>\n",
       "      <td>reader_model_pred_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38656</th>\n",
       "      <td>b0ycks</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>So i have recently started writing a book and ...</td>\n",
       "      <td>What book is it?</td>\n",
       "      <td>Does the book give any information about what ...</td>\n",
       "      <td>Advice</td>\n",
       "      <td>Does the book give any information about what ...</td>\n",
       "      <td>reader_model_pred_text</td>\n",
       "      <td>What book is it?</td>\n",
       "      <td>text_only_model_pred_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42544</th>\n",
       "      <td>d1gl4d</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>I’m not sure what exactly I’m asking for by po...</td>\n",
       "      <td>How can people say that a rape victim?</td>\n",
       "      <td>Have you tried talking to a counselor about this?</td>\n",
       "      <td>Advice</td>\n",
       "      <td>How can people say that a rape victim?</td>\n",
       "      <td>text_only_model_pred_text</td>\n",
       "      <td>Have you tried talking to a counselor about this?</td>\n",
       "      <td>reader_model_pred_text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id       reader_token_str  \\\n",
       "23949     8phwx3  <EXPERT_PCT_0_AUTHOR>   \n",
       "26453     8lygi5  <EXPERT_PCT_0_AUTHOR>   \n",
       "37479     8oxseg  <EXPERT_PCT_0_AUTHOR>   \n",
       "38656     b0ycks  <EXPERT_PCT_0_AUTHOR>   \n",
       "42544     d1gl4d  <EXPERT_PCT_0_AUTHOR>   \n",
       "\n",
       "                                                    post  \\\n",
       "23949  I’m 30, have a well-paying job in Silicon Vall...   \n",
       "26453  I'm on a trip currently, and my boyfriend and ...   \n",
       "37479  well there is a female i know, like im not fri...   \n",
       "38656  So i have recently started writing a book and ...   \n",
       "42544  I’m not sure what exactly I’m asking for by po...   \n",
       "\n",
       "                        text_only_model_pred_text  \\\n",
       "23949     And how would I feel if I did the same?   \n",
       "26453     Do you have any idea what the issue is?   \n",
       "37479  Did you ever ask her why she dislikes you?   \n",
       "38656                            What book is it?   \n",
       "42544      How can people say that a rape victim?   \n",
       "\n",
       "                                  reader_model_pred_text subreddit  \\\n",
       "23949           Do I like the taste of the relationship?    Advice   \n",
       "26453     Do you have any pictures or video of the trip?    Advice   \n",
       "37479      How does she react when you don't invite her?    Advice   \n",
       "38656  Does the book give any information about what ...    Advice   \n",
       "42544  Have you tried talking to a counselor about this?    Advice   \n",
       "\n",
       "                                                  text_1  \\\n",
       "23949            And how would I feel if I did the same?   \n",
       "26453     Do you have any pictures or video of the trip?   \n",
       "37479         Did you ever ask her why she dislikes you?   \n",
       "38656  Does the book give any information about what ...   \n",
       "42544             How can people say that a rape victim?   \n",
       "\n",
       "                        system_1  \\\n",
       "23949  text_only_model_pred_text   \n",
       "26453     reader_model_pred_text   \n",
       "37479  text_only_model_pred_text   \n",
       "38656     reader_model_pred_text   \n",
       "42544  text_only_model_pred_text   \n",
       "\n",
       "                                                  text_2  \\\n",
       "23949           Do I like the taste of the relationship?   \n",
       "26453            Do you have any idea what the issue is?   \n",
       "37479      How does she react when you don't invite her?   \n",
       "38656                                   What book is it?   \n",
       "42544  Have you tried talking to a counselor about this?   \n",
       "\n",
       "                        system_2  \n",
       "23949     reader_model_pred_text  \n",
       "26453  text_only_model_pred_text  \n",
       "37479     reader_model_pred_text  \n",
       "38656  text_only_model_pred_text  \n",
       "42544     reader_model_pred_text  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## get sample from different subreddits\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "sample_output_data = []\n",
    "samples_per_reader_group = 5\n",
    "for subreddit_i, data_i in output_diff_test_data.groupby('subreddit'):\n",
    "    # remove UNK readers\n",
    "    data_i = data_i[data_i.loc[:, 'reader_token_str']!='UNK']\n",
    "    for reader_token_j, data_j in data_i.groupby('reader_token_str'):\n",
    "        article_ids_j = np.random.choice(data_j.loc[:, 'article_id'].unique(), samples_per_reader_group, replace=False)\n",
    "        sample_data_j = data_j[data_j.loc[:, 'article_id'].isin(article_ids_j)].drop_duplicates('article_id')\n",
    "        sample_output_data.append(sample_data_j)\n",
    "sample_output_data = pd.concat(sample_output_data, axis=0)\n",
    "print(f'{sample_output_data.shape[0]} sample data')\n",
    "display(sample_output_data.head())\n",
    "# ## save to file\n",
    "# sample_output_data.to_csv('../../data/reddit_data/annotation_data/text_quality_ground_truth_data.tsv', sep='\\t', index=False)\n",
    "## shuffle labels, rewrite as annotator data\n",
    "annotator_sample_data = sample_output_data.copy()\n",
    "annotator_sample_data.rename(columns={'source_text' : 'post'}, inplace=True)\n",
    "pred_text_cols = ['text_only_model_pred_text', 'reader_model_pred_text']\n",
    "N_pred_text = len(pred_text_cols)\n",
    "sample_pred_shuffled_idx = annotator_sample_data.loc[:, pred_text_cols].apply(lambda x: np.random.choice(list(range(N_pred_text)), N_pred_text, replace=False), axis=1)\n",
    "sample_pred_shuffled_text_cols = sample_pred_shuffled_idx.apply(lambda x: [pred_text_cols[idx] for idx in x])\n",
    "for i in range(N_pred_text):\n",
    "    annotator_sample_data = annotator_sample_data.assign(**{\n",
    "        f'question_{i+1}' : list(map(lambda x: annotator_sample_data.iloc[x[0], :].loc[x[1][i]], enumerate(sample_pred_shuffled_text_cols.values))),\n",
    "        f'system_{i+1}' : list(map(lambda x: x[i], sample_pred_shuffled_text_cols))\n",
    "    })\n",
    "display(annotator_sample_data.head())\n",
    "## save ground-truth to file\n",
    "annotator_sample_data.to_csv('../../data/reddit_data/annotation_data/generated_text_evaluation/text_quality_ground_truth_data.tsv', sep='\\t', index=False)\n",
    "## remove labels lol\n",
    "system_cols = [f'system_{i+1}' for i in range(N_pred_text)]\n",
    "unlabeled_sample_data = annotator_sample_data.drop(system_cols + ['reader_token_str'] + pred_text_cols, axis=1)\n",
    "unlabeled_sample_data = unlabeled_sample_data.assign(**{\n",
    "    'text_that_makes_more_sense' : -1,\n",
    "    'text_that_is_more_fluent' : -1,\n",
    "    'text_that_is_more_likely_helpful' : -1,\n",
    "})\n",
    "unlabeled_sample_data.to_csv('../../data/reddit_data/annotation_data/generated_text_evaluation/text_quality_annotation_data.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data for real and generated reader-aware questions\n",
    "Let's get real and generated text for reader-aware questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advice\n",
      "15\n",
      "38\n",
      "1\n",
      "AmItheAsshole\n",
      "86\n",
      "246\n",
      "42\n",
      "legaladvice\n",
      "6\n",
      "56\n",
      "1\n",
      "pcmasterrace\n",
      "2\n",
      "13\n",
      "1\n",
      "personalfinance\n",
      "20\n",
      "100\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "## for each reader group pair: get 2 questions from same article\n",
    "reader_group_data = [\n",
    "    ('EXPERT', '<EXPERT_PCT_0_AUTHOR>', '<EXPERT_PCT_1_AUTHOR>'),\n",
    "    ('TIME', '<RESPONSE_TIME_0_AUTHOR>', '<RESPONSE_TIME_1_AUTHOR>'),\n",
    "    ('LOC', '<US_AUTHOR>', '<NONUS_AUTHOR>'),\n",
    "]\n",
    "# val_data_article_reader_groups = val_data.groupby('article_id').apply(lambda x: set(x.loc[:, 'reader_token_str'].unique()))\n",
    "# article ID | reader group class | question | reader group type | subreddit\n",
    "sample_size = 20\n",
    "for subreddit_i, data_i in val_data.groupby('subreddit'):\n",
    "    print(subreddit_i)\n",
    "    article_reader_groups_i = data_i.groupby('article_id').apply(lambda x: set(x.loc[:, 'reader_token_str'].unique()))\n",
    "    for reader_group_type_j, reader_group_1, reader_group_2 in reader_group_data:\n",
    "        articles_ids_j = article_reader_groups_i[article_reader_groups_i.apply(lambda x: reader_group_1 in x and reader_group_2 in x)]\n",
    "        print(len(articles_ids_j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! It looks like `pcmasterrace` and `personalfinance`, which we were planning to use in evaluation, don't have great coverage of reader groups.\n",
    "\n",
    "Let's pivot to training data to improve coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load('../../data/reddit_data/combined_data_train_data.pt')\n",
    "train_data = pd.DataFrame(list(train_data))\n",
    "data_cols = ['article_id', 'author_has_subreddit_embed', 'author_has_text_embed', 'reader_token_str', 'source_text', 'source_ids_reader_token', 'target_text', 'subreddit_embed', 'text_embed', 'attention_mask']\n",
    "train_data = train_data.loc[:, data_cols]\n",
    "# add subreddit info\n",
    "train_data = pd.merge(train_data, post_metadata, on=['article_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK                         1134850\n",
      "<EXPERT_PCT_0_AUTHOR>        290931\n",
      "<RESPONSE_TIME_0_AUTHOR>     223571\n",
      "<RESPONSE_TIME_1_AUTHOR>      79179\n",
      "<US_AUTHOR>                   29237\n",
      "<NONUS_AUTHOR>                21367\n",
      "<EXPERT_PCT_1_AUTHOR>         11819\n",
      "Name: reader_token_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.loc[:, 'reader_token_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advice\n",
      "group EXPERT has 66 articles\n",
      "group TIME has 201 articles\n",
      "group LOC has 8 articles\n",
      "AmItheAsshole\n",
      "group EXPERT has 270 articles\n",
      "group TIME has 946 articles\n",
      "group LOC has 122 articles\n",
      "legaladvice\n",
      "group EXPERT has 40 articles\n",
      "group TIME has 199 articles\n",
      "group LOC has 6 articles\n",
      "pcmasterrace\n",
      "group EXPERT has 19 articles\n",
      "group TIME has 59 articles\n",
      "group LOC has 0 articles\n",
      "personalfinance\n",
      "group EXPERT has 75 articles\n",
      "group TIME has 413 articles\n",
      "group LOC has 9 articles\n"
     ]
    }
   ],
   "source": [
    "for subreddit_i, data_i in train_data.groupby('subreddit'):\n",
    "    print(subreddit_i)\n",
    "    article_reader_groups_i = data_i.groupby('article_id').apply(lambda x: set(x.loc[:, 'reader_token_str'].unique()))\n",
    "    for reader_group_type_j, reader_group_1, reader_group_2 in reader_group_data:\n",
    "        articles_ids_j = article_reader_groups_i[article_reader_groups_i.apply(lambda x: reader_group_1 in x and reader_group_2 in x)]\n",
    "        print(f'group {reader_group_type_j} has {len(articles_ids_j)} articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better! Now we can sample some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post</th>\n",
       "      <th>question_1</th>\n",
       "      <th>group_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>group_2</th>\n",
       "      <th>group_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8kc90i</td>\n",
       "      <td>Advice</td>\n",
       "      <td>First off, I have no problem with weed because...</td>\n",
       "      <td>Is she trying to use the marijuana as a shortc...</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>but is it worth being caught?</td>\n",
       "      <td>&lt;EXPERT_PCT_1_AUTHOR&gt;</td>\n",
       "      <td>EXPERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8l91i1</td>\n",
       "      <td>Advice</td>\n",
       "      <td>I work online and last week my boss called and...</td>\n",
       "      <td>Now, how's that cold?</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>Did you thank him for been a good boss and why...</td>\n",
       "      <td>&lt;EXPERT_PCT_1_AUTHOR&gt;</td>\n",
       "      <td>EXPERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8p4uwz</td>\n",
       "      <td>Advice</td>\n",
       "      <td>Was in the midst of a panic attack over some t...</td>\n",
       "      <td>How would you feel if you or your family got a...</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>Did any one see that you hit the car?</td>\n",
       "      <td>&lt;EXPERT_PCT_1_AUTHOR&gt;</td>\n",
       "      <td>EXPERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8v8mga</td>\n",
       "      <td>Advice</td>\n",
       "      <td>In other words, I don't know who I am. I suck ...</td>\n",
       "      <td>Have you ever tried keeping a diary or journal?</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>Do you doubt yourself, your choices, etc.?</td>\n",
       "      <td>&lt;EXPERT_PCT_1_AUTHOR&gt;</td>\n",
       "      <td>EXPERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8vm0a1</td>\n",
       "      <td>Advice</td>\n",
       "      <td>Hey, I’m 19 and a half and I’ve been out of hi...</td>\n",
       "      <td>What problem do you wish was solved in the world?</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>It was very different from School or College, ...</td>\n",
       "      <td>&lt;EXPERT_PCT_1_AUTHOR&gt;</td>\n",
       "      <td>EXPERT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id subreddit                                               post  \\\n",
       "0     8kc90i    Advice  First off, I have no problem with weed because...   \n",
       "1     8l91i1    Advice  I work online and last week my boss called and...   \n",
       "2     8p4uwz    Advice  Was in the midst of a panic attack over some t...   \n",
       "3     8v8mga    Advice  In other words, I don't know who I am. I suck ...   \n",
       "4     8vm0a1    Advice  Hey, I’m 19 and a half and I’ve been out of hi...   \n",
       "\n",
       "                                          question_1                group_1  \\\n",
       "0  Is she trying to use the marijuana as a shortc...  <EXPERT_PCT_0_AUTHOR>   \n",
       "1                              Now, how's that cold?  <EXPERT_PCT_0_AUTHOR>   \n",
       "2  How would you feel if you or your family got a...  <EXPERT_PCT_0_AUTHOR>   \n",
       "3    Have you ever tried keeping a diary or journal?  <EXPERT_PCT_0_AUTHOR>   \n",
       "4  What problem do you wish was solved in the world?  <EXPERT_PCT_0_AUTHOR>   \n",
       "\n",
       "                                          question_2                group_2  \\\n",
       "0                      but is it worth being caught?  <EXPERT_PCT_1_AUTHOR>   \n",
       "1  Did you thank him for been a good boss and why...  <EXPERT_PCT_1_AUTHOR>   \n",
       "2              Did any one see that you hit the car?  <EXPERT_PCT_1_AUTHOR>   \n",
       "3         Do you doubt yourself, your choices, etc.?  <EXPERT_PCT_1_AUTHOR>   \n",
       "4  It was very different from School or College, ...  <EXPERT_PCT_1_AUTHOR>   \n",
       "\n",
       "  group_type  \n",
       "0     EXPERT  \n",
       "1     EXPERT  \n",
       "2     EXPERT  \n",
       "3     EXPERT  \n",
       "4     EXPERT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "sample_size = 100\n",
    "reader_group_sample_question_data = []\n",
    "for subreddit_i, data_i in train_data.groupby('subreddit'):\n",
    "    article_reader_groups_i = data_i.groupby('article_id').apply(lambda x: set(x.loc[:, 'reader_token_str'].unique()))\n",
    "    for reader_group_type_j, reader_group_1, reader_group_2 in reader_group_data:\n",
    "        article_ids_j = article_reader_groups_i[article_reader_groups_i.apply(lambda x: reader_group_1 in x and reader_group_2 in x)].index.tolist()\n",
    "        # sample\n",
    "        if(len(article_ids_j) > sample_size):\n",
    "            article_ids_j = np.random.choice(article_ids_j, sample_size, replace=False)\n",
    "        # get paired reader group data for each article\n",
    "        for article_id_k in article_ids_j:\n",
    "            data_k = data_i[(data_i.loc[:, 'article_id']==article_id_k)]\n",
    "            sample_data_k_1 = data_k[data_k.loc[:, 'reader_token_str']==reader_group_1].iloc[0, :]\n",
    "            sample_data_k_2 = data_k[data_k.loc[:, 'reader_token_str']==reader_group_2].iloc[0, :]\n",
    "            post_text_k = data_k.loc[:, 'source_text'].iloc[0]\n",
    "            reader_group_sample_question_data.append([article_id_k, subreddit_i, post_text_k, sample_data_k_1.loc['target_text'], reader_group_1, sample_data_k_2.loc['target_text'], reader_group_2, reader_group_type_j])\n",
    "reader_group_sample_question_data = pd.DataFrame(reader_group_sample_question_data, \n",
    "                                                 columns=['article_id', 'subreddit', 'post', 'question_1', 'group_1', 'question_2', 'group_2', 'group_type'])\n",
    "display(reader_group_sample_question_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now! Let's generate questions for the same data using the reader-aware model, and organize to match the layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model\n",
    "from test_question_generation import load_model\n",
    "model_cache_dir = '../../data/model_cache/'\n",
    "model_weight_file = '../../data/reddit_data/author_text_data/question_generation_model/checkpoint-114500/pytorch_model.bin'\n",
    "data_dir = '../../data/reddit_data/author_text_data/'\n",
    "model_type = 'bart_author'\n",
    "model, model_tokenizer = load_model(model_cache_dir, model_weight_file, model_type, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1634\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>reader_token_str</th>\n",
       "      <th>source_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1636010</th>\n",
       "      <td>7py853</td>\n",
       "      <td>&lt;NONUS_AUTHOR&gt;</td>\n",
       "      <td>[tensor(0), tensor(154), tensor(7), tensor(5),...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220202</th>\n",
       "      <td>7py853</td>\n",
       "      <td>&lt;US_AUTHOR&gt;</td>\n",
       "      <td>[tensor(0), tensor(154), tensor(7), tensor(5),...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654293</th>\n",
       "      <td>7rkvv3</td>\n",
       "      <td>&lt;US_AUTHOR&gt;</td>\n",
       "      <td>[tensor(0), tensor(17), tensor(27), tensor(119...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199596</th>\n",
       "      <td>7rkvv3</td>\n",
       "      <td>&lt;NONUS_AUTHOR&gt;</td>\n",
       "      <td>[tensor(0), tensor(17), tensor(27), tensor(119...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507009</th>\n",
       "      <td>814t9v</td>\n",
       "      <td>&lt;NONUS_AUTHOR&gt;</td>\n",
       "      <td>[tensor(0), tensor(1141), tensor(6), tensor(81...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id reader_token_str  \\\n",
       "1636010     7py853   <NONUS_AUTHOR>   \n",
       "1220202     7py853      <US_AUTHOR>   \n",
       "1654293     7rkvv3      <US_AUTHOR>   \n",
       "1199596     7rkvv3   <NONUS_AUTHOR>   \n",
       "1507009     814t9v   <NONUS_AUTHOR>   \n",
       "\n",
       "                                                source_ids  \\\n",
       "1636010  [tensor(0), tensor(154), tensor(7), tensor(5),...   \n",
       "1220202  [tensor(0), tensor(154), tensor(7), tensor(5),...   \n",
       "1654293  [tensor(0), tensor(17), tensor(27), tensor(119...   \n",
       "1199596  [tensor(0), tensor(17), tensor(27), tensor(119...   \n",
       "1507009  [tensor(0), tensor(1141), tensor(6), tensor(81...   \n",
       "\n",
       "                                            attention_mask  \n",
       "1636010  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "1220202  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "1654293  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "1199596  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "1507009  [tensor(1), tensor(1), tensor(1), tensor(1), t...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## subset data to articles and reader groups mentioned in sample data\n",
    "generation_data = train_data[train_data.loc[:, 'article_id'].isin(reader_group_sample_question_data.loc[:, 'article_id'].unique())].drop_duplicates(['article_id', 'reader_token_str'])\n",
    "article_id_valid_tokens = reader_group_sample_question_data.groupby('article_id').apply(lambda x: x.iloc[0, :].loc[['group_1', 'group_2']].values.tolist())\n",
    "generation_data = generation_data[generation_data.apply(lambda x: x.loc['reader_token_str'] in article_id_valid_tokens.loc[x.loc['article_id']], axis=1)]\n",
    "generation_data.sort_values('article_id', inplace=True)\n",
    "generation_data = generation_data.loc[:, ['article_id', 'reader_token_str', 'source_ids_reader_token', 'attention_mask']]\n",
    "generation_data.rename(columns={'source_ids_reader_token' : 'source_ids'}, inplace=True)\n",
    "generation_data.drop_duplicates(['article_id', 'reader_token_str'], inplace=True)\n",
    "print(generation_data.shape[0])\n",
    "# fix tensor vars\n",
    "generation_data = generation_data.assign(**{\n",
    "    'source_ids' : generation_data.loc[:, 'source_ids'].apply(lambda x: torch.LongTensor(x)),\n",
    "    'attention_mask' : generation_data.loc[:, 'attention_mask'].apply(lambda x: torch.LongTensor(x)),\n",
    "})\n",
    "# convert to list of dicts\n",
    "generation_data_iter = generation_data.apply(lambda x: x.to_dict(), axis=1).values.tolist()\n",
    "display(generation_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1634/1634 [07:34<00:00,  3.60it/s]\n"
     ]
    }
   ],
   "source": [
    "## generate text for all source examples\n",
    "from model_helpers import generate_predictions\n",
    "generation_method = 'beam_search'\n",
    "num_beams = 8\n",
    "pred_text = generate_predictions(model, generation_data_iter, model_tokenizer, generation_method=generation_method, num_beams=num_beams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260 generated pairs total\n"
     ]
    }
   ],
   "source": [
    "## re-add to generation data\n",
    "generation_pred_data = generation_data.assign(**{\n",
    "    'pred_text' : pred_text\n",
    "})\n",
    "## reorganize to match original sampled data\n",
    "reader_token_groups = {\n",
    "    'LOC' : ['<US_AUTHOR>', '<NONUS_AUTHOR>'],\n",
    "    'EXPERT' : ['<EXPERT_PCT_0_AUTHOR>', '<EXPERT_PCT_1_AUTHOR>'],\n",
    "    'TIME' : ['<RESPONSE_TIME_0_AUTHOR>', '<RESPONSE_TIME_1_AUTHOR>'],\n",
    "}\n",
    "reader_token_group_lookup = {v1 : k for k,v in reader_token_groups.items() for v1 in v}\n",
    "def flatten_pred_data(data, reader_token_group_lookup):\n",
    "    reader_group_type = reader_token_group_lookup[data.loc[:, 'reader_token_str'].iloc[0]]\n",
    "    data_1 = data.iloc[0, :]\n",
    "    data_2 = data.iloc[1, :]\n",
    "    flat_data = [data_1.loc['pred_text'], data_1.loc['reader_token_str'], \n",
    "                 data_2.loc['pred_text'], data_2.loc['reader_token_str'],\n",
    "                 reader_group_type]\n",
    "    flat_data_cols = ['question_1', 'group_1', 'question_2', 'group_2', 'group_type']\n",
    "    flat_data = pd.Series(flat_data, index=flat_data_cols)\n",
    "    return flat_data\n",
    "per_article_generation_pred_data = generation_pred_data.groupby('article_id').apply(lambda x: flatten_pred_data(x, reader_token_group_lookup)).reset_index()\n",
    "# remove duplicates\n",
    "per_article_generation_pred_data = per_article_generation_pred_data[per_article_generation_pred_data.loc[:, 'question_1']!=per_article_generation_pred_data.loc[:, 'question_2']]\n",
    "## join with metadata\n",
    "per_article_generation_pred_data = pd.merge(per_article_generation_pred_data, reader_group_sample_question_data.loc[:, ['article_id', 'subreddit', 'post']].drop_duplicates('article_id'), on='article_id', how='left')\n",
    "print(f'{per_article_generation_pred_data.shape[0]} generated pairs total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the real and generated data, let's shuffle the groups to prepare for annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_questions_by_group(data, num_groups, group_vars=['question', 'group']):\n",
    "    ordered_group_cols = [[f'{var}_{i}' for var in group_vars] for i in range(1, num_groups+1)]\n",
    "    group_cols = list(ordered_group_cols)\n",
    "    np.random.shuffle(group_cols)\n",
    "    flat_group_cols = [y for x in group_cols for y in x]\n",
    "    flat_ordered_group_cols = [y for x in ordered_group_cols for y in x]\n",
    "    group_data = data.loc[flat_group_cols]\n",
    "    group_data.index = flat_ordered_group_cols\n",
    "    data.drop(flat_ordered_group_cols, inplace=True)\n",
    "    data = data.append(group_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post</th>\n",
       "      <th>group_type</th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>group_type_choices</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7py853</td>\n",
       "      <td>legaladvice</td>\n",
       "      <td>Turning to the experts at reddit!  I'm in a ba...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Are you sure it's not a scam and not a identit...</td>\n",
       "      <td>Are you sure it's not a scam?</td>\n",
       "      <td>US vs. non-US</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>814t9v</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>My wife, over a year ago, thought she submitte...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Did she file for deferment?</td>\n",
       "      <td>Did you send her a certified letter or just a ...</td>\n",
       "      <td>US vs. non-US</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89p14v</td>\n",
       "      <td>Advice</td>\n",
       "      <td>Every Tuesday my neighbours garbage goes flyin...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Are you sure it wasn’t your mom’s personal junk?</td>\n",
       "      <td>How did you get your garbage there?</td>\n",
       "      <td>US vs. non-US</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8c71q3</td>\n",
       "      <td>Advice</td>\n",
       "      <td>My ex girlfriend is very suicidal. We broke up...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>How long have you been with her?</td>\n",
       "      <td>How long have you been with this person?</td>\n",
       "      <td>US vs. non-US</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8kc90i</td>\n",
       "      <td>Advice</td>\n",
       "      <td>First off, I have no problem with weed because...</td>\n",
       "      <td>EXPERT</td>\n",
       "      <td>Is she trying to use the marijuana for feeling...</td>\n",
       "      <td>What is her motivation behind it?</td>\n",
       "      <td>expert vs. novice</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id        subreddit  \\\n",
       "0     7py853      legaladvice   \n",
       "1     814t9v  personalfinance   \n",
       "2     89p14v           Advice   \n",
       "3     8c71q3           Advice   \n",
       "4     8kc90i           Advice   \n",
       "\n",
       "                                                post group_type  \\\n",
       "0  Turning to the experts at reddit!  I'm in a ba...        LOC   \n",
       "1  My wife, over a year ago, thought she submitte...        LOC   \n",
       "2  Every Tuesday my neighbours garbage goes flyin...        LOC   \n",
       "3  My ex girlfriend is very suicidal. We broke up...        LOC   \n",
       "4  First off, I have no problem with weed because...     EXPERT   \n",
       "\n",
       "                                          question_1  \\\n",
       "0  Are you sure it's not a scam and not a identit...   \n",
       "1                        Did she file for deferment?   \n",
       "2   Are you sure it wasn’t your mom’s personal junk?   \n",
       "3                   How long have you been with her?   \n",
       "4  Is she trying to use the marijuana for feeling...   \n",
       "\n",
       "                                          question_2 group_type_choices  label  \n",
       "0                      Are you sure it's not a scam?      US vs. non-US     -1  \n",
       "1  Did you send her a certified letter or just a ...      US vs. non-US     -1  \n",
       "2                How did you get your garbage there?      US vs. non-US     -1  \n",
       "3           How long have you been with this person?      US vs. non-US     -1  \n",
       "4                  What is her motivation behind it?  expert vs. novice     -1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post</th>\n",
       "      <th>group_type</th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>group_type_choices</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8kc90i</td>\n",
       "      <td>Advice</td>\n",
       "      <td>First off, I have no problem with weed because...</td>\n",
       "      <td>EXPERT</td>\n",
       "      <td>Is she trying to use the marijuana as a shortc...</td>\n",
       "      <td>but is it worth being caught?</td>\n",
       "      <td>expert vs. novice</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8l91i1</td>\n",
       "      <td>Advice</td>\n",
       "      <td>I work online and last week my boss called and...</td>\n",
       "      <td>EXPERT</td>\n",
       "      <td>Did you thank him for been a good boss and why...</td>\n",
       "      <td>Now, how's that cold?</td>\n",
       "      <td>expert vs. novice</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8p4uwz</td>\n",
       "      <td>Advice</td>\n",
       "      <td>Was in the midst of a panic attack over some t...</td>\n",
       "      <td>EXPERT</td>\n",
       "      <td>How would you feel if you or your family got a...</td>\n",
       "      <td>Did any one see that you hit the car?</td>\n",
       "      <td>expert vs. novice</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8v8mga</td>\n",
       "      <td>Advice</td>\n",
       "      <td>In other words, I don't know who I am. I suck ...</td>\n",
       "      <td>EXPERT</td>\n",
       "      <td>Do you doubt yourself, your choices, etc.?</td>\n",
       "      <td>Have you ever tried keeping a diary or journal?</td>\n",
       "      <td>expert vs. novice</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8vm0a1</td>\n",
       "      <td>Advice</td>\n",
       "      <td>Hey, I’m 19 and a half and I’ve been out of hi...</td>\n",
       "      <td>EXPERT</td>\n",
       "      <td>What problem do you wish was solved in the world?</td>\n",
       "      <td>It was very different from School or College, ...</td>\n",
       "      <td>expert vs. novice</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id subreddit                                               post  \\\n",
       "0     8kc90i    Advice  First off, I have no problem with weed because...   \n",
       "1     8l91i1    Advice  I work online and last week my boss called and...   \n",
       "2     8p4uwz    Advice  Was in the midst of a panic attack over some t...   \n",
       "3     8v8mga    Advice  In other words, I don't know who I am. I suck ...   \n",
       "4     8vm0a1    Advice  Hey, I’m 19 and a half and I’ve been out of hi...   \n",
       "\n",
       "  group_type                                         question_1  \\\n",
       "0     EXPERT  Is she trying to use the marijuana as a shortc...   \n",
       "1     EXPERT  Did you thank him for been a good boss and why...   \n",
       "2     EXPERT  How would you feel if you or your family got a...   \n",
       "3     EXPERT         Do you doubt yourself, your choices, etc.?   \n",
       "4     EXPERT  What problem do you wish was solved in the world?   \n",
       "\n",
       "                                          question_2 group_type_choices  label  \n",
       "0                      but is it worth being caught?  expert vs. novice     -1  \n",
       "1                              Now, how's that cold?  expert vs. novice     -1  \n",
       "2              Did any one see that you hit the car?  expert vs. novice     -1  \n",
       "3    Have you ever tried keeping a diary or journal?  expert vs. novice     -1  \n",
       "4  It was very different from School or College, ...  expert vs. novice     -1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_groups = 2\n",
    "shuffled_generation_pred_data = per_article_generation_pred_data.apply(lambda x: shuffle_questions_by_group(x, num_groups), axis=1)\n",
    "shuffled_reader_group_sample_question_data = reader_group_sample_question_data.apply(lambda x: shuffle_questions_by_group(x, num_groups), axis=1)\n",
    "# align columns lol\n",
    "shuffled_generation_pred_data = shuffled_generation_pred_data.loc[:, shuffled_reader_group_sample_question_data.columns]\n",
    "## prepare for annotation\n",
    "reader_group_type_choices = pd.DataFrame([\n",
    "    ['EXPERT', 'expert vs. novice'],\n",
    "    ['TIME', 'fast response vs. slow response'],\n",
    "    ['LOC', 'US vs. non-US'],\n",
    "], columns=['group_type', 'group_type_choices'])\n",
    "def prepare_for_annotation(data, reader_group_type_choices):\n",
    "    # drop labels\n",
    "    annotation_data = data.drop(['group_1', 'group_2'], axis=1)\n",
    "    # add choices\n",
    "    annotation_data = pd.merge(annotation_data, reader_group_type_choices, on=['group_type'], how='left')\n",
    "    annotation_data = annotation_data.assign(**{'question_1_group_label' : -1})\n",
    "    return annotation_data\n",
    "annotation_generation_pred_data = prepare_for_annotation(shuffled_generation_pred_data, reader_group_type_choices)\n",
    "annotation_reader_group_sample_question_data = prepare_for_annotation(shuffled_reader_group_sample_question_data, reader_group_type_choices)\n",
    "display(annotation_generation_pred_data.head())\n",
    "display(annotation_reader_group_sample_question_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmItheAsshole      300\n",
       "personalfinance    184\n",
       "Advice             174\n",
       "legaladvice        146\n",
       "pcmasterrace        78\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "AmItheAsshole      87\n",
       "personalfinance    59\n",
       "Advice             55\n",
       "legaladvice        41\n",
       "pcmasterrace       18\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check subreddit distribution\n",
    "display(annotation_reader_group_sample_question_data.loc[:, 'subreddit'].value_counts())\n",
    "display(annotation_generation_pred_data.loc[:, 'subreddit'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-124-c260bb5366e4>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  annotation_reader_group_sample_question_data.sort_values(['subreddit', 'article_id'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## restrict to same posts\n",
    "annotation_reader_group_sample_question_data = annotation_reader_group_sample_question_data[annotation_reader_group_sample_question_data.loc[:, 'article_id'].isin(annotation_generation_pred_data.loc[:, 'article_id'].unique())]\n",
    "## sort\n",
    "annotation_reader_group_sample_question_data.sort_values(['subreddit', 'article_id'], inplace=True)\n",
    "annotation_generation_pred_data.sort_values(['subreddit', 'article_id'], inplace=True)\n",
    "print(annotation_reader_group_sample_question_data.shape[0])\n",
    "print(annotation_generation_pred_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add real/generated labels\n",
    "shuffled_reader_group_sample_question_data = shuffled_reader_group_sample_question_data.assign(**{\n",
    "    'question_type' : 'real',\n",
    "})\n",
    "shuffled_generation_pred_data = shuffled_generation_pred_data.assign(**{\n",
    "    'question_type' : 'author_token_model',\n",
    "})\n",
    "## combine\n",
    "combined_ground_truth_data = pd.concat([\n",
    "    shuffled_reader_group_sample_question_data,\n",
    "    shuffled_generation_pred_data\n",
    "], axis=0)\n",
    "combined_annotation_data = pd.concat([\n",
    "    annotation_reader_group_sample_question_data,\n",
    "    annotation_generation_pred_data,\n",
    "])\n",
    "## sort\n",
    "combined_annotation_data.sort_values(['article_id', 'subreddit', 'group_type_choices'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write ground truth data\n",
    "combined_ground_truth_data.to_csv('../../data/reddit_data/annotation_data/generated_text_evaluation/reader_group_ground_truth_data.tsv', sep='\\t', index=False)\n",
    "# write annotation data\n",
    "combined_annotation_data.to_csv('../../data/reddit_data/annotation_data/generated_text_evaluation/reader_group_annotation_data.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test pilot annotations (round 1)\n",
    "Let's test the pilot annotations (from `r/PCMasterRace`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['article_id', 'reader_token_str', 'post', 'text_only_model_pred_text',\n",
      "       'reader_model_pred_text', 'subreddit', 'question_1', 'system_1',\n",
      "       'question_2', 'system_2'],\n",
      "      dtype='object')\n",
      "Index(['article_id', 'subreddit', 'post', 'group_type', 'question_1',\n",
      "       'group_1', 'question_2', 'group_2', 'question_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## load ground-truth data\n",
    "import pandas as pd\n",
    "text_quality_data = pd.read_csv('../../data/reddit_data/annotation_data/generated_text_evaluation/text_quality_ground_truth_data.tsv', sep='\\t', index_col=False)\n",
    "reader_group_data = pd.read_csv('../../data/reddit_data/annotation_data/generated_text_evaluation/reader_group_ground_truth_data.tsv', sep='\\t', index_col=False)\n",
    "# fix reader group columns\n",
    "reader_group_type_lookup = {\n",
    "    '<EXPERT_PCT_0_AUTHOR>' : 'non-expert',\n",
    "    '<EXPERT_PCT_1_AUTHOR>' : 'expert',\n",
    "    '<RESPONSE_TIME_0_AUTHOR>' : 'slow',\n",
    "    '<RESPONSE_TIME_1_AUTHOR>' : 'high',\n",
    "}\n",
    "import re\n",
    "reader_group_cols = list(filter(lambda x: re.match('group_\\d', x), reader_group_data.columns))\n",
    "for reader_group_col in reader_group_cols:\n",
    "    reader_group_data = reader_group_data.assign(**{\n",
    "        reader_group_col : reader_group_data.loc[:, reader_group_col].apply(reader_group_type_lookup.get)\n",
    "    })\n",
    "print(text_quality_data.columns)\n",
    "print(reader_group_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "def collect_organize_annotation_data(data_files):\n",
    "    combined_data = []\n",
    "    data_type = re.search('(.+)(?=_annotation_data)', os.path.basename(data_files[0])).group(0)\n",
    "    if(data_type == 'text_quality'):\n",
    "        annotation_cols = ['text_that_is_more_relevant', 'text_that_is_more_fluent', 'text_that_is_more_likely_helpful']\n",
    "    elif(data_type == 'reader_group'):\n",
    "        annotation_cols = ['question_1_group_label']\n",
    "    for data_file in data_files:\n",
    "        data = pd.read_csv(data_file, sep='\\t', index_col=False)\n",
    "        annotator_id = int(data_file.replace('.tsv', '').split('_')[-1])\n",
    "        data.rename(columns={\n",
    "            col : f'{col}_{annotator_id}'\n",
    "            for col in annotation_cols\n",
    "        }, inplace=True)\n",
    "        combined_data.append(data)\n",
    "    if(data_type == 'text_quality'):\n",
    "        join_cols = ['article_id', 'subreddit']\n",
    "    # for reader group annotation, some posts have multiple question tests (e.g. US/non-US and expert/non-expert)\n",
    "    elif(data_type == 'reader_group'):\n",
    "        join_cols = ['article_id', 'subreddit', 'question_1', 'question_2']\n",
    "    # drop dulicate columns\n",
    "#     for data in combined_data:\n",
    "#         data.drop_duplicates(join_cols, inplace=True)\n",
    "    clean_data = combined_data[0].copy()\n",
    "    label_col_matcher = re.compile('|'.join(list(map(lambda x: f'{x}_\\d', annotation_cols))))\n",
    "    for data in combined_data[1:]:\n",
    "#         print(f'clean data cols {clean_data.columns}')\n",
    "#         print(f'data cols {data.columns}')\n",
    "#         label_cols = list(filter(lambda x: re.match('.+_\\d', x), data.columns))\n",
    "        label_cols = list(filter(lambda x: label_col_matcher.match(x) is not None, data.columns))\n",
    "        join_label_cols = list(set(join_cols)|set(label_cols))\n",
    "        clean_data = pd.merge(clean_data, data.loc[:, join_label_cols], on=join_cols, how='outer')\n",
    "    # remove null labels\n",
    "    clean_label_cols = list(filter(lambda x: re.match('.+_\\d', x), clean_data.columns))\n",
    "    null_label_val = -1\n",
    "    clean_data = clean_data[clean_data.loc[:, clean_label_cols].max(axis=1) != null_label_val]\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 data for text quality\n",
      "36 data for text quality\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>post</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>text_that_is_more_relevant_2</th>\n",
       "      <th>text_that_is_more_fluent_2</th>\n",
       "      <th>text_that_is_more_likely_helpful_2</th>\n",
       "      <th>Comment</th>\n",
       "      <th>text_that_is_more_relevant_1</th>\n",
       "      <th>text_that_is_more_likely_helpful_1</th>\n",
       "      <th>text_that_is_more_fluent_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>az4os4</td>\n",
       "      <td>This is my first build and they are all brand ...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>What are you trying to achieve here?</td>\n",
       "      <td>Do you have a graphics card installed?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>czgw6r</td>\n",
       "      <td>Hi guys, I recently faced a problem on Intel X...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Do you have the same problem in another system?</td>\n",
       "      <td>Do you have an Intel CPU?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aorth3</td>\n",
       "      <td>I seem to have a performance issue with Hitman...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Is it at 1080p or 1440p?</td>\n",
       "      <td>Does it do it at 1080 or 1440p?</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>same question</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agykvp</td>\n",
       "      <td>Hello Everbody,   I want to build a new pc for...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>What are you going to be doing with the pc?</td>\n",
       "      <td>Are you okay with that?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arenff</td>\n",
       "      <td>I have one of those Intel Stock coolers, in a ...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>What's your temps like?</td>\n",
       "      <td>Do you have good airflow in your case?</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                                               post     subreddit  \\\n",
       "0     az4os4  This is my first build and they are all brand ...  pcmasterrace   \n",
       "1     czgw6r  Hi guys, I recently faced a problem on Intel X...  pcmasterrace   \n",
       "2     aorth3  I seem to have a performance issue with Hitman...  pcmasterrace   \n",
       "3     agykvp  Hello Everbody,   I want to build a new pc for...  pcmasterrace   \n",
       "4     arenff  I have one of those Intel Stock coolers, in a ...  pcmasterrace   \n",
       "\n",
       "                                        question_1  \\\n",
       "0             What are you trying to achieve here?   \n",
       "1  Do you have the same problem in another system?   \n",
       "2                         Is it at 1080p or 1440p?   \n",
       "3      What are you going to be doing with the pc?   \n",
       "4                          What's your temps like?   \n",
       "\n",
       "                               question_2  text_that_is_more_relevant_2  \\\n",
       "0  Do you have a graphics card installed?                             2   \n",
       "1               Do you have an Intel CPU?                             2   \n",
       "2         Does it do it at 1080 or 1440p?                             2   \n",
       "3                 Are you okay with that?                             1   \n",
       "4  Do you have good airflow in your case?                             1   \n",
       "\n",
       "   text_that_is_more_fluent_2  text_that_is_more_likely_helpful_2  \\\n",
       "0                           1                                   1   \n",
       "1                           1                                   2   \n",
       "2                           2                                   2   \n",
       "3                           1                                   1   \n",
       "4                           2                                   2   \n",
       "\n",
       "         Comment  text_that_is_more_relevant_1  \\\n",
       "0            NaN                             2   \n",
       "1            NaN                             2   \n",
       "2  same question                             1   \n",
       "3            NaN                             1   \n",
       "4            NaN                             2   \n",
       "\n",
       "   text_that_is_more_likely_helpful_1  text_that_is_more_fluent_1  \n",
       "0                                   1                           2  \n",
       "1                                   2                           2  \n",
       "2                                   1                           1  \n",
       "3                                   1                           1  \n",
       "4                                   2                           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post</th>\n",
       "      <th>group_type</th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>group_type_choices</th>\n",
       "      <th>question_1_group_label_2</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>comments</th>\n",
       "      <th>question_1_group_label_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8mz1o1</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>hey i'm in need of some helpi have a beefy pc ...</td>\n",
       "      <td>TIME</td>\n",
       "      <td>Is that temp changing at all?</td>\n",
       "      <td>What system is that, what motherboard with whi...</td>\n",
       "      <td>fast response vs. slow response</td>\n",
       "      <td>fast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8mz1o1</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>hey i'm in need of some helpi have a beefy pc ...</td>\n",
       "      <td>TIME</td>\n",
       "      <td>What model is your cpu?</td>\n",
       "      <td>What temp is your monitor?</td>\n",
       "      <td>fast response vs. slow response</td>\n",
       "      <td>slow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>very hard to say for both</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8uajem</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Hello, I was curious as to what kind of stuff ...</td>\n",
       "      <td>TIME</td>\n",
       "      <td>Have you tried power cycling the monitor?</td>\n",
       "      <td>What do you mean the RAM was in the wrong way?</td>\n",
       "      <td>fast response vs. slow response</td>\n",
       "      <td>slow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8uajem</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Hello, I was curious as to what kind of stuff ...</td>\n",
       "      <td>TIME</td>\n",
       "      <td>Are you sure it's the RAM and not the motherbo...</td>\n",
       "      <td>What do you mean it's in the wrong way?</td>\n",
       "      <td>fast response vs. slow response</td>\n",
       "      <td>slow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8v9wk1</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>So I see everyone getting like around 60 fps. ...</td>\n",
       "      <td>TIME</td>\n",
       "      <td>Isnt this game a shitty port with 50 different...</td>\n",
       "      <td>are all your drivers up to date?</td>\n",
       "      <td>fast response vs. slow response</td>\n",
       "      <td>fast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id     subreddit                                               post  \\\n",
       "0     8mz1o1  pcmasterrace  hey i'm in need of some helpi have a beefy pc ...   \n",
       "1     8mz1o1  pcmasterrace  hey i'm in need of some helpi have a beefy pc ...   \n",
       "2     8uajem  pcmasterrace  Hello, I was curious as to what kind of stuff ...   \n",
       "3     8uajem  pcmasterrace  Hello, I was curious as to what kind of stuff ...   \n",
       "4     8v9wk1  pcmasterrace  So I see everyone getting like around 60 fps. ...   \n",
       "\n",
       "  group_type                                         question_1  \\\n",
       "0       TIME                      Is that temp changing at all?   \n",
       "1       TIME                            What model is your cpu?   \n",
       "2       TIME          Have you tried power cycling the monitor?   \n",
       "3       TIME  Are you sure it's the RAM and not the motherbo...   \n",
       "4       TIME  Isnt this game a shitty port with 50 different...   \n",
       "\n",
       "                                          question_2  \\\n",
       "0  What system is that, what motherboard with whi...   \n",
       "1                         What temp is your monitor?   \n",
       "2     What do you mean the RAM was in the wrong way?   \n",
       "3            What do you mean it's in the wrong way?   \n",
       "4                   are all your drivers up to date?   \n",
       "\n",
       "                group_type_choices question_1_group_label_2  Unnamed: 8  \\\n",
       "0  fast response vs. slow response                     fast         NaN   \n",
       "1  fast response vs. slow response                     slow         NaN   \n",
       "2  fast response vs. slow response                     slow         NaN   \n",
       "3  fast response vs. slow response                     slow         NaN   \n",
       "4  fast response vs. slow response                     fast         NaN   \n",
       "\n",
       "                    comments question_1_group_label_1  \n",
       "0                        NaN                     fast  \n",
       "1  very hard to say for both                     slow  \n",
       "2                        NaN                     slow  \n",
       "3                        NaN                     slow  \n",
       "4                        NaN                     fast  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = '../../data/reddit_data/annotation_data/generated_text_evaluation'\n",
    "text_quality_annotation_files = list(filter(lambda x: re.match('text_quality_.*pilot_\\d\\.tsv', x) is not None, os.listdir('../../data/reddit_data/annotation_data/generated_text_evaluation/')))\n",
    "reader_group_annotation_files = list(filter(lambda x: re.match('reader_group_.*pilot_\\d\\.tsv', x) is not None, os.listdir('../../data/reddit_data/annotation_data/generated_text_evaluation/')))\n",
    "text_quality_annotation_files = list(map(lambda x: os.path.join(data_dir, x), text_quality_annotation_files))\n",
    "reader_group_annotation_files = list(map(lambda x: os.path.join(data_dir, x), reader_group_annotation_files))\n",
    "text_quality_annotation_data = collect_organize_annotation_data(text_quality_annotation_files)\n",
    "reader_group_annotation_data = collect_organize_annotation_data(reader_group_annotation_files)\n",
    "print(f'{text_quality_annotation_data.shape[0]} data for text quality')\n",
    "print(f'{reader_group_annotation_data.shape[0]} data for text quality')\n",
    "display(text_quality_annotation_data.head())\n",
    "display(reader_group_annotation_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_id', 'subreddit', 'post', 'group_type', 'question_1',\n",
       "       'question_2', 'group_type_choices', 'question_1_group_label_2',\n",
       "       'Unnamed: 8', 'comments', 'question_1_group_label_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_group_annotation_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text_only_model_pred_text</th>\n",
       "      <th>reader_model_pred_text</th>\n",
       "      <th>reader_token_str</th>\n",
       "      <th>system_1</th>\n",
       "      <th>system_2</th>\n",
       "      <th>post</th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>text_that_is_more_relevant_2</th>\n",
       "      <th>text_that_is_more_fluent_2</th>\n",
       "      <th>text_that_is_more_likely_helpful_2</th>\n",
       "      <th>Comment</th>\n",
       "      <th>text_that_is_more_relevant_1</th>\n",
       "      <th>text_that_is_more_likely_helpful_1</th>\n",
       "      <th>text_that_is_more_fluent_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>az4os4</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Do you have a graphics card installed?</td>\n",
       "      <td>What are you trying to achieve here?</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>reader_model_pred_text</td>\n",
       "      <td>text_only_model_pred_text</td>\n",
       "      <td>This is my first build and they are all brand ...</td>\n",
       "      <td>What are you trying to achieve here?</td>\n",
       "      <td>Do you have a graphics card installed?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>czgw6r</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Do you have the same problem in another system?</td>\n",
       "      <td>Do you have an Intel CPU?</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>text_only_model_pred_text</td>\n",
       "      <td>reader_model_pred_text</td>\n",
       "      <td>Hi guys, I recently faced a problem on Intel X...</td>\n",
       "      <td>Do you have the same problem in another system?</td>\n",
       "      <td>Do you have an Intel CPU?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aorth3</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Is it at 1080p or 1440p?</td>\n",
       "      <td>Does it do it at 1080 or 1440p?</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>text_only_model_pred_text</td>\n",
       "      <td>reader_model_pred_text</td>\n",
       "      <td>I seem to have a performance issue with Hitman...</td>\n",
       "      <td>Is it at 1080p or 1440p?</td>\n",
       "      <td>Does it do it at 1080 or 1440p?</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>same question</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agykvp</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Are you okay with that?</td>\n",
       "      <td>What are you going to be doing with the pc?</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>reader_model_pred_text</td>\n",
       "      <td>text_only_model_pred_text</td>\n",
       "      <td>Hello Everbody,   I want to build a new pc for...</td>\n",
       "      <td>What are you going to be doing with the pc?</td>\n",
       "      <td>Are you okay with that?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arenff</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>What's your temps like?</td>\n",
       "      <td>Do you have good airflow in your case?</td>\n",
       "      <td>&lt;EXPERT_PCT_0_AUTHOR&gt;</td>\n",
       "      <td>text_only_model_pred_text</td>\n",
       "      <td>reader_model_pred_text</td>\n",
       "      <td>I have one of those Intel Stock coolers, in a ...</td>\n",
       "      <td>What's your temps like?</td>\n",
       "      <td>Do you have good airflow in your case?</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id     subreddit                        text_only_model_pred_text  \\\n",
       "0     az4os4  pcmasterrace           Do you have a graphics card installed?   \n",
       "1     czgw6r  pcmasterrace  Do you have the same problem in another system?   \n",
       "2     aorth3  pcmasterrace                         Is it at 1080p or 1440p?   \n",
       "3     agykvp  pcmasterrace                          Are you okay with that?   \n",
       "4     arenff  pcmasterrace                          What's your temps like?   \n",
       "\n",
       "                        reader_model_pred_text       reader_token_str  \\\n",
       "0         What are you trying to achieve here?  <EXPERT_PCT_0_AUTHOR>   \n",
       "1                    Do you have an Intel CPU?  <EXPERT_PCT_0_AUTHOR>   \n",
       "2              Does it do it at 1080 or 1440p?  <EXPERT_PCT_0_AUTHOR>   \n",
       "3  What are you going to be doing with the pc?  <EXPERT_PCT_0_AUTHOR>   \n",
       "4       Do you have good airflow in your case?  <EXPERT_PCT_0_AUTHOR>   \n",
       "\n",
       "                    system_1                   system_2  \\\n",
       "0     reader_model_pred_text  text_only_model_pred_text   \n",
       "1  text_only_model_pred_text     reader_model_pred_text   \n",
       "2  text_only_model_pred_text     reader_model_pred_text   \n",
       "3     reader_model_pred_text  text_only_model_pred_text   \n",
       "4  text_only_model_pred_text     reader_model_pred_text   \n",
       "\n",
       "                                                post  \\\n",
       "0  This is my first build and they are all brand ...   \n",
       "1  Hi guys, I recently faced a problem on Intel X...   \n",
       "2  I seem to have a performance issue with Hitman...   \n",
       "3  Hello Everbody,   I want to build a new pc for...   \n",
       "4  I have one of those Intel Stock coolers, in a ...   \n",
       "\n",
       "                                        question_1  \\\n",
       "0             What are you trying to achieve here?   \n",
       "1  Do you have the same problem in another system?   \n",
       "2                         Is it at 1080p or 1440p?   \n",
       "3      What are you going to be doing with the pc?   \n",
       "4                          What's your temps like?   \n",
       "\n",
       "                               question_2  text_that_is_more_relevant_2  \\\n",
       "0  Do you have a graphics card installed?                             2   \n",
       "1               Do you have an Intel CPU?                             2   \n",
       "2         Does it do it at 1080 or 1440p?                             2   \n",
       "3                 Are you okay with that?                             1   \n",
       "4  Do you have good airflow in your case?                             1   \n",
       "\n",
       "   text_that_is_more_fluent_2  text_that_is_more_likely_helpful_2  \\\n",
       "0                           1                                   1   \n",
       "1                           1                                   2   \n",
       "2                           2                                   2   \n",
       "3                           1                                   1   \n",
       "4                           2                                   2   \n",
       "\n",
       "         Comment  text_that_is_more_relevant_1  \\\n",
       "0            NaN                             2   \n",
       "1            NaN                             2   \n",
       "2  same question                             1   \n",
       "3            NaN                             1   \n",
       "4            NaN                             2   \n",
       "\n",
       "   text_that_is_more_likely_helpful_1  text_that_is_more_fluent_1  \n",
       "0                                   1                           2  \n",
       "1                                   2                           2  \n",
       "2                                   1                           1  \n",
       "3                                   1                           1  \n",
       "4                                   2                           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>group_1</th>\n",
       "      <th>group_2</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>post</th>\n",
       "      <th>group_type</th>\n",
       "      <th>group_type_choices</th>\n",
       "      <th>question_1_group_label_2</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>comments</th>\n",
       "      <th>question_1_group_label_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bg2q51</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>expert</td>\n",
       "      <td>non-expert</td>\n",
       "      <td>real</td>\n",
       "      <td>What storage do you have?</td>\n",
       "      <td>This is going to sound ridiculous, but have yo...</td>\n",
       "      <td>So first off, I'm running an i5-7500, GTX1070,...</td>\n",
       "      <td>EXPERT</td>\n",
       "      <td>expert vs. novice</td>\n",
       "      <td>expert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>novice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clojsj</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>non-expert</td>\n",
       "      <td>expert</td>\n",
       "      <td>real</td>\n",
       "      <td>Is the graphics card getting enough airflow?</td>\n",
       "      <td>Did you change nvidia driver settings to displ...</td>\n",
       "      <td>I'm running the following and am unhappy with ...</td>\n",
       "      <td>EXPERT</td>\n",
       "      <td>expert vs. novice</td>\n",
       "      <td>non-expert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>novice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d8yjen</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>expert</td>\n",
       "      <td>non-expert</td>\n",
       "      <td>real</td>\n",
       "      <td>That may be an option instead of you paying to...</td>\n",
       "      <td>Hungarian here, I'm dropping my tuf505 for ser...</td>\n",
       "      <td>Just a few weeks ago I had an ROG STRIX 1070Ti...</td>\n",
       "      <td>EXPERT</td>\n",
       "      <td>expert vs. novice</td>\n",
       "      <td>non-expert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>expert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8mz1o1</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>high</td>\n",
       "      <td>slow</td>\n",
       "      <td>real</td>\n",
       "      <td>Is that temp changing at all?</td>\n",
       "      <td>What system is that, what motherboard with whi...</td>\n",
       "      <td>hey i'm in need of some helpi have a beefy pc ...</td>\n",
       "      <td>TIME</td>\n",
       "      <td>fast response vs. slow response</td>\n",
       "      <td>fast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8uajem</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>slow</td>\n",
       "      <td>high</td>\n",
       "      <td>real</td>\n",
       "      <td>Have you tried power cycling the monitor?</td>\n",
       "      <td>What do you mean the RAM was in the wrong way?</td>\n",
       "      <td>Hello, I was curious as to what kind of stuff ...</td>\n",
       "      <td>TIME</td>\n",
       "      <td>fast response vs. slow response</td>\n",
       "      <td>slow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id     subreddit     group_1     group_2 question_type  \\\n",
       "0     bg2q51  pcmasterrace      expert  non-expert          real   \n",
       "1     clojsj  pcmasterrace  non-expert      expert          real   \n",
       "2     d8yjen  pcmasterrace      expert  non-expert          real   \n",
       "3     8mz1o1  pcmasterrace        high        slow          real   \n",
       "4     8uajem  pcmasterrace        slow        high          real   \n",
       "\n",
       "                                          question_1  \\\n",
       "0                          What storage do you have?   \n",
       "1       Is the graphics card getting enough airflow?   \n",
       "2  That may be an option instead of you paying to...   \n",
       "3                      Is that temp changing at all?   \n",
       "4          Have you tried power cycling the monitor?   \n",
       "\n",
       "                                          question_2  \\\n",
       "0  This is going to sound ridiculous, but have yo...   \n",
       "1  Did you change nvidia driver settings to displ...   \n",
       "2  Hungarian here, I'm dropping my tuf505 for ser...   \n",
       "3  What system is that, what motherboard with whi...   \n",
       "4     What do you mean the RAM was in the wrong way?   \n",
       "\n",
       "                                                post group_type  \\\n",
       "0  So first off, I'm running an i5-7500, GTX1070,...     EXPERT   \n",
       "1  I'm running the following and am unhappy with ...     EXPERT   \n",
       "2  Just a few weeks ago I had an ROG STRIX 1070Ti...     EXPERT   \n",
       "3  hey i'm in need of some helpi have a beefy pc ...       TIME   \n",
       "4  Hello, I was curious as to what kind of stuff ...       TIME   \n",
       "\n",
       "                group_type_choices question_1_group_label_2  Unnamed: 8  \\\n",
       "0                expert vs. novice                   expert         NaN   \n",
       "1                expert vs. novice               non-expert         NaN   \n",
       "2                expert vs. novice               non-expert         NaN   \n",
       "3  fast response vs. slow response                     fast         NaN   \n",
       "4  fast response vs. slow response                     slow         NaN   \n",
       "\n",
       "  comments question_1_group_label_1  \n",
       "0      NaN                   novice  \n",
       "1      NaN                   novice  \n",
       "2      NaN                   expert  \n",
       "3      NaN                     fast  \n",
       "4      NaN                     slow  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## reshape data\n",
    "text_quality_data_cols = ['article_id', 'subreddit', 'text_only_model_pred_text', 'reader_model_pred_text', 'reader_token_str', 'system_1', 'system_2']\n",
    "clean_text_quality_data = pd.merge(\n",
    "    text_quality_data.loc[:, text_quality_data_cols],\n",
    "    text_quality_annotation_data, on=['article_id', 'subreddit'],\n",
    ")\n",
    "reader_group_data_cols = ['article_id', 'subreddit', 'group_1', 'group_2', 'question_type', 'question_1', 'question_2']\n",
    "clean_reader_group_data = pd.merge(\n",
    "    reader_group_data.loc[:, reader_group_data_cols],\n",
    "    reader_group_annotation_data, on=['article_id', 'subreddit', 'question_1', 'question_2'],\n",
    ")\n",
    "display(clean_text_quality_data.head())\n",
    "display(clean_reader_group_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the text quality data, how well do the two systems compare with one another in terms of fluency, etc.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom_test\n",
    "def get_aggregate_label_counts(data, label_cols=[]):\n",
    "    label_counts = []\n",
    "    for col_i in label_cols:\n",
    "        label_cols_i = list(filter(lambda x: col_i in x, data.columns))\n",
    "        combined_labels_i = []\n",
    "        for label_col_j in label_cols_i:\n",
    "            # get name of system that matches question chosen\n",
    "            labels_j = data.apply(lambda x: x.loc[f'system_{x.loc[label_col_j]}'], axis=1)\n",
    "            combined_labels_i += labels_j.values.tolist()\n",
    "        combined_label_counts_i = pd.Series(combined_labels_i).value_counts()\n",
    "        combined_label_pct_i = combined_label_counts_i / combined_label_counts_i.sum()\n",
    "        combined_label_pct_i.loc['label_type'] = col_i\n",
    "        combined_label_pct_i.loc['N'] = len(combined_labels_i)\n",
    "        # test for significance lol\n",
    "        p_val = binom_test(combined_label_counts_i.values, n=len(combined_labels_i))\n",
    "        combined_label_pct_i.loc['binom_test'] = p_val\n",
    "        label_counts.append(combined_label_pct_i)\n",
    "    label_counts = pd.concat(label_counts, axis=1).transpose()\n",
    "    return label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reader_model_pred_text</th>\n",
       "      <th>text_only_model_pred_text</th>\n",
       "      <th>label_type</th>\n",
       "      <th>N</th>\n",
       "      <th>binom_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>text_that_is_more_relevant</td>\n",
       "      <td>60</td>\n",
       "      <td>0.698883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>text_that_is_more_fluent</td>\n",
       "      <td>60</td>\n",
       "      <td>0.245061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.35</td>\n",
       "      <td>text_that_is_more_likely_helpful</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0273401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.411111</td>\n",
       "      <td>combined</td>\n",
       "      <td>180</td>\n",
       "      <td>0.020597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reader_model_pred_text text_only_model_pred_text  \\\n",
       "0               0.533333                  0.466667   \n",
       "1               0.583333                  0.416667   \n",
       "2                   0.65                      0.35   \n",
       "0               0.588889                  0.411111   \n",
       "\n",
       "                         label_type    N binom_test  \n",
       "0        text_that_is_more_relevant   60   0.698883  \n",
       "1          text_that_is_more_fluent   60   0.245061  \n",
       "2  text_that_is_more_likely_helpful   60  0.0273401  \n",
       "0                          combined  180   0.020597  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## compute aggregate counts for each system being chosen as \"better\"\n",
    "text_quality_label_cols = ['text_that_is_more_relevant', 'text_that_is_more_fluent', 'text_that_is_more_likely_helpful']\n",
    "text_quality_label_counts = get_aggregate_label_counts(clean_text_quality_data, label_cols=text_quality_label_cols)\n",
    "# get total stats\n",
    "model_cols = ['reader_model_pred_text', 'text_only_model_pred_text']\n",
    "N_total = text_quality_label_counts.loc[:, 'N'].sum()\n",
    "mean_choice_counts = text_quality_label_counts.apply(lambda x: x.loc[model_cols] * x.loc['N'], axis=1).sum(axis=0)\n",
    "mean_choice_pct = mean_choice_counts / N_total\n",
    "mean_choice_pct.loc['label_type'] = 'combined'\n",
    "mean_choice_pct.loc['N'] = N_total\n",
    "mean_choice_pct.loc['binom_test'] = binom_test(mean_choice_counts, N_total)\n",
    "text_quality_label_counts = text_quality_label_counts.append(pd.DataFrame(mean_choice_pct).transpose())\n",
    "display(text_quality_label_counts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! We see a slight preference for the reader-aware model overall, but no significant preference for `relevant` and `fluent` labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the reader group guessing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>group_1</th>\n",
       "      <th>group_2</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>post</th>\n",
       "      <th>group_type</th>\n",
       "      <th>group_type_choices</th>\n",
       "      <th>question_1_group_label_2</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>comments</th>\n",
       "      <th>question_1_group_label_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bg2q51</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>expert</td>\n",
       "      <td>non-expert</td>\n",
       "      <td>real</td>\n",
       "      <td>What storage do you have?</td>\n",
       "      <td>This is going to sound ridiculous, but have yo...</td>\n",
       "      <td>So first off, I'm running an i5-7500, GTX1070,...</td>\n",
       "      <td>EXPERT</td>\n",
       "      <td>expert vs. novice</td>\n",
       "      <td>expert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>novice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clojsj</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>non-expert</td>\n",
       "      <td>expert</td>\n",
       "      <td>real</td>\n",
       "      <td>Is the graphics card getting enough airflow?</td>\n",
       "      <td>Did you change nvidia driver settings to displ...</td>\n",
       "      <td>I'm running the following and am unhappy with ...</td>\n",
       "      <td>EXPERT</td>\n",
       "      <td>expert vs. novice</td>\n",
       "      <td>non-expert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>novice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d8yjen</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>expert</td>\n",
       "      <td>non-expert</td>\n",
       "      <td>real</td>\n",
       "      <td>That may be an option instead of you paying to...</td>\n",
       "      <td>Hungarian here, I'm dropping my tuf505 for ser...</td>\n",
       "      <td>Just a few weeks ago I had an ROG STRIX 1070Ti...</td>\n",
       "      <td>EXPERT</td>\n",
       "      <td>expert vs. novice</td>\n",
       "      <td>non-expert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>expert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8mz1o1</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>high</td>\n",
       "      <td>slow</td>\n",
       "      <td>real</td>\n",
       "      <td>Is that temp changing at all?</td>\n",
       "      <td>What system is that, what motherboard with whi...</td>\n",
       "      <td>hey i'm in need of some helpi have a beefy pc ...</td>\n",
       "      <td>TIME</td>\n",
       "      <td>fast response vs. slow response</td>\n",
       "      <td>fast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8uajem</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>slow</td>\n",
       "      <td>high</td>\n",
       "      <td>real</td>\n",
       "      <td>Have you tried power cycling the monitor?</td>\n",
       "      <td>What do you mean the RAM was in the wrong way?</td>\n",
       "      <td>Hello, I was curious as to what kind of stuff ...</td>\n",
       "      <td>TIME</td>\n",
       "      <td>fast response vs. slow response</td>\n",
       "      <td>slow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id     subreddit     group_1     group_2 question_type  \\\n",
       "0     bg2q51  pcmasterrace      expert  non-expert          real   \n",
       "1     clojsj  pcmasterrace  non-expert      expert          real   \n",
       "2     d8yjen  pcmasterrace      expert  non-expert          real   \n",
       "3     8mz1o1  pcmasterrace        high        slow          real   \n",
       "4     8uajem  pcmasterrace        slow        high          real   \n",
       "\n",
       "                                          question_1  \\\n",
       "0                          What storage do you have?   \n",
       "1       Is the graphics card getting enough airflow?   \n",
       "2  That may be an option instead of you paying to...   \n",
       "3                      Is that temp changing at all?   \n",
       "4          Have you tried power cycling the monitor?   \n",
       "\n",
       "                                          question_2  \\\n",
       "0  This is going to sound ridiculous, but have yo...   \n",
       "1  Did you change nvidia driver settings to displ...   \n",
       "2  Hungarian here, I'm dropping my tuf505 for ser...   \n",
       "3  What system is that, what motherboard with whi...   \n",
       "4     What do you mean the RAM was in the wrong way?   \n",
       "\n",
       "                                                post group_type  \\\n",
       "0  So first off, I'm running an i5-7500, GTX1070,...     EXPERT   \n",
       "1  I'm running the following and am unhappy with ...     EXPERT   \n",
       "2  Just a few weeks ago I had an ROG STRIX 1070Ti...     EXPERT   \n",
       "3  hey i'm in need of some helpi have a beefy pc ...       TIME   \n",
       "4  Hello, I was curious as to what kind of stuff ...       TIME   \n",
       "\n",
       "                group_type_choices question_1_group_label_2  Unnamed: 8  \\\n",
       "0                expert vs. novice                   expert         NaN   \n",
       "1                expert vs. novice               non-expert         NaN   \n",
       "2                expert vs. novice               non-expert         NaN   \n",
       "3  fast response vs. slow response                     fast         NaN   \n",
       "4  fast response vs. slow response                     slow         NaN   \n",
       "\n",
       "  comments question_1_group_label_1  \n",
       "0      NaN                   novice  \n",
       "1      NaN                   novice  \n",
       "2      NaN                   expert  \n",
       "3      NaN                     fast  \n",
       "4      NaN                     slow  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_reader_group_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group type | # correct | # incorrect | text type (real/generated)\n",
    "from scipy.stats import binom_test\n",
    "def get_guess_pct_data(data, label_cols):\n",
    "    combined_label_guesses = []\n",
    "    for label_col_i in label_cols:\n",
    "        label_guesses_i = (data.loc[:, 'group_1']==data.loc[:, label_col_i]).astype(int)\n",
    "        combined_label_guesses += label_guesses_i.values.tolist()\n",
    "    ## get aggregate T/F guess counts\n",
    "    combined_label_guess_counts = pd.Series(combined_label_guesses).value_counts()\n",
    "    combined_label_guess_pct = combined_label_guess_counts / combined_label_guess_counts.sum()\n",
    "    combined_label_guess_pct.loc['N'] = len(combined_label_guesses)\n",
    "    # binom test\n",
    "    p_val = binom_test(combined_label_guess_counts.values, n=len(combined_label_guess_counts))\n",
    "    combined_label_guess_pct.loc['p_val'] = p_val\n",
    "    return combined_label_guess_pct\n",
    "def get_guess_counts_per_type(data, label_cols, type_var):\n",
    "    combined_label_guess_data = []\n",
    "    for group_i, data_i in data.groupby(type_var):\n",
    "        combined_label_guess_pct = get_guess_pct_data(data_i, label_cols)\n",
    "        combined_label_guess_pct.loc['type_val'] = group_i\n",
    "        combined_label_guess_pct.loc['type'] = type_var\n",
    "        combined_label_guess_data.append(combined_label_guess_pct)\n",
    "    combined_label_guess_data = pd.concat(combined_label_guess_data, axis=1).transpose().rename(columns={0:'wrong', 1:'right'})\n",
    "    return combined_label_guess_data\n",
    "def get_aggregate_guess_counts(data, label_col='question_1_group_label'):\n",
    "    label_cols = list(filter(lambda x: re.match(f'{label_col}_\\d', x), data.columns))\n",
    "    combined_label_guess_data = []\n",
    "    ## overall guesses\n",
    "    combined_label_guess_pct = get_guess_pct_data(data, label_cols)\n",
    "    # clean up\n",
    "    combined_label_guess_pct.loc['type'] = 'combined'\n",
    "    combined_label_guess_pct.loc['type_val'] = 'combined'\n",
    "    combined_label_guess_pct = pd.DataFrame(combined_label_guess_pct).transpose()\n",
    "    combined_label_guess_pct.rename(columns={0:'wrong', 1:'right'}, inplace=True)\n",
    "    ## guesses by reader group\n",
    "    reader_group_guess_count_data = get_guess_counts_per_type(data, label_cols, 'group_type')\n",
    "    ## guesses by question type\n",
    "    question_type_guess_count_data = get_guess_counts_per_type(data, label_cols, 'question_type')\n",
    "    combined_label_guess_data = [\n",
    "        combined_label_guess_pct,\n",
    "        reader_group_guess_count_data,\n",
    "        question_type_guess_count_data\n",
    "    ]\n",
    "    combined_label_guess_data = pd.concat(combined_label_guess_data, axis=0)\n",
    "    # sort columns\n",
    "    ordered_guess_cols = ['type', 'type_val', 'N', 'right', 'wrong', 'p_val']\n",
    "    combined_label_guess_data = combined_label_guess_data.loc[:, ordered_guess_cols]\n",
    "    return combined_label_guess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            type            type_val   N     right     wrong      p_val\n",
      "0       combined            combined  72  0.347222  0.652778  0.0127746\n",
      "0     group_type              EXPERT  12       0.5       0.5          1\n",
      "1     group_type                TIME  60  0.316667  0.683333  0.0062176\n",
      "0  question_type  author_token_model  36  0.388889  0.611111   0.242985\n",
      "1  question_type                real  36  0.305556  0.694444  0.0288167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-14478c8070d6>:23: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  combined_label_guess_data = pd.concat(combined_label_guess_data, axis=1).transpose().rename(columns={0:'wrong', 1:'right'})\n",
      "<ipython-input-41-14478c8070d6>:44: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  combined_label_guess_data = pd.concat(combined_label_guess_data, axis=0)\n"
     ]
    }
   ],
   "source": [
    "label_col = 'question_1_group_label'\n",
    "reader_group_guess_counts = get_aggregate_guess_counts(clean_reader_group_data, label_col=label_col)\n",
    "print(reader_group_guess_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! So overall the annotators did not do well on the task except for the `EXPERT` data and for the `author_token_model` data (less bad than `real` data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1, 300])\n",
      "torch.Size([1025, 1, 300])\n",
      "torch.Size([300, 1, 1024])\n"
     ]
    }
   ],
   "source": [
    "## tmp\n",
    "import torch\n",
    "input_dim = 1024\n",
    "embed_dim = 300\n",
    "fake_text_data = torch.Tensor(input_dim, embed_dim).unsqueeze(1)\n",
    "fake_author_data = torch.Tensor(1, embed_dim).unsqueeze(1)\n",
    "print(fake_text_data.shape)\n",
    "combine_network = torch.nn.Linear(input_dim+1, input_dim)\n",
    "fake_text_author_data = torch.cat([fake_text_data, fake_author_data])\n",
    "print(fake_text_author_data.shape)\n",
    "fake_output = combine_network(fake_text_author_data.squeeze(1).T).unsqueeze(1)\n",
    "print(fake_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect generated text data: expert vs non-expert\n",
    "For a pilot test, let's collect examples of questions from expert and non-expert authors to rate for fluency/coherence/utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ianbstew/miniconda3/envs/py3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3338: DtypeWarning: Columns (1,2,8,9,10,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "100%|██████████| 127373/127373 [01:21<00:00, 1562.79it/s]\n",
      "100%|██████████| 26913/26913 [00:14<00:00, 1794.35it/s]\n",
      "100%|██████████| 127373/127373 [01:25<00:00, 1494.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after paired sampling: question data has label distribution = 0.0      100636\n",
      "1.0      100636\n",
      "US         4306\n",
      "NONUS      4306\n",
      "Name: author_group, dtype: int64\n",
      "after paired sampling: question data has subreddit distribution = AmItheAsshole      160736\n",
      "personalfinance     20056\n",
      "Advice              12546\n",
      "legaladvice         11080\n",
      "pcmasterrace         5466\n",
      "Name: subreddit, dtype: int64\n",
      "(209884, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if('..' not in sys.path):\n",
    "    sys.path.append('..')\n",
    "from data_processing.data_helpers import load_sample_data\n",
    "sample_question_data = load_sample_data(sample_type='paired')\n",
    "print(sample_question_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## load generated data\n",
    "import gzip\n",
    "import torch\n",
    "test_data = torch.load('../../data/reddit_data/combined_data_test_data.pt')\n",
    "test_data = test_data.data.to_pandas()\n",
    "test_data = test_data.loc[:, ['article_id', 'question_id', 'author']]\n",
    "text_only_model_data = list(map(lambda x: x.strip(), gzip.open('../../data/reddit_data/text_only_model/test_data_sample_top_p=0.9_temperature=1.0_output_text.gz', 'rt')))[:len(test_data)]\n",
    "reader_model_data = list(map(lambda x: x.strip(), gzip.open('../../data/reddit_data/author_text_data/test_data_sample_top_p=0.9_temperature=1.0_output_text.gz', 'rt')))[:len(test_data)]\n",
    "test_data = test_data.assign(**{\n",
    "    'text_model' : text_only_model_data,\n",
    "    'reader_model' : reader_model_data,\n",
    "})\n",
    "test_data.rename(columns={'article_id' : 'parent_id'}, inplace=True)\n",
    "# combine with sample data\n",
    "import pandas as pd\n",
    "sample_data = pd.merge(sample_question_data, test_data, on=['question_id', 'parent_id', 'author'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# post | subreddit | expert Q (real) | expert Q (reader-attention model) | novice Q (reader-attention model) | Q (text-only model)\n",
    "import random\n",
    "random.seed(123)\n",
    "paired_group_data = []\n",
    "author_group_category_vals = {\n",
    "    'relative_time_bin' : [0, 1],\n",
    "    'expert_pct_bin' : [0, 1],\n",
    "    'location_region' : ['US', 'NONUS'],\n",
    "}\n",
    "num_group_vals = 2\n",
    "for (parent_id_i, group_category_i), data_i in sample_data.groupby(['parent_id', 'group_category']):\n",
    "    if(len(set(data_i.loc[:, 'author_group'].unique()) & set(author_group_category_vals[group_category_i]))==num_group_vals):\n",
    "        group_vals_i = author_group_category_vals[group_category_i]\n",
    "        random.shuffle(group_vals_i)\n",
    "        # randomly swap values for annotation!!\n",
    "        post_i = data_i.loc[:, 'post'].iloc[0]\n",
    "        text_output_i = data_i.loc[:, 'text_model'].iloc[0]\n",
    "        subreddit_i = data_i.loc[:, 'subreddit'].iloc[0]\n",
    "        paired_group_data_i = []\n",
    "        for j, group_val_j in enumerate(group_vals_i):\n",
    "            data_j = data_i[data_i.loc[:, 'author_group']==group_val_j].iloc[0, :]\n",
    "            # get real text, reader-aware text\n",
    "            paired_group_data_i.append(pd.Series([group_val_j, data_j.loc['reader_model'], data_j.loc['question'], data_j.loc['id']], index=[f'reader_group_{j+1}', f'reader_model_output_group_{j+1}', f'question_group_{j+1}', f'question_id_{j+1}']))\n",
    "        paired_group_data_i = pd.concat(paired_group_data_i, axis=0)\n",
    "        paired_group_data_i = paired_group_data_i.append(pd.Series([parent_id_i, post_i, subreddit_i, text_output_i, group_category_i], index=['post_id', 'post_text', 'subreddit', 'text_model_output', 'reader_group_category']))\n",
    "#         paired_group_data_i = paired_group_data_i.append(pd.Series(group_vals_i, index=[f'group_{x+1}' for x in range(len(group_vals_i))]))\n",
    "        paired_group_data.append(paired_group_data_i)\n",
    "paired_group_data = pd.concat(paired_group_data, axis=1).transpose()\n",
    "# add per-pair ID\n",
    "paired_group_data = paired_group_data.assign(**{\n",
    "    'pair_id' : paired_group_data.apply(lambda x: hash(x.loc['question_group_1']+x.loc['question_group_2']), axis=1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reader_group_1</th>\n",
       "      <th>reader_model_output_group_1</th>\n",
       "      <th>question_group_1</th>\n",
       "      <th>question_id_1</th>\n",
       "      <th>reader_group_2</th>\n",
       "      <th>reader_model_output_group_2</th>\n",
       "      <th>question_group_2</th>\n",
       "      <th>question_id_2</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text_model_output</th>\n",
       "      <th>reader_group_category</th>\n",
       "      <th>pair_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NONUS</td>\n",
       "      <td>INFO: is she paying rent?</td>\n",
       "      <td>Did you not get any of these offers/agreements...</td>\n",
       "      <td>dx9arkq</td>\n",
       "      <td>US</td>\n",
       "      <td>Here's a concise article on the topic: [What s...</td>\n",
       "      <td>Do you have documentation of the 10k/year?</td>\n",
       "      <td>dx9pbju</td>\n",
       "      <td>8bq34k</td>\n",
       "      <td>Orginally I was quoted a salary of 97k. I acce...</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Did you ever tell her that you were going to m...</td>\n",
       "      <td>location_region</td>\n",
       "      <td>2146274659287971115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>How old are you?</td>\n",
       "      <td>What is your current truck worth right now?</td>\n",
       "      <td>dz3kiw3</td>\n",
       "      <td>1</td>\n",
       "      <td>What do you mean by \"maxed out by the end of t...</td>\n",
       "      <td>You moved because your boyfriend got a job som...</td>\n",
       "      <td>dz2v4hu</td>\n",
       "      <td>8jvy48</td>\n",
       "      <td>June 2016 I bought a new truck, I didn't like ...</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Is there a way you can get out of your parents...</td>\n",
       "      <td>expert_pct_bin</td>\n",
       "      <td>-858238340043718643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>How old are you?</td>\n",
       "      <td>What is your current truck worth right now?</td>\n",
       "      <td>dz3kiw3</td>\n",
       "      <td>0</td>\n",
       "      <td>What do you mean by \"maxed out by the end of t...</td>\n",
       "      <td>You moved because your boyfriend got a job som...</td>\n",
       "      <td>dz2v4hu</td>\n",
       "      <td>8jvy48</td>\n",
       "      <td>June 2016 I bought a new truck, I didn't like ...</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Is there a way you can get out of your parents...</td>\n",
       "      <td>relative_time_bin</td>\n",
       "      <td>-858238340043718643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Have you checked if the monitor is plugged int...</td>\n",
       "      <td>Are you paying for insurance that you don't ne...</td>\n",
       "      <td>dz6l00q</td>\n",
       "      <td>1</td>\n",
       "      <td>Also, do you know if your husband is still in ...</td>\n",
       "      <td>Which phone carrier do you currently have?</td>\n",
       "      <td>dz5q8vo</td>\n",
       "      <td>8k8bqm</td>\n",
       "      <td>My credit isn't great and I pay nearly 300 a m...</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Does the monitor have any beep codes?</td>\n",
       "      <td>expert_pct_bin</td>\n",
       "      <td>170855644871119080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Have you checked if the monitor is plugged int...</td>\n",
       "      <td>Are you paying for insurance that you don't ne...</td>\n",
       "      <td>dz6l00q</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know the name of the account, but sure...</td>\n",
       "      <td>Are there any opportunities to increase wages?</td>\n",
       "      <td>dz5p42x</td>\n",
       "      <td>8k8bqm</td>\n",
       "      <td>My credit isn't great and I pay nearly 300 a m...</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Does the monitor have any beep codes?</td>\n",
       "      <td>relative_time_bin</td>\n",
       "      <td>3624212230905290669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reader_group_1                        reader_model_output_group_1  ... reader_group_category              pair_id\n",
       "0          NONUS                          INFO: is she paying rent?  ...       location_region  2146274659287971115\n",
       "1              0                                   How old are you?  ...        expert_pct_bin  -858238340043718643\n",
       "2              1                                   How old are you?  ...     relative_time_bin  -858238340043718643\n",
       "3              0  Have you checked if the monitor is plugged int...  ...        expert_pct_bin   170855644871119080\n",
       "4              1  Have you checked if the monitor is plugged int...  ...     relative_time_bin  3624212230905290669\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(paired_group_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's organize this into annotation-friendly format for Qualtrics:\n",
    "\n",
    "- post\n",
    "\n",
    "`{post text}`\n",
    "\n",
    "- question quality annotation\n",
    "\n",
    "```\n",
    "[[Question:Matrix]]\n",
    "1. {question text}\n",
    "\n",
    "[[Choices]]\n",
    "ma Coherent\n",
    "mb Fluent\n",
    "mc Answerable\n",
    "\n",
    "[[Answers]]\n",
    "m1 Very\n",
    "m2 Somewhat\n",
    "m3 Neutral\n",
    "m4 Not very\n",
    "m5 Not at all\n",
    "```\n",
    "\n",
    "- question reader group comparison\n",
    "\n",
    "```\n",
    "[[Question:MC]]\n",
    "2. \n",
    "Q1: {question1 text}\n",
    "Q2: {question2 text}\n",
    "Which question was more likely written by a {group1} reader?\n",
    "\n",
    "[[Choices]]\n",
    "a Q1\n",
    "b Q2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "DEFAULT_GROUP_VAL_LOOKUP = {\n",
    "    'location_region' : 'US',\n",
    "    'expert_pct_bin' : 1,\n",
    "    'relative_time_bin' : 1,\n",
    "}\n",
    "DEFAULT_GROUP_VAL_NAME_LOOKUP = {\n",
    "    'location_region' : 'US',\n",
    "    'expert_pct_bin' : 'expert',\n",
    "    'relative_time_bin' : 'slow-response',\n",
    "}\n",
    "GROUP_VAL_ALL_NAME_LOOKUP = {\n",
    "    'location_region' : ['NONUS', 'US'],\n",
    "    'expert_pct_bin' : ['novice', 'expert'],\n",
    "    'relative_time_bin' : ['fast-response', 'slow-response']\n",
    "    \n",
    "}\n",
    "def convert_question_data_to_txt(data, question_vals=['question_group', 'reader_model_output_group'], question_num=1):\n",
    "    text = [f\"\"\"\n",
    "    [[Question:DB]]\n",
    "    Please read the following post and first rate the questions that follow the post according to how (1) coherent, (2) fluent, and (3) answerable you believe that they are.\n",
    "    Next, read two additional questions and determine who wrote the questions.<br></br>\n",
    "    \n",
    "    Post:\\n\\n{data.loc['post_text']}\n",
    "    \"\"\"]\n",
    "    all_question_vals = ['text_model_output'] + [f'{q}_{question_num}' for q in question_vals]\n",
    "    # shuffle order\n",
    "    \n",
    "    combined_question_id = ','.join(data.loc[['question_id_1', 'question_id_2']].values)\n",
    "    reader_group_category = data.loc['reader_group_category']\n",
    "    question_id_base = f'post={data.loc[\"post_id\"]}_question={combined_question_id}_group={reader_group_category}_'\n",
    "    # question quality\n",
    "    q_ctr = 1\n",
    "    for i, question_val_i in enumerate(all_question_vals):\n",
    "        question_txt_i = f\"\"\"\n",
    "        [[Question:Matrix]]\n",
    "        [[ID:{question_id_base+'question='+question_val_i+'_quality_'+str(i+1)}]]\n",
    "        {q_ctr}. {data.loc[question_val_i]}\n",
    "        \n",
    "        [[Choices]]\n",
    "        Coherent\n",
    "        Fluent\n",
    "        Answerable\n",
    "        \n",
    "        [[Answers]]\n",
    "        Very\n",
    "        Somewhat\n",
    "        Neutral\n",
    "        Not very\n",
    "        Not at all\n",
    "        \"\"\"\n",
    "        text.append(question_txt_i)\n",
    "        q_ctr += 1\n",
    "    # reader groups\n",
    "    num_reader_groups = 2\n",
    "    default_group_val = DEFAULT_GROUP_VAL_LOOKUP[reader_group_category]\n",
    "    default_group_val_name = DEFAULT_GROUP_VAL_NAME_LOOKUP[reader_group_category]\n",
    "    group_val_names = GROUP_VAL_ALL_NAME_LOOKUP[reader_group_category]\n",
    "    reader_group_question_txt = f\"\"\"\n",
    "    [[Question:MC]]\n",
    "    [[ID:{question_id_base+'group'}]]\n",
    "    {q_ctr}. One of the following questions was written by a {group_val_names[0]} reader and the other question was written by a {group_val_names[1]} reader.\n",
    "    Which question is more likely to be written by a ***{default_group_val_name} reader?***\n",
    "    \n",
    "    [[Choices]]\n",
    "    \"\"\"\n",
    "    for i in range(1, num_reader_groups+1):\n",
    "        reader_group_question_txt += f\"\"\"\n",
    "        Q{i}: {data.loc['reader_model_output_group_'+str(i)]}\"\"\"\n",
    "    text.append(reader_group_question_txt)\n",
    "    text = ''.join(text)\n",
    "    text = re.sub('(?<=\\n)( ){3,}', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[Question:DB]]\n",
      "Please read the following post and first rate the questions that follow the post according to how (1) coherent, (2) fluent, and (3) answerable you believe that they are.\n",
      "Next, read two additional questions and determine who wrote the questions.<br></br>\n",
      "\n",
      "Post:\n",
      "\n",
      "Orginally I was quoted a salary of 97k. I accepted. Later, in an email, I was told that was a mistake and that my actual salary would be around 75k. They said \"I hope this doesnt impact your decision to work for us\". \n",
      "\n",
      "I told them it did impact my decision. I told them this was my dream job but that I have offers for up 120k so I am definitely not accepting 75k.  Finally after much negotiation, we settled on a salary of $94k and $10k per year student loan repayment (for up to 60k for 6 years). \n",
      "\n",
      "Now, months later, I am filling out the loan repayment paper work and the HR lady emails me again saying they made a mistake and that after reivenstigation of policies the student loan repayment is only going to be a TOTAL of 10k over 3 years. And the full 60k will not be reached until 8 years. \n",
      "\n",
      "How should I respond to the email if this is not okay with me? Are all these changes red flags? Should I pick a different place to work? \n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=8bq34k_question=dx9arkq,dx9pbju_group=location_region_question=text_model_output_quality_1]]\n",
      "1. Did you ever tell her that you were going to move out at the same time?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=8bq34k_question=dx9arkq,dx9pbju_group=location_region_question=question_group_1_quality_2]]\n",
      "2. Did you not get any of these offers/agreements in writing?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=8bq34k_question=dx9arkq,dx9pbju_group=location_region_question=reader_model_output_group_1_quality_3]]\n",
      "3. INFO: is she paying rent?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:MC]]\n",
      "[[ID:post=8bq34k_question=dx9arkq,dx9pbju_group=location_region_group]]\n",
      "4. One of the following questions was written by a NONUS reader and the other question was written by a US reader.\n",
      "Which question is more likely to be written by a ***US reader?***\n",
      "\n",
      "[[Choices]]\n",
      "\n",
      "Q1: INFO: is she paying rent?\n",
      "Q2: Here's a concise article on the topic: [What should I invest in?\n"
     ]
    }
   ],
   "source": [
    "print(convert_question_data_to_txt(paired_group_data.iloc[0, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's organize these into blocks according to subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_question_txt_by_subreddit(data):\n",
    "    subreddit_txt = []\n",
    "    for subreddit_i, data_i in data.groupby('subreddit'):\n",
    "        subreddit_question_data_i = data_i.apply(lambda x: convert_question_data_to_txt(x), axis=1).values\n",
    "        subreddit_question_data_txt_i = '[[AdvancedFormat]]'\n",
    "        subreddit_question_data_txt_i = '\\n'.join([\n",
    "            subreddit_question_data_txt_i,\n",
    "            '\\n\\n[[PageBreak]]\\n\\n'.join(subreddit_question_data_i),\n",
    "        ])\n",
    "        subreddit_question_data_txt_i = '\\n'.join([\n",
    "            f'[[Block:subreddit={subreddit_i}]]', \n",
    "            subreddit_question_data_txt_i],\n",
    "        )\n",
    "        subreddit_txt.append([subreddit_i, subreddit_question_data_txt_i])\n",
    "    subreddits, subreddit_question_data_txt = zip(*subreddit_txt)\n",
    "    return subreddits, subreddit_question_data_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "personalfinance    10\n",
       "legaladvice        10\n",
       "pcmasterrace       10\n",
       "AmItheAsshole      10\n",
       "Advice             10\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_data.loc[:, 'subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to expert data for simplicity\n",
    "reader_group_category = 'expert_pct_bin'\n",
    "expert_paired_group_data = paired_group_data[paired_group_data.loc[:, 'reader_group_category']==reader_group_category]\n",
    "## sample data per subreddit\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "sample_size = 10\n",
    "annotation_data = []\n",
    "for subreddit_i, data_i in expert_paired_group_data.groupby('subreddit'):\n",
    "    data_i = data_i.loc[np.random.choice(data_i.index, sample_size, replace=(data_i.shape[0] < sample_size))]\n",
    "    annotation_data.append(data_i)\n",
    "annotation_data = pd.concat(annotation_data, axis=0)\n",
    "data_subreddits, data_subreddit_txt = group_question_txt_by_subreddit(annotation_data)\n",
    "## write everything\n",
    "import os\n",
    "out_dir = '../../data/reddit_data/annotation_data/generated_text_evaluation/compare_model_output/'\n",
    "annotation_data_out_file = os.path.join(out_dir, f'reader_group={reader_group_category}_annotation_data.tsv')\n",
    "annotation_data.to_csv(annotation_data_out_file, sep='\\t', index=False)\n",
    "for subreddit_i, data_txt_i in zip(data_subreddits, data_subreddit_txt):\n",
    "    txt_out_file_i = os.path.join(out_dir, f'subreddit={subreddit_i}_reader_group={reader_group_category}_qualtrics_survey.txt')\n",
    "    with open(txt_out_file_i, 'w') as txt_out_i:\n",
    "        txt_out_i.write(data_txt_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Block:subreddit=Advice]]\n",
      "[[AdvancedFormat]]\n",
      "\n",
      "[[Question:DB]]\n",
      "Please read the following post and first rate the questions that follow the post according to how (1) coherent, (2) fluent, and (3) answerable you believe that they are.\n",
      "Next, read two additional questions and determine who wrote the questions.<br></br>\n",
      "\n",
      "Post:\n",
      "\n",
      "I have been unschooled my entire life because my parents thought they could handle educating me. However that didnt ever happen so now i have about 2 months to prepare with little to no education other than little things ive learned here and there how should i prepare academicly/mentaly. Like what basics do i need to know or ill be screwed\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=c2s45v_question=ermm0s8,ern7pfd_group=expert_pct_bin_question=text_model_output_quality_1]]\n",
      "1. How much is the car worth?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=c2s45v_question=ermm0s8,ern7pfd_group=expert_pct_bin_question=question_group_1_quality_2]]\n",
      "2. Your entire life homeschooled?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=c2s45v_question=ermm0s8,ern7pfd_group=expert_pct_bin_question=reader_model_output_group_1_quality_3]]\n",
      "3. NTA - what is her interest rate on this car payment?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:MC]]\n",
      "[[ID:post=c2s45v_question=ermm0s8,ern7pfd_group=expert_pct_bin_group]]\n",
      "4. One of the following questions was written by a novice reader and the other question was written by a expert reader.\n",
      "Which question is more likely to be written by a ***expert reader?***\n",
      "\n",
      "[[Choices]]\n",
      "\n",
      "Q1: NTA - what is her interest rate on this car payment?\n",
      "Q2: How is that a bad thing?\n",
      "\n",
      "[[PageBreak]]\n",
      "\n",
      "\n",
      "[[Question:DB]]\n",
      "Please read the following post and first rate the questions that follow the post according to how (1) coherent, (2) fluent, and (3) answerable you believe that they are.\n",
      "Next, read two additional questions and determine who wrote the questions.<br></br>\n",
      "\n",
      "Post:\n",
      "\n",
      "Here is a photo of it, I think it's chalkboard paint. I'm afraid to do anything to it because I might damage it. But I know if I don't, it will fade in time. https://imgur.com/a/kfOgPcB \n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=akc803_question=ef3r6gn,ef3kimo_group=expert_pct_bin_question=text_model_output_quality_1]]\n",
      "1. Did he ever pay it?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=akc803_question=ef3r6gn,ef3kimo_group=expert_pct_bin_question=question_group_1_quality_2]]\n",
      "2. Can it be cut out and framed?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=akc803_question=ef3r6gn,ef3kimo_group=expert_pct_bin_question=reader_model_output_group_1_quality_3]]\n",
      "3. When you replaced the graphics card, did you use the new drive's OS?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:MC]]\n",
      "[[ID:post=akc803_question=ef3r6gn,ef3kimo_group=expert_pct_bin_group]]\n",
      "4. One of the following questions was written by a novice reader and the other question was written by a expert reader.\n",
      "Which question is more likely to be written by a ***expert reader?***\n",
      "\n",
      "[[Choices]]\n",
      "\n",
      "Q1: When you replaced the graphics card, did you use the new drive's OS?\n",
      "Q2: I'm not sure how much that would cost... is it possible to just pay it off and never have to use it again?\n",
      "\n",
      "[[PageBreak]]\n",
      "\n",
      "\n",
      "[[Question:DB]]\n",
      "Please read the following post and first rate the questions that follow the post according to how (1) coherent, (2) fluent, and (3) answerable you believe that they are.\n",
      "Next, read two additional questions and determine who wrote the questions.<br></br>\n",
      "\n",
      "Post:\n",
      "\n",
      "Considering how many milestones of normal person life I missed out on, how much normalcy can I achieve? What could possibly make up for a life this wasted? Ordinarily people look back on their lives and whatever they committed the most time to, they do that. For instance, maybe if I had spent the last 20 years pursuing career advancement, even if I was a 46 year old virgin I could say \"But in exchange for sex, you've earned 20 years of pure career advancement! You couldn't have done that if you had sex!\" But then again, there's only so far you can advance in any given career. Unless I change jobs, I think I've hit my dead end. \n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      "Some people say \"Make a bucket list and achieve that.\" But what I want is to be normal. And to be normal I would have to turn back time and go through normal person milestones. And I can't do that. So what's the best possible like I *can* have?\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=cb4xn2_question=etespep,etd8dqu_group=expert_pct_bin_question=text_model_output_quality_1]]\n",
      "1. Are you renting a single room, or are you renting the entire place?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=cb4xn2_question=etespep,etd8dqu_group=expert_pct_bin_question=question_group_1_quality_2]]\n",
      "2. Are you enrolled in any classes?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=cb4xn2_question=etespep,etd8dqu_group=expert_pct_bin_question=reader_model_output_group_1_quality_3]]\n",
      "3. Are you renting a single room, or are you renting the entire place?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:MC]]\n",
      "[[ID:post=cb4xn2_question=etespep,etd8dqu_group=expert_pct_bin_group]]\n",
      "4. One of the following questions was written by a novice reader and the other question was written by a expert reader.\n",
      "Which question is more likely to be written by a ***expert reader?***\n",
      "\n",
      "[[Choices]]\n",
      "\n",
      "Q1: Are you renting a single room, or are you renting the entire place?\n",
      "Q2: Does your landlord have a written lease of any kind?\n",
      "\n",
      "[[PageBreak]]\n",
      "\n",
      "\n",
      "[[Question:DB]]\n",
      "Please read the following post and first rate the questions that follow the post according to how (1) coherent, (2) fluent, and (3) answerable you believe that they are.\n",
      "Next, read two additional questions and determine who wrote the questions.<br></br>\n",
      "\n",
      "Post:\n",
      "\n",
      "So In 2016 I got married to someone I’ve known since middle school. Well I was in the military and found out I was deploying during the time we initially planned to get married so we moved it up and just got married in a courthouse in March of 2016. Well while I was deployed she found a dog she wanted to get in a different state which was actually near her hometown. Well she has always had family problems but her ex’s mom and her had a good relationship so she just decided to stay with her during her visit to get the dog and visit friends. Well her ex stayed there a night while she stayed there. (He was living with his dad) well one night she was taking a shower and he went in and he wanted to have sex with her. Well she ended up letting him do it. She tells me it’s because she was scared he would get mad. And at this time I was deployed on the other side of the world. She waited a week to tell me. And since then even after I’ve tried talking to her about it. I just can’t seem to get over it. I told her to tell the cops or something but she refused. They are still friends but don’t ever hang out. I just can’t seem to feel like it’s entirely accurate that she didn’t want him to but I wasn’t there so I can’t be 100% sure... and it still ticks me off and makes me depressed sometimes. I just can’t seem to get over it and I don’t want to bring it up to tell her it hurts cuz she will get mad. I just don’t know how to go about trying to forget about it entirely\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=aoez3s_question=eg17dn8,eg0oq7g_group=expert_pct_bin_question=text_model_output_quality_1]]\n",
      "1. What is the notice number, identified in the upper right corner of page one?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=aoez3s_question=eg17dn8,eg0oq7g_group=expert_pct_bin_question=question_group_1_quality_2]]\n",
      "2. If it was against her will, why are they still friends?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=aoez3s_question=eg17dn8,eg0oq7g_group=expert_pct_bin_question=reader_model_output_group_1_quality_3]]\n",
      "3. What is the notice number, identified in the upper right corner of page one?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:MC]]\n",
      "[[ID:post=aoez3s_question=eg17dn8,eg0oq7g_group=expert_pct_bin_group]]\n",
      "4. One of the following questions was written by a novice reader and the other question was written by a expert reader.\n",
      "Which question is more likely to be written by a ***expert reader?***\n",
      "\n",
      "[[Choices]]\n",
      "\n",
      "Q1: What is the notice number, identified in the upper right corner of page one?\n",
      "Q2: Why are they doing this?\n",
      "\n",
      "[[PageBreak]]\n",
      "\n",
      "\n",
      "[[Question:DB]]\n",
      "Please read the following post and first rate the questions that follow the post according to how (1) coherent, (2) fluent, and (3) answerable you believe that they are.\n",
      "Next, read two additional questions and determine who wrote the questions.<br></br>\n",
      "\n",
      "Post:\n",
      "\n",
      "So my dad has been yelling for the past year at my mom because as he says, and i quote, she doesnt fulfill his needs anymore. They are fighting every night and the past month it has gotten worse, I cant get enough sleep because they are up all night fighting and he is yelling at her all the time while she tries to calm him. I get panic attacks almost every night because I am crying so hard that i cant breath from hearing what he is saying to her and calling her names. I really disspise him. He is abusive(verbally only) towards my mom and I dont know how to handle it. I have exams atm and I cant concentrate cause its the only thing I am thinking about and i dont get enough sleep so i feel tired at the morning when i go to take my exams. Also, they keep fighting  throughout the day, making it hard for me to study. My mom doesnt deserve this kind of treatment and I hate seeing her like this. I feel like the age gap is what causes this as my mom is going though menopause which leads to lack of sexual desire, unlike my dad. \n",
      "•\n",
      "•\n",
      "•\n",
      "I could really use some advise or support as I dont feel comfortable talking about this to my friends or my boyfriend. I feel like I'm going to explode because of how many things I keep inside me. This is the first time I had it out of my chest.\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=bu0u9d_question=ep5ihgn,ep5f2pn_group=expert_pct_bin_question=text_model_output_quality_1]]\n",
      "1. How are you paying for the program?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=bu0u9d_question=ep5ihgn,ep5f2pn_group=expert_pct_bin_question=question_group_1_quality_2]]\n",
      "2. I understand she may be menopausal and her libido has gone down but what efforts is she making to show him that she loves and desires him?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=bu0u9d_question=ep5ihgn,ep5f2pn_group=expert_pct_bin_question=reader_model_output_group_1_quality_3]]\n",
      "3. Have they asked you to help them?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:MC]]\n",
      "[[ID:post=bu0u9d_question=ep5ihgn,ep5f2pn_group=expert_pct_bin_group]]\n",
      "4. One of the following questions was written by a novice reader and the other question was written by a expert reader.\n",
      "Which question is more likely to be written by a ***expert reader?***\n",
      "\n",
      "[[Choices]]\n",
      "\n",
      "Q1: Have they asked you to help them?\n",
      "Q2: Is it even worth paying all that money back?\n",
      "\n",
      "[[PageBreak]]\n",
      "\n",
      "\n",
      "[[Question:DB]]\n",
      "Please read the following post and first rate the questions that follow the post according to how (1) coherent, (2) fluent, and (3) answerable you believe that they are.\n",
      "Next, read two additional questions and determine who wrote the questions.<br></br>\n",
      "\n",
      "Post:\n",
      "\n",
      "So I'll try to keep this short. My grandpa was diagnosed with cancer a couple of months ago and he has started the treatments after a surgery, he is exactly as he was, joyful and fun. But soon he'll start the treatments that really make you sick and I want to do anything I can to help him. I know that cannabis doesn't cure cancer, but it could help with the nausea, pain and help him eat more if he loses his appetite. I'm pretty certain that he hasn't done any drugs in the past and he's pretty oldschool. How can I suggest weed to him? Obviously I would buy it for him etc.\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=ajdnf6_question=eevjda2,eevoacf_group=expert_pct_bin_question=text_model_output_quality_1]]\n",
      "1. What is your goal?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=ajdnf6_question=eevjda2,eevoacf_group=expert_pct_bin_question=question_group_1_quality_2]]\n",
      "2. How old was he when Woodstock happened?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=ajdnf6_question=eevjda2,eevoacf_group=expert_pct_bin_question=reader_model_output_group_1_quality_3]]\n",
      "3. What's your current rent?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:MC]]\n",
      "[[ID:post=ajdnf6_question=eevjda2,eevoacf_group=expert_pct_bin_group]]\n",
      "4. One of the following questions was written by a novice reader and the other question was written by a expert reader.\n",
      "Which question is more likely to be written by a ***expert reader?***\n",
      "\n",
      "[[Choices]]\n",
      "\n",
      "Q1: What's your current rent?\n",
      "Q2: Why do you want to quit?\n",
      "\n",
      "[[PageBreak]]\n",
      "\n",
      "\n",
      "[[Question:DB]]\n",
      "Please read the following post and first rate the questions that follow the post according to how (1) coherent, (2) fluent, and (3) answerable you believe that they are.\n",
      "Next, read two additional questions and determine who wrote the questions.<br></br>\n",
      "\n",
      "Post:\n",
      "\n",
      "Today, I was on an outing with a girl. A friend of mine. We both like each other, but don't want a relationship. Today, the scene was good and we started making out. It was my first time kissing a girl and fondling her breasts, but I didn't feel anything magical. My dick was hard, but that's all. Nothing. Now, after a few hours, I don't know what I'm feeling. I feel a pit in my stomach and confused or just plain numb. I'm unable to concentrate and don't know what to do. I jerked off thinking that would make me better, but that didn't help. I don't know what to do. Will this be the same with other girls? Is making out so boring? How do I get through this????\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=9mfvob_question=e7ebvjv,e7eap9z_group=expert_pct_bin_question=text_model_output_quality_1]]\n",
      "1. Do you get along with your husband generally?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=9mfvob_question=e7ebvjv,e7eap9z_group=expert_pct_bin_question=question_group_1_quality_2]]\n",
      "2. Are all conversations like this?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=9mfvob_question=e7ebvjv,e7eap9z_group=expert_pct_bin_question=reader_model_output_group_1_quality_3]]\n",
      "3. Why did you ask him to do it on Mother’s Day?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:MC]]\n",
      "[[ID:post=9mfvob_question=e7ebvjv,e7eap9z_group=expert_pct_bin_group]]\n",
      "4. One of the following questions was written by a novice reader and the other question was written by a expert reader.\n",
      "Which question is more likely to be written by a ***expert reader?***\n",
      "\n",
      "[[Choices]]\n",
      "\n",
      "Q1: Why did you ask him to do it on Mother’s Day?\n",
      "Q2: What do you want to do with your life?\n",
      "\n",
      "[[PageBreak]]\n",
      "\n",
      "\n",
      "[[Question:DB]]\n",
      "Please read the following post and first rate the questions that follow the post according to how (1) coherent, (2) fluent, and (3) answerable you believe that they are.\n",
      "Next, read two additional questions and determine who wrote the questions.<br></br>\n",
      "\n",
      "Post:\n",
      "\n",
      "My professor constantly brings up debates about race, religion, political views, etc. The debate today was about words. What words hurt people and how to keep track. Well I told her that what bothers me is that I may say a word that offends someone out of ignorance. If they asked me POLITELY to not say the word I would not. However, the typical response is a lot of anger and energy which causes me to get defensive. The anger causes a scene and instead of solving anything it gets escalated and heated. She then continued to state how it was my fault that the other person's feelings were hurt. Either way it doesn't matter if she's right or I'm right. I personally believe what she did was very unprofessional. She asked me what word would offend me. I told her yellow-belly (I'm Japanese). She proceeded with \"Your short, let's say I make short jokes. I wouldn't walk around making short jokes if I knew it hurt you\" yet again I stated saying hurtful things out of IGNORANCE. She then continued to say that I need some \"adulting\"... She did this in front of my fellow classmates and it was humiliating being called short and immature just for having a different opinion and debating. I feel attacked.. am I? Should I go to the dean to report this unprofessionalism or leave it alone? Thanks guys..\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=99k3nu_question=e4orbnh,e4ocolv_group=expert_pct_bin_question=text_model_output_quality_1]]\n",
      "1. Is it a Chase account?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=99k3nu_question=e4orbnh,e4ocolv_group=expert_pct_bin_question=question_group_1_quality_2]]\n",
      "2. But, continuing to do so after being told what you’ve done is insulting.... do you see... the... lesson... she... yah?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=99k3nu_question=e4orbnh,e4ocolv_group=expert_pct_bin_question=reader_model_output_group_1_quality_3]]\n",
      "3. Is it a Chase account?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:MC]]\n",
      "[[ID:post=99k3nu_question=e4orbnh,e4ocolv_group=expert_pct_bin_group]]\n",
      "4. One of the following questions was written by a novice reader and the other question was written by a expert reader.\n",
      "Which question is more likely to be written by a ***expert reader?***\n",
      "\n",
      "[[Choices]]\n",
      "\n",
      "Q1: Is it a Chase account?\n",
      "Q2: How much do you have in savings?\n",
      "\n",
      "[[PageBreak]]\n",
      "\n",
      "\n",
      "[[Question:DB]]\n",
      "Please read the following post and first rate the questions that follow the post according to how (1) coherent, (2) fluent, and (3) answerable you believe that they are.\n",
      "Next, read two additional questions and determine who wrote the questions.<br></br>\n",
      "\n",
      "Post:\n",
      "\n",
      "So today I had an urgent meeting after school which I had to change for. After my last class of the day, I sprinted into one of the two cubicles of our school’s washroom to change. The washroom was already packed which made me anxious (only a flimsy door that didn’t lock properly separated my half naked self from a bunch of unpredictable teenagers), so I rushed to change as fast as possible. \n",
      "\n",
      "I took a glance at the toilet (cuz why not right lol) and it was filled with piss and shit. Gross, right? I briefly considered flushing it, but the fact that I was already running late and the large number of people in the vicinity prevented my subconscious from doing so for some reason. (I now deeply regret not taking the 2 seconds to flush it) \n",
      "\n",
      "\n",
      "After changing, I threw open the doer and made to sprint out the door. As I hurried away, a classmate (who I’ve only recently gotten to meet) yelled back at me “HEY, DO YOU MIND FLUSHING THE TOILET?” \n",
      "\n",
      "Fuck.\n",
      "\n",
      "“Wait, I swear it wasn’t me. I ..uh.. have a thing I have to go to so I had to change. I didn’t use the toilet,” my sleep-deprived dumbass stammered unconvincingly. \n",
      "\n",
      "He, understandably, replies, “I’m sorry but I find that really hard to believe.”\n",
      "\n",
      "At this point, I’m mortified (but not surprised) by how everything perfectly fell into place to create this nightmare, so I try my best to fix things by speed walking into the cubicle and flushing the nasty ass toilet. As I walk back I desperately attempt to convince him that I did not commit the crime that he’s convicted me of. \n",
      "\n",
      "“I swear, I didn’t do that. I just had to change for a meeting I have” I pleaded.\n",
      "\n",
      "He just throws me a dirty look and I have no choice but to walk away in shame. Awesome way to cap off an already shitty day. \n",
      "\n",
      "What do I do now to cope with this traumatizing experience? The person in question is in half my classes and I’ve talked to him a couple of times. I know how the situation looked from his perspective, but that doesn’t change the fact that I’m still cringing 9 hours after it happened. Not looking forward to school tomorrow. \n",
      "\n",
      "\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=9svh99_question=e8rsj8z,e8rsb7w_group=expert_pct_bin_question=text_model_output_quality_1]]\n",
      "1. Are they saying they don't have to support you in any way either?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=9svh99_question=e8rsj8z,e8rsb7w_group=expert_pct_bin_question=question_group_1_quality_2]]\n",
      "2. be like \"why would I not flush my own poop especially when people are waiting?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=9svh99_question=e8rsj8z,e8rsb7w_group=expert_pct_bin_question=reader_model_output_group_1_quality_3]]\n",
      "3. Have you spent a considerable amount of time in the job?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:MC]]\n",
      "[[ID:post=9svh99_question=e8rsj8z,e8rsb7w_group=expert_pct_bin_group]]\n",
      "4. One of the following questions was written by a novice reader and the other question was written by a expert reader.\n",
      "Which question is more likely to be written by a ***expert reader?***\n",
      "\n",
      "[[Choices]]\n",
      "\n",
      "Q1: Have you spent a considerable amount of time in the job?\n",
      "Q2: Will you be able to support yourself and your family in the long run?\n",
      "\n",
      "[[PageBreak]]\n",
      "\n",
      "\n",
      "[[Question:DB]]\n",
      "Please read the following post and first rate the questions that follow the post according to how (1) coherent, (2) fluent, and (3) answerable you believe that they are.\n",
      "Next, read two additional questions and determine who wrote the questions.<br></br>\n",
      "\n",
      "Post:\n",
      "\n",
      "Basically, I live everyday thinking the people I interact with either want to hurt me, or they'll abandon me once they realize that I'm not as good as they think I am. I also feel like everyone is talking about me behind my back and it's never anything good. I've started pushing people away because I'm scared that they don't want me around anyway, but then I annoy myself because I feel so lonely. \n",
      "\n",
      "I'm also becoming afraid of doing something as simple as driving. Sometimes I get in the car and panic because I think someone will try to hit me. \n",
      "\n",
      "Anyway, my mind has been a total mess. I see potential threats everywhere I go and honestly I just wanna have a good time for once\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=d31hda_question=ezyio0l,ezyai0i_group=expert_pct_bin_question=text_model_output_quality_1]]\n",
      "1. Have you considered a 529?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=d31hda_question=ezyio0l,ezyai0i_group=expert_pct_bin_question=question_group_1_quality_2]]\n",
      "2. OCD and intrusive thoughts?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:Matrix]]\n",
      "[[ID:post=d31hda_question=ezyio0l,ezyai0i_group=expert_pct_bin_question=reader_model_output_group_1_quality_3]]\n",
      "3. Have you considered a 529?\n",
      "\n",
      "[[Choices]]\n",
      "Coherent\n",
      "Fluent\n",
      "Answerable\n",
      "\n",
      "[[Answers]]\n",
      "Very\n",
      "Somewhat\n",
      "Neutral\n",
      "Not very\n",
      "Not at all\n",
      "\n",
      "[[Question:MC]]\n",
      "[[ID:post=d31hda_question=ezyio0l,ezyai0i_group=expert_pct_bin_group]]\n",
      "4. One of the following questions was written by a novice reader and the other question was written by a expert reader.\n",
      "Which question is more likely to be written by a ***expert reader?***\n",
      "\n",
      "[[Choices]]\n",
      "\n",
      "Q1: Have you considered a 529?\n",
      "Q2: Are you a good salesman?\n"
     ]
    }
   ],
   "source": [
    "print(data_subreddit_txt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3] *",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
