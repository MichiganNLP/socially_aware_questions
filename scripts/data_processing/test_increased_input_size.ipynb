{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test increased input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been stuck with input size 1024 because of memory problems.\n",
    "\n",
    "Let's try to increase this by shrinking other parts of the model, using multiple GPUs, or using a longer version of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longformer\n",
    "Let's use the `Longformer` model defined in prior work, which uses local self-attention rather than global attention to reduce memory/training time.\n",
    "\n",
    "Details [here](https://huggingface.co/transformers/model_doc/longformer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LongformerConfig, LongformerModel\n",
    "config = LongformerConfig()\n",
    "cache_dir = '../../data/longformer_cache/'\n",
    "model = LongformerModel.from_pretrained('allenai/longformer-base-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 9226, 16, 41, 8135, 3645, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import LongformerTokenizer\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096', cache_dir=cache_dir)\n",
    "test_input_str = ['this is an input sentence', 'this is another input sentence']\n",
    "test_input_ids = tokenizer.encode_plus(test_input_str[0])\n",
    "print(test_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## test max document length\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "test_vocab = ['testing', 'words', 'sentence', 'language']\n",
    "max_doc_length = 4096\n",
    "test_input_str = ' '.join(np.random.choice(test_vocab, max_doc_length, replace=True))\n",
    "test_input_tokens = tokenizer.encode_plus(test_input_str, truncation=True)\n",
    "import torch\n",
    "device_name = 'cuda:2'\n",
    "model.to(device_name)\n",
    "with torch.no_grad():\n",
    "    test_input_ids = torch.LongTensor(test_input_tokens['input_ids']).reshape(1,-1)\n",
    "    test_attention = torch.LongTensor(test_input_tokens['attention_mask']).reshape(1,-1)\n",
    "    test_input_ids = test_input_ids.to(device_name)\n",
    "    test_attention = test_attention.to(device_name)\n",
    "    test_output = model(test_input_ids, test_attention)\n",
    "    test_input_ids = test_input_ids.to('cpu')\n",
    "    test_attention = test_attention.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.0524, -0.0313,  0.0290,  ..., -0.0564, -0.0237, -0.0572],\n",
      "         [ 0.0336, -0.0289,  0.1894,  ..., -0.5832,  0.0433, -0.0138],\n",
      "         [ 0.1830, -0.1202,  0.2508,  ..., -0.6626,  0.1989,  0.0652],\n",
      "         ...,\n",
      "         [-0.2211, -0.0821,  0.0413,  ..., -0.3656,  0.0050, -0.0762],\n",
      "         [-0.2310, -0.2436,  0.0702,  ..., -0.0624, -0.0860,  0.0031],\n",
      "         [-0.1774, -0.1190,  0.0915,  ..., -0.2293,  0.1176, -0.0809]]],\n",
      "       device='cuda:2'), tensor([[ 0.1938, -0.2920,  0.0522, -0.0186,  0.3591, -0.1527, -0.5196, -0.3524,\n",
      "         -0.0942, -0.3459, -0.4731, -0.1311,  0.2271, -0.3579,  0.0459, -0.2032,\n",
      "         -0.3294, -0.1121, -0.1357, -0.0892, -0.0480,  0.0020, -0.2277,  0.0582,\n",
      "         -0.5146, -0.0252, -0.1562, -0.3015,  0.2656,  0.2639, -0.0479, -0.0453,\n",
      "         -0.2961,  0.0293,  0.0439,  0.2718, -0.2025,  0.1744, -0.4228,  0.2750,\n",
      "         -0.0817,  0.1218,  0.2675, -0.0756,  0.1055,  0.1678, -0.2062, -0.2978,\n",
      "         -0.1758,  0.4407,  0.3613,  0.3274,  0.2859,  0.1160, -0.2758, -0.2193,\n",
      "         -0.0363,  0.0481, -0.1804, -0.1392, -0.2612, -0.2633, -0.0798, -0.2611,\n",
      "         -0.0810,  0.1368,  0.1847,  0.0690,  0.2816, -0.4044, -0.2625,  0.1058,\n",
      "          0.3815,  0.1801,  0.0782,  0.2487, -0.2159,  0.1480, -0.0561,  0.4134,\n",
      "         -0.4313,  0.5408,  0.1382,  0.0213, -0.5541,  0.2993, -0.4694,  0.3946,\n",
      "         -0.1394, -0.0129,  0.2541,  0.3349,  0.1774, -0.0193, -0.0103,  0.0286,\n",
      "         -0.3923, -0.1010, -0.4688, -0.6601,  0.1929, -0.2203, -0.1946,  0.3195,\n",
      "          0.0224, -0.5013, -0.3308, -0.0801,  0.0141,  0.1466,  0.4199, -0.0165,\n",
      "         -0.1099, -0.0447, -0.2358,  0.0998, -0.1254, -0.0606,  0.0980,  0.2115,\n",
      "          0.1197,  0.0995,  0.0720,  0.0645,  0.1939,  0.1228,  0.0865, -0.1342,\n",
      "          0.4276, -0.0853, -0.3800, -0.0023, -0.0991, -0.4231,  0.2031, -0.1174,\n",
      "          0.3710,  0.0938, -0.0587,  0.2027,  0.1171,  0.1503, -0.2113, -0.0362,\n",
      "         -0.0644, -0.0892,  0.2412, -0.1448,  0.1857,  0.0380, -0.1346, -0.0379,\n",
      "          0.3351, -0.0584,  0.1456, -0.1218,  0.0122,  0.0362, -0.1602, -0.0970,\n",
      "          0.1062,  0.4299,  0.1490, -0.0024,  0.1210, -0.3047, -0.1636, -0.1884,\n",
      "          0.0070,  0.1488, -0.0320,  0.3080, -0.1690,  0.3303,  0.3506,  0.0520,\n",
      "         -0.1508, -0.0210, -0.1511,  0.1963,  0.1330, -0.1116, -0.0390,  0.3177,\n",
      "         -0.0490,  0.1765,  0.1108, -0.2257, -0.0185,  0.2489,  0.0039,  0.2141,\n",
      "         -0.0938, -0.5226,  0.4709, -0.1398, -0.0551, -0.1302,  0.0652,  0.3586,\n",
      "          0.1799, -0.3807,  0.1056, -0.0132, -0.5034, -0.0849, -0.1043, -0.0828,\n",
      "         -0.0590, -0.2357,  0.2207,  0.4470,  0.3747, -0.2812,  0.2370,  0.1695,\n",
      "          0.2596,  0.3421,  0.2926, -0.2319,  0.3648, -0.4953,  0.0934, -0.0627,\n",
      "          0.1916,  0.3176, -0.0840,  0.2492, -0.0161,  0.3252,  0.1243,  0.0764,\n",
      "          0.3667, -0.3290, -0.4205,  0.1338, -0.1778, -0.2297,  0.1669,  0.2454,\n",
      "         -0.3512, -0.1076, -0.3460, -0.1081,  0.0596,  0.0166, -0.2046, -0.3574,\n",
      "          0.1291,  0.4351, -0.1133, -0.4818, -0.1052, -0.3454,  0.0437,  0.3595,\n",
      "          0.1537,  0.2589, -0.1783, -0.2456, -0.0422,  0.0240, -0.2011, -0.3207,\n",
      "         -0.0133,  0.2583, -0.3714, -0.1407, -0.0198, -0.2832,  0.2444, -0.0681,\n",
      "         -0.1853, -0.0305, -0.0666, -0.1451, -0.3331, -0.1295,  0.0402,  0.0263,\n",
      "         -0.4833, -0.3847, -0.5399,  0.2910,  0.4058, -0.0431,  0.4367, -0.1266,\n",
      "          0.1104,  0.0306,  0.2179, -0.0052,  0.4448, -0.4124,  0.0859, -0.3319,\n",
      "          0.3582, -0.3133,  0.1570,  0.3639, -0.3487,  0.2051, -0.1612, -0.3093,\n",
      "          0.4310, -0.2358, -0.4267,  0.1077, -0.1517, -0.0577,  0.4028,  0.0271,\n",
      "          0.2298, -0.2067,  0.2502,  0.1793,  0.1298,  0.2274, -0.0889,  0.6576,\n",
      "          0.1368,  0.0286,  0.0336,  0.2758,  0.3502,  0.1378,  0.3281,  0.2352,\n",
      "         -0.2086, -0.0058, -0.3872,  0.4524, -0.4776,  0.0492, -0.1850,  0.2515,\n",
      "          0.4664, -0.1489, -0.2640,  0.2535,  0.1223, -0.2069,  0.1988, -0.2621,\n",
      "          0.0140, -0.3049, -0.1029,  0.2498, -0.0280, -0.1543,  0.2860,  0.3696,\n",
      "          0.5161,  0.3029, -0.2322, -0.1585,  0.1099, -0.2184,  0.0914, -0.1031,\n",
      "         -0.1518,  0.1655,  0.1816,  0.1418, -0.0468, -0.0373,  0.0993, -0.0616,\n",
      "         -0.3875, -0.0695,  0.4129, -0.0862, -0.4160,  0.5175, -0.0051,  0.3621,\n",
      "          0.0552, -0.0126,  0.0227, -0.1860,  0.0524, -0.0356, -0.2141,  0.1929,\n",
      "         -0.2921, -0.3378,  0.0207,  0.1763, -0.4912, -0.4454,  0.1294,  0.1038,\n",
      "         -0.2085, -0.1938, -0.0440, -0.1849, -0.0958, -0.2733,  0.3931,  0.1365,\n",
      "         -0.0531,  0.1663,  0.0031, -0.3336, -0.1407, -0.4500, -0.1356, -0.0022,\n",
      "          0.5974, -0.2120, -0.0382,  0.6088,  0.2531,  0.3728,  0.3467, -0.4254,\n",
      "          0.1667, -0.1298,  0.2835, -0.2752, -0.2327, -0.3422,  0.0630,  0.1158,\n",
      "          0.1192, -0.0817,  0.3714,  0.1327,  0.1881,  0.0484,  0.1064,  0.0496,\n",
      "          0.2205, -0.0584, -0.0133,  0.1962, -0.1953,  0.1306,  0.0539, -0.3848,\n",
      "          0.2379, -0.2428,  0.1482, -0.3913,  0.0024, -0.2304,  0.3703,  0.1770,\n",
      "         -0.1395,  0.1627, -0.1123, -0.0758,  0.1099,  0.1519,  0.2187, -0.0449,\n",
      "         -0.0413, -0.0745,  0.2310, -0.2903, -0.1181,  0.1739,  0.3909,  0.2019,\n",
      "         -0.3270, -0.3464, -0.2485, -0.4409,  0.2712, -0.1699,  0.2904, -0.5160,\n",
      "         -0.3392,  0.0740,  0.1209,  0.1650, -0.2038, -0.2688,  0.1180,  0.1272,\n",
      "         -0.3567, -0.2296,  0.2923, -0.0645,  0.1696, -0.2826, -0.1904, -0.2382,\n",
      "         -0.3108, -0.0970, -0.2829, -0.2391,  0.0113,  0.2913, -0.3555,  0.3885,\n",
      "         -0.0379,  0.3445,  0.1037, -0.2030, -0.1578, -0.3362,  0.3558, -0.2030,\n",
      "         -0.3615, -0.3626, -0.1493,  0.1017,  0.4094,  0.3198, -0.4615,  0.2198,\n",
      "          0.1292, -0.2428,  0.5485,  0.2866, -0.1362, -0.3636, -0.0788,  0.4126,\n",
      "         -0.1608,  0.0495,  0.1957, -0.3671, -0.0497,  0.1874,  0.4716,  0.0583,\n",
      "          0.3345,  0.3496, -0.1031,  0.0525, -0.0023,  0.0030, -0.2566,  0.4732,\n",
      "         -0.0770, -0.3491,  0.0944,  0.0041,  0.4155, -0.3122, -0.7032, -0.2170,\n",
      "          0.3131, -0.2360,  0.4446, -0.2769, -0.5313, -0.4410, -0.0055, -0.1822,\n",
      "         -0.1613, -0.0281,  0.3597, -0.0904,  0.1239,  0.3807,  0.4134,  0.1928,\n",
      "          0.1643, -0.0520, -0.1669,  0.0701,  0.2328, -0.0944, -0.0143,  0.1459,\n",
      "         -0.0454, -0.0640,  0.0503,  0.0707,  0.2319, -0.0194, -0.0521,  0.1561,\n",
      "         -0.2630, -0.0220, -0.1204, -0.1381, -0.0023,  0.3102,  0.1543, -0.2932,\n",
      "         -0.1727,  0.2301, -0.2115, -0.0543,  0.0939,  0.3109,  0.4019,  0.2578,\n",
      "          0.0966, -0.1990, -0.0726, -0.0047, -0.3230, -0.2851, -0.2640, -0.1084,\n",
      "         -0.0509,  0.0007, -0.2472, -0.1522, -0.1775,  0.3871,  0.2551,  0.0763,\n",
      "          0.3533, -0.3075, -0.2342,  0.0819, -0.2450, -0.0981,  0.0444,  0.0413,\n",
      "          0.0376,  0.1953,  0.0973, -0.2364, -0.1671,  0.2005, -0.0302, -0.0596,\n",
      "          0.0638, -0.4092,  0.4126,  0.1278, -0.2102, -0.0643,  0.1488, -0.2865,\n",
      "          0.1112, -0.4398,  0.1065, -0.0520,  0.2548, -0.1226,  0.0345, -0.0950,\n",
      "         -0.3985,  0.2562, -0.1487, -0.0124, -0.0699, -0.3029, -0.1589, -0.0404,\n",
      "         -0.3003,  0.0890,  0.1277,  0.0303, -0.0929,  0.4238, -0.0413,  0.1587,\n",
      "         -0.2022, -0.2840, -0.4807,  0.2077, -0.1862, -0.3774, -0.1723,  0.0916,\n",
      "         -0.2214, -0.1295,  0.2896,  0.3231, -0.1458, -0.1919,  0.1102, -0.0155,\n",
      "          0.1200, -0.0849, -0.2872, -0.0647, -0.2912, -0.1835,  0.0553,  0.4275,\n",
      "          0.1554,  0.0704, -0.1661,  0.1365, -0.0343, -0.0471,  0.0969,  0.2344,\n",
      "          0.2395, -0.1427,  0.1233, -0.2969, -0.2043,  0.1605, -0.5182, -0.3266,\n",
      "          0.3001,  0.2644, -0.4459, -0.1300, -0.4039, -0.0823, -0.1084, -0.0281,\n",
      "         -0.1407, -0.1021, -0.1889, -0.4075, -0.2209, -0.1567, -0.3371, -0.1424,\n",
      "         -0.1990, -0.3801,  0.0528,  0.3763, -0.1064,  0.3468, -0.1097, -0.3170,\n",
      "          0.0264, -0.0175, -0.0129,  0.0585, -0.2771, -0.4373, -0.2256,  0.3065,\n",
      "         -0.0902,  0.2367,  0.2202, -0.5000,  0.1321, -0.0101, -0.3140,  0.0161,\n",
      "         -0.4688, -0.2442,  0.2053, -0.0859, -0.0478,  0.0480, -0.1316, -0.3166,\n",
      "         -0.0992, -0.4141, -0.0896, -0.0349, -0.0287,  0.1352, -0.4418, -0.6223,\n",
      "          0.3714, -0.2629, -0.0656,  0.2052,  0.0262,  0.2685, -0.2587,  0.0105,\n",
      "          0.2432,  0.2309, -0.2397,  0.0531, -0.2534, -0.0893,  0.1209,  0.0457]],\n",
      "       device='cuda:2'))\n"
     ]
    }
   ],
   "source": [
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4096, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like this worked! Can this handle the news articles in our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WASHINGTON -- President Trump's advisers have ...</td>\n",
       "      <td>Where is our supine U. S. Congress?</td>\n",
       "      <td>5ad09d04068401528a2a8848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A federal judge in Manhattan indicated on Mond...</td>\n",
       "      <td>would that apply to me if I were in those circ...</td>\n",
       "      <td>5ad49614068401528a2a8e81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>President Trump recently tweeted, “ The United...</td>\n",
       "      <td>@ Sarah : I ask, in all sincerity, what good t...</td>\n",
       "      <td>5add197f068401528a2aa147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I came to America from India at age 23. That w...</td>\n",
       "      <td>Why aren't Indian citizens and other immigrant...</td>\n",
       "      <td>5ad75687068401528a2a95e6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No president in my lifetime has made me think ...</td>\n",
       "      <td>But what about at home?</td>\n",
       "      <td>5ac4059c068401528a2a1c89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_text  \\\n",
       "0  WASHINGTON -- President Trump's advisers have ...   \n",
       "1  A federal judge in Manhattan indicated on Mond...   \n",
       "2  President Trump recently tweeted, “ The United...   \n",
       "3  I came to America from India at age 23. That w...   \n",
       "4  No president in my lifetime has made me think ...   \n",
       "\n",
       "                                         target_text                article_id  \n",
       "0                Where is our supine U. S. Congress?  5ad09d04068401528a2a8848  \n",
       "1  would that apply to me if I were in those circ...  5ad49614068401528a2a8e81  \n",
       "2  @ Sarah : I ask, in all sincerity, what good t...  5add197f068401528a2aa147  \n",
       "3  Why aren't Indian citizens and other immigrant...  5ad75687068401528a2a95e6  \n",
       "4                            But what about at home?  5ac4059c068401528a2a1c89  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## load sample data\n",
    "import pandas as pd\n",
    "NYT_article_data = pd.read_csv('../../data/nyt_comments/NYT_question_data_train_data.csv', sep=',', index_col=False)\n",
    "display(NYT_article_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_article_data = NYT_article_data.assign(**{\n",
    "    'source_text_len' : NYT_article_data.loc[:, 'source_text'].apply(tokenizer.tokenize)\n",
    "})\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(NYT_article_data.loc[:, 'source_text_len'])\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3] *",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
