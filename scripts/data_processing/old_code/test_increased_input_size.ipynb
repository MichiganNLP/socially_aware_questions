{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test increased input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been stuck with input size 1024 because of memory problems.\n",
    "\n",
    "Let's try to increase this by shrinking other parts of the model, using multiple GPUs, or using a longer version of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longformer\n",
    "Let's use the `Longformer` model defined in prior work, which uses local self-attention rather than global attention to reduce memory/training time.\n",
    "\n",
    "Details [here](https://huggingface.co/transformers/model_doc/longformer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LongformerConfig, LongformerModel\n",
    "config = LongformerConfig()\n",
    "cache_dir = '../../data/longformer_cache/'\n",
    "model = LongformerModel.from_pretrained('allenai/longformer-base-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save config for later?\n",
    "model.config.to_json_file('../../data/longformer_cache/longformer_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 9226, 16, 41, 8135, 3645, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import LongformerTokenizer, BartTokenizer\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096', cache_dir=cache_dir)\n",
    "# tokenizer = BartTokenizer.from_pretrained('facebook/bart-base', cache_dir='../../data/nyt_comments/model_cache/')\n",
    "test_input_str = ['this is an input sentence', 'this is another input sentence']\n",
    "test_input_ids = tokenizer.encode_plus(test_input_str[0])\n",
    "print(test_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## test max document length\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "test_vocab = ['testing', 'words', 'sentence', 'language']\n",
    "max_doc_length = 4096\n",
    "test_input_str = ' '.join(np.random.choice(test_vocab, max_doc_length, replace=True))\n",
    "test_input_tokens = tokenizer.encode_plus(test_input_str, truncation=True)\n",
    "import torch\n",
    "device_name = 'cuda:2'\n",
    "model.to(device_name)\n",
    "with torch.no_grad():\n",
    "    test_input_ids = torch.LongTensor(test_input_tokens['input_ids']).reshape(1,-1)\n",
    "    test_attention = torch.LongTensor(test_input_tokens['attention_mask']).reshape(1,-1)\n",
    "    test_input_ids = test_input_ids.to(device_name)\n",
    "    test_attention = test_attention.to(device_name)\n",
    "    test_output = model(test_input_ids, test_attention)\n",
    "    test_input_ids = test_input_ids.to('cpu')\n",
    "    test_attention = test_attention.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.0527, -0.0315,  0.0286,  ..., -0.0564, -0.0239, -0.0570],\n",
      "         [ 0.0341, -0.0290,  0.1896,  ..., -0.5842,  0.0429, -0.0135],\n",
      "         [ 0.1834, -0.1210,  0.2500,  ..., -0.6635,  0.1980,  0.0649],\n",
      "         ...,\n",
      "         [-0.0481, -0.0921,  0.0864,  ..., -0.3947, -0.0060, -0.0552],\n",
      "         [-0.0623, -0.0581,  0.0635,  ..., -0.4156, -0.0499, -0.0616],\n",
      "         [-0.1087, -0.1674,  0.1134,  ..., -0.2352,  0.0707, -0.0627]]],\n",
      "       device='cuda:2'), tensor([[ 1.9369e-01, -2.9230e-01,  5.1652e-02, -1.8974e-02,  3.5887e-01,\n",
      "         -1.5266e-01, -5.1965e-01, -3.5222e-01, -9.4029e-02, -3.4605e-01,\n",
      "         -4.7307e-01, -1.3086e-01,  2.2708e-01, -3.5769e-01,  4.5912e-02,\n",
      "         -2.0275e-01, -3.2902e-01, -1.1249e-01, -1.3565e-01, -8.9653e-02,\n",
      "         -4.8179e-02,  2.1219e-03, -2.2777e-01,  5.8795e-02, -5.1465e-01,\n",
      "         -2.5448e-02, -1.5650e-01, -3.0164e-01,  2.6552e-01,  2.6359e-01,\n",
      "         -4.8347e-02, -4.6063e-02, -2.9614e-01,  2.9422e-02,  4.3749e-02,\n",
      "          2.7111e-01, -2.0250e-01,  1.7385e-01, -4.2292e-01,  2.7474e-01,\n",
      "         -8.1772e-02,  1.2164e-01,  2.6738e-01, -7.5415e-02,  1.0537e-01,\n",
      "          1.6781e-01, -2.0601e-01, -2.9747e-01, -1.7513e-01,  4.4076e-01,\n",
      "          3.6138e-01,  3.2774e-01,  2.8577e-01,  1.1591e-01, -2.7589e-01,\n",
      "         -2.1873e-01, -3.5868e-02,  4.8282e-02, -1.8023e-01, -1.3882e-01,\n",
      "         -2.6079e-01, -2.6319e-01, -7.9949e-02, -2.6151e-01, -8.0545e-02,\n",
      "          1.3640e-01,  1.8474e-01,  6.8747e-02,  2.8174e-01, -4.0427e-01,\n",
      "         -2.6239e-01,  1.0601e-01,  3.8159e-01,  1.8062e-01,  7.7928e-02,\n",
      "          2.4860e-01, -2.1599e-01,  1.4860e-01, -5.5575e-02,  4.1359e-01,\n",
      "         -4.3078e-01,  5.4080e-01,  1.3799e-01,  2.1683e-02, -5.5392e-01,\n",
      "          2.9913e-01, -4.6931e-01,  3.9487e-01, -1.3955e-01, -1.2764e-02,\n",
      "          2.5423e-01,  3.3493e-01,  1.7733e-01, -1.9020e-02, -1.0468e-02,\n",
      "          2.8644e-02, -3.9206e-01, -1.0096e-01, -4.6842e-01, -6.5951e-01,\n",
      "          1.9321e-01, -2.1950e-01, -1.9512e-01,  3.1906e-01,  2.2411e-02,\n",
      "         -5.0113e-01, -3.3078e-01, -8.0336e-02,  1.4135e-02,  1.4638e-01,\n",
      "          4.1939e-01, -1.6171e-02, -1.0969e-01, -4.4375e-02, -2.3558e-01,\n",
      "          9.9685e-02, -1.2562e-01, -6.0876e-02,  9.8187e-02,  2.1145e-01,\n",
      "          1.2019e-01,  9.9018e-02,  7.2129e-02,  6.4537e-02,  1.9339e-01,\n",
      "          1.2287e-01,  8.6700e-02, -1.3428e-01,  4.2729e-01, -8.5697e-02,\n",
      "         -3.8023e-01, -2.1495e-03, -9.8731e-02, -4.2264e-01,  2.0286e-01,\n",
      "         -1.1749e-01,  3.7077e-01,  9.3484e-02, -5.8673e-02,  2.0289e-01,\n",
      "          1.1708e-01,  1.4989e-01, -2.1118e-01, -3.6078e-02, -6.4910e-02,\n",
      "         -8.8944e-02,  2.4066e-01, -1.4466e-01,  1.8535e-01,  3.8730e-02,\n",
      "         -1.3427e-01, -3.7859e-02,  3.3548e-01, -5.8387e-02,  1.4528e-01,\n",
      "         -1.2121e-01,  1.2630e-02,  3.6336e-02, -1.6033e-01, -9.6948e-02,\n",
      "          1.0614e-01,  4.2982e-01,  1.4921e-01, -2.7299e-03,  1.2140e-01,\n",
      "         -3.0482e-01, -1.6350e-01, -1.8871e-01,  7.4891e-03,  1.4848e-01,\n",
      "         -3.2137e-02,  3.0776e-01, -1.6902e-01,  3.3007e-01,  3.5024e-01,\n",
      "          5.2082e-02, -1.5098e-01, -2.0743e-02, -1.5092e-01,  1.9607e-01,\n",
      "          1.3279e-01, -1.1166e-01, -3.9095e-02,  3.1749e-01, -4.8772e-02,\n",
      "          1.7612e-01,  1.1041e-01, -2.2584e-01, -1.8606e-02,  2.4884e-01,\n",
      "          4.0062e-03,  2.1454e-01, -9.3820e-02, -5.2263e-01,  4.7062e-01,\n",
      "         -1.3996e-01, -5.5082e-02, -1.3040e-01,  6.5606e-02,  3.5871e-01,\n",
      "          1.8027e-01, -3.8053e-01,  1.0613e-01, -1.3800e-02, -5.0366e-01,\n",
      "         -8.4310e-02, -1.0359e-01, -8.2790e-02, -5.8990e-02, -2.3552e-01,\n",
      "          2.2112e-01,  4.4685e-01,  3.7486e-01, -2.8164e-01,  2.3697e-01,\n",
      "          1.6920e-01,  2.5968e-01,  3.4224e-01,  2.9234e-01, -2.3214e-01,\n",
      "          3.6476e-01, -4.9497e-01,  9.2865e-02, -6.3017e-02,  1.9192e-01,\n",
      "          3.1746e-01, -8.4407e-02,  2.4871e-01, -1.6190e-02,  3.2493e-01,\n",
      "          1.2439e-01,  7.6620e-02,  3.6698e-01, -3.2887e-01, -4.2038e-01,\n",
      "          1.3419e-01, -1.7791e-01, -2.2943e-01,  1.6683e-01,  2.4476e-01,\n",
      "         -3.5123e-01, -1.0750e-01, -3.4569e-01, -1.0799e-01,  5.9427e-02,\n",
      "          1.6949e-02, -2.0467e-01, -3.5740e-01,  1.2910e-01,  4.3477e-01,\n",
      "         -1.1343e-01, -4.8163e-01, -1.0534e-01, -3.4565e-01,  4.3745e-02,\n",
      "          3.5939e-01,  1.5388e-01,  2.5877e-01, -1.7852e-01, -2.4644e-01,\n",
      "         -4.1652e-02,  2.3864e-02, -2.0086e-01, -3.2071e-01, -1.2879e-02,\n",
      "          2.5882e-01, -3.7145e-01, -1.4070e-01, -2.0208e-02, -2.8308e-01,\n",
      "          2.4463e-01, -6.8306e-02, -1.8511e-01, -3.0293e-02, -6.6410e-02,\n",
      "         -1.4470e-01, -3.3325e-01, -1.2909e-01,  3.9851e-02,  2.6114e-02,\n",
      "         -4.8293e-01, -3.8438e-01, -5.3975e-01,  2.9095e-01,  4.0634e-01,\n",
      "         -4.3420e-02,  4.3669e-01, -1.2621e-01,  1.1028e-01,  3.0917e-02,\n",
      "          2.1769e-01, -4.8688e-03,  4.4499e-01, -4.1211e-01,  8.6320e-02,\n",
      "         -3.3162e-01,  3.5823e-01, -3.1323e-01,  1.5685e-01,  3.6331e-01,\n",
      "         -3.4871e-01,  2.0545e-01, -1.6134e-01, -3.0921e-01,  4.3110e-01,\n",
      "         -2.3634e-01, -4.2660e-01,  1.0713e-01, -1.5137e-01, -5.8246e-02,\n",
      "          4.0297e-01,  2.7549e-02,  2.2963e-01, -2.0618e-01,  2.5034e-01,\n",
      "          1.7910e-01,  1.2992e-01,  2.2672e-01, -8.8486e-02,  6.5736e-01,\n",
      "          1.3654e-01,  2.9079e-02,  3.3835e-02,  2.7636e-01,  3.4998e-01,\n",
      "          1.3808e-01,  3.2795e-01,  2.3554e-01, -2.0881e-01, -6.1089e-03,\n",
      "         -3.8650e-01,  4.5231e-01, -4.7736e-01,  4.9291e-02, -1.8467e-01,\n",
      "          2.5177e-01,  4.6570e-01, -1.4873e-01, -2.6416e-01,  2.5285e-01,\n",
      "          1.2198e-01, -2.0634e-01,  1.9843e-01, -2.6233e-01,  1.4137e-02,\n",
      "         -3.0515e-01, -1.0254e-01,  2.4945e-01, -2.7880e-02, -1.5404e-01,\n",
      "          2.8564e-01,  3.6986e-01,  5.1583e-01,  3.0253e-01, -2.3237e-01,\n",
      "         -1.5872e-01,  1.0987e-01, -2.1866e-01,  9.1442e-02, -1.0299e-01,\n",
      "         -1.5185e-01,  1.6551e-01,  1.8084e-01,  1.4153e-01, -4.6618e-02,\n",
      "         -3.6741e-02,  9.9311e-02, -6.1442e-02, -3.8774e-01, -6.9651e-02,\n",
      "          4.1269e-01, -8.6250e-02, -4.1574e-01,  5.1740e-01, -4.9823e-03,\n",
      "          3.6166e-01,  5.5074e-02, -1.2916e-02,  2.2772e-02, -1.8622e-01,\n",
      "          5.2563e-02, -3.5245e-02, -2.1415e-01,  1.9299e-01, -2.9188e-01,\n",
      "         -3.3728e-01,  2.1756e-02,  1.7647e-01, -4.9104e-01, -4.4566e-01,\n",
      "          1.2916e-01,  1.0379e-01, -2.0866e-01, -1.9345e-01, -4.3979e-02,\n",
      "         -1.8511e-01, -9.5919e-02, -2.7371e-01,  3.9296e-01,  1.3627e-01,\n",
      "         -5.3082e-02,  1.6673e-01,  3.1566e-03, -3.3301e-01, -1.4063e-01,\n",
      "         -4.5024e-01, -1.3552e-01, -1.9371e-03,  5.9682e-01, -2.1162e-01,\n",
      "         -3.7979e-02,  6.0884e-01,  2.5277e-01,  3.7231e-01,  3.4641e-01,\n",
      "         -4.2518e-01,  1.6673e-01, -1.2910e-01,  2.8344e-01, -2.7438e-01,\n",
      "         -2.3233e-01, -3.4235e-01,  6.3313e-02,  1.1563e-01,  1.1946e-01,\n",
      "         -8.1675e-02,  3.7105e-01,  1.3254e-01,  1.8858e-01,  4.8509e-02,\n",
      "          1.0611e-01,  5.0126e-02,  2.2041e-01, -5.8605e-02, -1.3102e-02,\n",
      "          1.9596e-01, -1.9493e-01,  1.3100e-01,  5.3732e-02, -3.8472e-01,\n",
      "          2.3795e-01, -2.4271e-01,  1.4806e-01, -3.9129e-01,  2.0877e-03,\n",
      "         -2.3059e-01,  3.7020e-01,  1.7722e-01, -1.3968e-01,  1.6219e-01,\n",
      "         -1.1280e-01, -7.5567e-02,  1.0951e-01,  1.5170e-01,  2.1845e-01,\n",
      "         -4.5086e-02, -4.1189e-02, -7.4428e-02,  2.3107e-01, -2.9038e-01,\n",
      "         -1.1785e-01,  1.7394e-01,  3.9045e-01,  2.0188e-01, -3.2673e-01,\n",
      "         -3.4578e-01, -2.4862e-01, -4.4097e-01,  2.7084e-01, -1.6930e-01,\n",
      "          2.9038e-01, -5.1610e-01, -3.3938e-01,  7.3814e-02,  1.2042e-01,\n",
      "          1.6511e-01, -2.0346e-01, -2.6858e-01,  1.1805e-01,  1.2687e-01,\n",
      "         -3.5648e-01, -2.2973e-01,  2.9193e-01, -6.4127e-02,  1.6937e-01,\n",
      "         -2.8232e-01, -1.9009e-01, -2.3826e-01, -3.1025e-01, -9.7121e-02,\n",
      "         -2.8299e-01, -2.3892e-01,  1.0936e-02,  2.9131e-01, -3.5545e-01,\n",
      "          3.8826e-01, -3.7620e-02,  3.4426e-01,  1.0341e-01, -2.0265e-01,\n",
      "         -1.5720e-01, -3.3616e-01,  3.5607e-01, -2.0278e-01, -3.6124e-01,\n",
      "         -3.6301e-01, -1.4948e-01,  1.0136e-01,  4.0900e-01,  3.1998e-01,\n",
      "         -4.6152e-01,  2.1958e-01,  1.2849e-01, -2.4230e-01,  5.4813e-01,\n",
      "          2.8667e-01, -1.3603e-01, -3.6366e-01, -7.8540e-02,  4.1231e-01,\n",
      "         -1.6038e-01,  4.9675e-02,  1.9550e-01, -3.6680e-01, -5.0049e-02,\n",
      "          1.8739e-01,  4.7169e-01,  5.8354e-02,  3.3405e-01,  3.4932e-01,\n",
      "         -1.0293e-01,  5.2850e-02, -2.2953e-03,  2.9853e-03, -2.5604e-01,\n",
      "          4.7270e-01, -7.7265e-02, -3.4876e-01,  9.4555e-02,  3.7247e-03,\n",
      "          4.1536e-01, -3.1171e-01, -7.0330e-01, -2.1692e-01,  3.1265e-01,\n",
      "         -2.3556e-01,  4.4447e-01, -2.7682e-01, -5.3108e-01, -4.4126e-01,\n",
      "         -5.8013e-03, -1.8209e-01, -1.6111e-01, -2.7983e-02,  3.5991e-01,\n",
      "         -9.0392e-02,  1.2423e-01,  3.8087e-01,  4.1339e-01,  1.9313e-01,\n",
      "          1.6398e-01, -5.2012e-02, -1.6666e-01,  7.0548e-02,  2.3277e-01,\n",
      "         -9.4330e-02, -1.4249e-02,  1.4656e-01, -4.5534e-02, -6.3638e-02,\n",
      "          5.1031e-02,  7.0496e-02,  2.3207e-01, -1.8816e-02, -5.1669e-02,\n",
      "          1.5622e-01, -2.6322e-01, -2.2330e-02, -1.2076e-01, -1.3790e-01,\n",
      "         -2.1842e-03,  3.0957e-01,  1.5444e-01, -2.9315e-01, -1.7267e-01,\n",
      "          2.3010e-01, -2.1109e-01, -5.4400e-02,  9.3984e-02,  3.1087e-01,\n",
      "          4.0201e-01,  2.5718e-01,  9.6087e-02, -1.9887e-01, -7.2539e-02,\n",
      "         -4.8229e-03, -3.2264e-01, -2.8471e-01, -2.6366e-01, -1.0837e-01,\n",
      "         -5.0824e-02,  4.3799e-04, -2.4715e-01, -1.5277e-01, -1.7752e-01,\n",
      "          3.8691e-01,  2.5507e-01,  7.6019e-02,  3.5279e-01, -3.0736e-01,\n",
      "         -2.3438e-01,  8.2104e-02, -2.4498e-01, -9.8045e-02,  4.4467e-02,\n",
      "          4.1481e-02,  3.7470e-02,  1.9487e-01,  9.7616e-02, -2.3648e-01,\n",
      "         -1.6722e-01,  2.0020e-01, -2.9602e-02, -5.9641e-02,  6.3594e-02,\n",
      "         -4.0886e-01,  4.1178e-01,  1.2748e-01, -2.1006e-01, -6.4155e-02,\n",
      "          1.4846e-01, -2.8679e-01,  1.1159e-01, -4.3944e-01,  1.0602e-01,\n",
      "         -5.1785e-02,  2.5470e-01, -1.2248e-01,  3.4408e-02, -9.5397e-02,\n",
      "         -3.9843e-01,  2.5568e-01, -1.4799e-01, -1.2225e-02, -6.9520e-02,\n",
      "         -3.0282e-01, -1.5881e-01, -3.9739e-02, -2.9990e-01,  8.9255e-02,\n",
      "          1.2710e-01,  3.0453e-02, -9.3669e-02,  4.2348e-01, -4.1390e-02,\n",
      "          1.5827e-01, -2.0225e-01, -2.8375e-01, -4.8073e-01,  2.0747e-01,\n",
      "         -1.8551e-01, -3.7725e-01, -1.7206e-01,  9.1963e-02, -2.2134e-01,\n",
      "         -1.2932e-01,  2.8928e-01,  3.2294e-01, -1.4499e-01, -1.9224e-01,\n",
      "          1.1035e-01, -1.5612e-02,  1.2030e-01, -8.5065e-02, -2.8706e-01,\n",
      "         -6.4674e-02, -2.9169e-01, -1.8329e-01,  5.4694e-02,  4.2731e-01,\n",
      "          1.5508e-01,  6.9902e-02, -1.6572e-01,  1.3637e-01, -3.4226e-02,\n",
      "         -4.6725e-02,  9.7028e-02,  2.3441e-01,  2.3927e-01, -1.4259e-01,\n",
      "          1.2327e-01, -2.9679e-01, -2.0401e-01,  1.6013e-01, -5.1794e-01,\n",
      "         -3.2636e-01,  3.0054e-01,  2.6429e-01, -4.4570e-01, -1.3007e-01,\n",
      "         -4.0381e-01, -8.2431e-02, -1.0811e-01, -2.7847e-02, -1.4086e-01,\n",
      "         -1.0206e-01, -1.8835e-01, -4.0683e-01, -2.2084e-01, -1.5661e-01,\n",
      "         -3.3728e-01, -1.4211e-01, -1.9882e-01, -3.7986e-01,  5.2509e-02,\n",
      "          3.7635e-01, -1.0663e-01,  3.4663e-01, -1.0965e-01, -3.1658e-01,\n",
      "          2.6301e-02, -1.7634e-02, -1.3622e-02,  5.8864e-02, -2.7674e-01,\n",
      "         -4.3689e-01, -2.2505e-01,  3.0620e-01, -9.0578e-02,  2.3686e-01,\n",
      "          2.2020e-01, -4.9989e-01,  1.3244e-01, -1.0543e-02, -3.1424e-01,\n",
      "          1.6255e-02, -4.6866e-01, -2.4426e-01,  2.0505e-01, -8.5787e-02,\n",
      "         -4.7561e-02,  4.7961e-02, -1.3128e-01, -3.1638e-01, -9.9206e-02,\n",
      "         -4.1436e-01, -8.9657e-02, -3.5183e-02, -2.8621e-02,  1.3509e-01,\n",
      "         -4.4119e-01, -6.2221e-01,  3.7102e-01, -2.6304e-01, -6.5639e-02,\n",
      "          2.0470e-01,  2.6372e-02,  2.6889e-01, -2.5817e-01,  1.0748e-02,\n",
      "          2.4264e-01,  2.3097e-01, -2.3952e-01,  5.3641e-02, -2.5348e-01,\n",
      "         -8.9063e-02,  1.2103e-01,  4.5193e-02]], device='cuda:2'))\n"
     ]
    }
   ],
   "source": [
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4096, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like this worked! Can this handle the news articles in our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WASHINGTON -- President Trump's advisers have ...</td>\n",
       "      <td>Where is our supine U. S. Congress?</td>\n",
       "      <td>5ad09d04068401528a2a8848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A federal judge in Manhattan indicated on Mond...</td>\n",
       "      <td>would that apply to me if I were in those circ...</td>\n",
       "      <td>5ad49614068401528a2a8e81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>President Trump recently tweeted, “ The United...</td>\n",
       "      <td>@ Sarah : I ask, in all sincerity, what good t...</td>\n",
       "      <td>5add197f068401528a2aa147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I came to America from India at age 23. That w...</td>\n",
       "      <td>Why aren't Indian citizens and other immigrant...</td>\n",
       "      <td>5ad75687068401528a2a95e6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No president in my lifetime has made me think ...</td>\n",
       "      <td>But what about at home?</td>\n",
       "      <td>5ac4059c068401528a2a1c89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_text  \\\n",
       "0  WASHINGTON -- President Trump's advisers have ...   \n",
       "1  A federal judge in Manhattan indicated on Mond...   \n",
       "2  President Trump recently tweeted, “ The United...   \n",
       "3  I came to America from India at age 23. That w...   \n",
       "4  No president in my lifetime has made me think ...   \n",
       "\n",
       "                                         target_text                article_id  \n",
       "0                Where is our supine U. S. Congress?  5ad09d04068401528a2a8848  \n",
       "1  would that apply to me if I were in those circ...  5ad49614068401528a2a8e81  \n",
       "2  @ Sarah : I ask, in all sincerity, what good t...  5add197f068401528a2aa147  \n",
       "3  Why aren't Indian citizens and other immigrant...  5ad75687068401528a2a95e6  \n",
       "4                            But what about at home?  5ac4059c068401528a2a1c89  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## load sample data\n",
    "import pandas as pd\n",
    "NYT_article_data = pd.read_csv('../../data/nyt_comments/NYT_question_data_train_data.csv', sep=',', index_col=False)\n",
    "display(NYT_article_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAANZ0lEQVR4nO3db6xk9V3H8ffHXWmV6raU1eDCeiFLiPvI1hta1JimrXUp3WJMo6xpLAl2Uw3GPw90SX3iM2qMMUQirhYxaqGITbuw26CpNsSEUBb/Lixrt5SWW2qhNlmNMbGkXx/c03ZyOxdm79zh3Pv1/Upuds5v5pz5fTObT2a+85tzUlVIknr5trEnIEnafIa7JDVkuEtSQ4a7JDVkuEtSQzvHngDAxRdfXEtLS2NPQ5K2lccee+zLVbV72n1bItyXlpY4efLk2NOQpG0lyefWu8+2jCQ1ZLhLUkOGuyQ1ZLhLUkOjhnuSg0mOnjt3bsxpSFI7o4Z7Vd1fVYd37do15jQkqR3bMpLUkOEuSQ1tiR8xbVdLR46P8rxP33rdKM8rafvwnbskNWS4S1JDhrskNWS4S1JDhrskNWS4S1JDnn5Akhry9AOS1JBtGUlqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYWEu5JLkzyWJJ3LOL4kqQXN1O4J7kzyXNJTq0ZP5DkTJKzSY5M3PUbwL2bOVFJ0uxmfed+F3BgciDJDuB24FpgP3Aoyf4kbwWeAL60ifOUJJ2HnbM8qKoeSrK0Zvhq4GxVPQWQ5B7geuBVwIWsBv7/JDlRVV9be8wkh4HDAHv37t1wAZKkbzVTuK9jD/DMxPYK8IaquhkgyY3Al6cFO0BVHQWOAiwvL9cc85AkrTFPuGfK2DdCuqrumuPYkqQ5zLNaZgW4bGL7UuDZ8zmA11CVpMWY5537o8CVSS4HvgDcAPzs+Rygqu4H7l9eXn7vRiexdOT4RneVpLZmXQp5N/AwcFWSlSQ3VdULwM3Ag8Bp4N6qenxxU5UkzWrW1TKH1hk/AZzY6JMnOQgc3Ldv30YPIUmaYtTTD1TV/VV1eNeuXWNOQ5La8dwyktTQqOHuahlJWgzbMpLUkG0ZSWrIcJekhuy5S1JD9twlqSHbMpLUkOEuSQ3Zc5ekhuy5S1JDtmUkqSHDXZIaMtwlqSHDXZIacrWMJDXkahlJasi2jCQ1ZLhLUkOGuyQ1ZLhLUkM7x56Azt/SkeOjPffTt1432nNLmp1LISWpIZdCSlJD9twlqSHDXZIaMtwlqSHDXZIaMtwlqSHDXZIaMtwlqSHDXZIa8heqktSQv1CVpIZsy0hSQ4a7JDVkuEtSQ4a7JDVkuEtSQ4a7JDVkuEtSQ4a7JDVkuEtSQ4a7JDVkuEtSQ4a7JDVkuEtSQ5se7kl+IMkdSe5L8gubfXxJ0kubKdyT3JnkuSSn1owfSHImydkkRwCq6nRVvQ/4aWB586csSXops75zvws4MDmQZAdwO3AtsB84lGT/cN87gb8HPrFpM5UkzWznLA+qqoeSLK0Zvho4W1VPASS5B7geeKKqjgHHkhwHPjTtmEkOA4cB9u7du7HZ62W3dOT4KM/79K3XjfK80nY1U7ivYw/wzMT2CvCGJG8Cfgp4BXBivZ2r6ihwFGB5ebnmmIckaY15wj1TxqqqPgl8co7jSpLmNM9qmRXgsontS4Fnz+cAXiBbkhZjnnB/FLgyyeVJLgBuAI6dzwG8QLYkLcasSyHvBh4GrkqykuSmqnoBuBl4EDgN3FtVjy9uqpKkWc26WubQOuMneJEvTV9KkoPAwX379m30EJKkKUY9/YBtGUlaDM8tI0kNjRrurpaRpMWwLSNJDdmWkaSGDHdJasieuyQ1ZM9dkhqyLSNJDRnuktSQPXdJasieuyQ1ZFtGkhoy3CWpIcNdkhoy3CWpIVfLSFJDrpaRpIZsy0hSQ4a7JDVkuEtSQ4a7JDVkuEtSQy6FlKSGXAopSQ3ZlpGkhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIX6hKUkP+QlWSGrItI0kNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNLSTck/xkkj9K8rEkb1vEc0iS1jdzuCe5M8lzSU6tGT+Q5EySs0mOAFTVR6vqvcCNwM9s6owlSS/pfN653wUcmBxIsgO4HbgW2A8cSrJ/4iG/OdwvSXoZzRzuVfUQ8JU1w1cDZ6vqqar6X+Ae4Pqs+gDw8ar6h2nHS3I4yckkJ59//vmNzl+SNMW8Pfc9wDMT2yvD2C8BbwXeleR903asqqNVtVxVy7t3755zGpKkSTvn3D9TxqqqbgNum/PYkqQNmjfcV4DLJrYvBZ6ddeckB4GD+/btm3Ma6m7pyPFRnvfpW68b5Xmlec3blnkUuDLJ5UkuAG4Ajs26sxfIlqTFOJ+lkHcDDwNXJVlJclNVvQDcDDwInAburarHFzNVSdKsZm7LVNWhdcZPACc28uS2ZSRpMUY9/YBtGUlaDM8tI0kNjRruSQ4mOXru3LkxpyFJ7diWkaSGbMtIUkOGuyQ1ZM9dkhqy5y5JDdmWkaSGDHdJamjes0LOxdMPSNoKxjrrKCzuzKP23CWpIdsyktSQ4S5JDY3ac5e2uo69WP3/YLhLW5SXFtQ8/IWqJDXkahlJasgvVCWpIcNdkhoy3CWpIcNdkhoy3CWpIZdCSlJDLoWUpIZsy0hSQ4a7JDVkuEtSQ4a7JDVkuEtSQ4a7JDVkuEtSQ4a7JDXkL1QlqSF/oSpJDdmWkaSGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGNj3ck1yR5INJ7tvsY0uSZjNTuCe5M8lzSU6tGT+Q5EySs0mOAFTVU1V10yImK0mazazv3O8CDkwOJNkB3A5cC+wHDiXZv6mzkyRtyM5ZHlRVDyVZWjN8NXC2qp4CSHIPcD3wxCzHTHIYOAywd+/eWecrqbGlI8fHnkIb8/Tc9wDPTGyvAHuSvDbJHcDrktyy3s5VdbSqlqtqeffu3XNMQ5K01kzv3NeRKWNVVf8BvG+O40qS5jTPO/cV4LKJ7UuBZ8/nAF4gW5IWY55wfxS4MsnlSS4AbgCOnc8BvEC2JC3GrEsh7wYeBq5KspLkpqp6AbgZeBA4DdxbVY8vbqqSpFnNulrm0DrjJ4ATG33yJAeBg/v27dvoISRJU4x6+gHbMpK0GJ5bRpIaGjXcXS0jSYuRqhp7DiR5HvjcBna9GPjyJk9nK+leH/SvsXt90L/GrVzf91fV1F+Bbolw36gkJ6tqeex5LEr3+qB/jd3rg/41btf67LlLUkOGuyQ1tN3D/ejYE1iw7vVB/xq71wf9a9yW9W3rnrskabrt/s5dkjSF4S5JDW3LcJ927dbtIMllSf4uyekkjyf55WH8oiR/k+TTw7+vmdjnlqHOM0l+YmL8h5L863DfbUmmnV9/NEl2JPnHJA8M221qTPLqJPcleXJ4La/pVB9Akl8d/o+eSnJ3kldu5xqnXQd6M+tJ8ookHx7GH8m3Xrnu5VdV2+oP2AF8BrgCuAD4Z2D/2POace6XAK8fbn8X8G+sXn/2t4Ejw/gR4APD7f1Dfa8ALh/q3jHc9yngGlYvmvJx4Nqx61tT668BHwIeGLbb1Aj8KfDzw+0LgFc3q28P8FngO4bte4Ebt3ONwI8BrwdOTYxtWj3ALwJ3DLdvAD48+us49gQ28CJdAzw4sX0LcMvY89pgLR8Dfhw4A1wyjF0CnJlWG6unV75meMyTE+OHgD8cu56J+VwKfAJ4M98M9xY1At89BF/WjLeob5jL1y+heRGrZ459AHjbdq8RWFoT7ptWz9cfM9zeyeovWrOoWmb5245tmanXbh1pLhs2fGx7HfAI8L1V9UWA4d/vGR62Xq17httrx7eK3wN+HfjaxFiXGq8Angf+ZGg7/XGSC+lTH1X1BeB3gM8DXwTOVdVf06jGwWbW8419avVaF+eA1y5s5jPYjuE+9dqtL/ss5pDkVcBfAb9SVf/5Yg+dMlYvMj66JO8Anquqx2bdZcrYVq5xJ6sf7/+gql4H/DerH+nXs93qY+g9X89qS+L7gAuTvPvFdpkytqVrfAkbqWfL1bodw33ua7eOKcm3sxrsf1FVHxmGv5TkkuH+S4DnhvH1al0Zbq8d3wp+BHhnkqeBe4A3J/lz+tS4AqxU1SPD9n2shn2X+gDeCny2qp6vqq8CHwF+mF41wubW8419kuwEdgFfWdjMZ7Adw33ua7eOZfhm/YPA6ar63Ym7jgHvGW6/h9Ve/NfHbxi+ib8cuBL41PAR8r+SvHE45s9N7DOqqrqlqi6tqiVWX5u/rap306TGqvp34JkkVw1DbwGeoEl9g88Db0zyncPc3sLqpTQ71QibW8/ksd7F6v/7cT+ljNnwn+OLkbezutLkM8D7x57Pecz7R1n9qPYvwD8Nf29ntTf3CeDTw78XTezz/qHOM0ysNACWgVPDfb/PyF/erFPvm/jmF6ptagR+EDg5vI4fBV7Tqb5hbr8FPDnM789YXTmybWsE7mb1+4Ovsvou+6bNrAd4JfCXwFlWV9RcMfZr6OkHJKmh7diWkSS9BMNdkhoy3CWpIcNdkhoy3CWpIcNdkhoy3CWpof8DkZMx7RZ1SAsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NYT_article_data = NYT_article_data.assign(**{\n",
    "    'source_text_len' : NYT_article_data.loc[:, 'source_text'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "})\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(NYT_article_data.loc[:, 'source_text_len'].values)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 / 747 articles above max source length\n",
      "355 / 38445 questions with articles above max source length\n"
     ]
    }
   ],
   "source": [
    "max_source_length = 4096\n",
    "print(f'{NYT_article_data[NYT_article_data.loc[:, \"source_text_len\"]>=max_source_length].drop_duplicates(\"article_id\").shape[0]} / {NYT_article_data.loc[:, \"article_id\"].nunique()} articles above max source length')\n",
    "print(f'{NYT_article_data[NYT_article_data.loc[:, \"source_text_len\"]>=max_source_length].shape[0]} / {NYT_article_data.shape[0]} questions with articles above max source length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Relatively few articles that are too long to encode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test generation too just for sanity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WASHINGTON -- President Trump's advisers have concluded that a wide-ranging corruption investigation into his personal lawyer poses a greater and more imminent threat to the president than even the special counsel's investigation, according to several people close to Mr. Trump. As his lawyers went to court in New York on Friday to try to block prosecutors from reading files that were seized from the personal lawyer, Michael D. Cohen, this week, Mr. Trump found himself increasingly isolated in mounting a response. He continued to struggle to hire a new criminal lawyer, and some of his own aides were reluctant to advise him about a response for fear of being dragged into a criminal investigation themselves. The raids on Mr. Cohen came as part of a monthslong federal investigation based in New York, court records show, and were sweeping in their breadth. In addition to searching his home, office and hotel room, F. B. I. agents seized material from Mr. Cohen's cellphones, tablet, laptop and safe deposit box, according to people briefed on the warrants. Prosecutors revealed in court documents that they had already secretly obtained many of Mr. Cohen's emails. Mr. Trump called Mr. Cohen on Friday to\" check in,\" according to two people briefed on the call. Depending on what else was discussed, the call could be problematic, as lawyers typically advise their clients against discussing investigations. Mr. Cohen has publicly declared that he would defend the president to the end, but court documents show that prosecutors are building a significant case that could put pressure on him to cooperate and tell investigators what he knows. The documents seized by prosecutors could shed light on the president's relationship with a lawyer who has helped navigate some of Mr. Trump's thorniest personal and business dilemmas. Mr. Cohen served for more than a decade as a trusted fixer and, during the campaign, helped tamp down brewing scandals about women who claimed to have carried on affairs with Mr. Trump. Mr. Trump, Mr. Cohen and their teams were still scrambling on Friday to assess the damage from the raid early Monday morning. They remained unsure what had been taken, an uncertainty that has heightened the unease around Mr. Trump. Although his lawyers had projected confidence in their dealings with the special counsel, Robert S. Mueller III, they were caught flat-footed by the New York raids. The lawyers fear that Mr. Cohen will not be forthcoming with them about what was in his files, leaving them girding for the unknown. Mr. Cohen and Mr. Trump, through their lawyers, argued in federal court on Friday that many of the seized records were protected by attorney-client privilege. They asked for an order temporarily prohibiting prosecutors from reading the documents until the matter could be litigated. Mr. Cohen argued that he or an independent lawyer should be allowed to review the documents first.\" Those searches have been executed, and the evidence is locked down,\" Joanna C. Hendon, a lawyer for Mr. Trump, said in court.\" I'm not trying to delay. I'm just trying to ensure that it's done scrupulously.\" Mr. Cohen's lawyer, Stephen Ryan, wrote in a court filing that the search\" creates constitutional concerns regarding officers of the executive branch rummaging through the private and privileged papers of the president.\" Prosecutors argued that the previously seized emails revealed that Mr. Cohen was\" performing little to no legal work, and that zero emails were exchanged with President Trump.\" They said their investigation was focused on Mr. Cohen's business dealings, not his work as a lawyer. But it is difficult to extract Mr. Cohen from his work for Mr. Trump. For more than a decade, Mr. Trump has unleashed Mr. Cohen on his foes -- investigative journalists, business rivals and potential litigants. And the New York search warrant makes clear that the authorities are interested in his unofficial role in the campaign. Prosecutors demanded all communication with the campaign -- and in particular two advisers, Corey Lewandowski and Hope Hicks, according to two people briefed on the warrants. Prosecutors also seized recordings of conversations that Mr. Cohen had secretly made, but he told people in recent days that he did not tape his conversations with Mr. Trump. Mr. Cohen frequently taped conversations with adversaries and opposing lawyers, according to the two people briefed. The raids on Mr. Cohen surprised and angered the president, who has been frustrated with the special counsel investigation into Russia's 2016 election interference, the Kremlin's possible coordination with Trump associates and whether the president has tried to obstruct those inquiries. In response to the raids, Mr. Trump has considered firing Mr. Mueller, Attorney General Jeff Sessions and the deputy attorney general, Rod J. Rosenstein. On Friday, Mr. Trump's spirits were frayed in the morning as his lawyer battled in the Manhattan courtroom. But he grew cheerier as the day went on, an adviser said, buoyed by a report by the Justice Department's inspector general that was damning about a former F. B. I. official, Andrew G. McCabe, who he believed had tried to undermine him. Mr. Cohen's lawyers have called the raids of his offices and hotel room an overreach of the law. Prosecutors said on Friday that they had used a search warrant, rather than a subpoena, because they had evidence that Mr. Cohen's files might be permanently deleted -- by whom, the documents did not say. Many details in the documents were redacted, but prosecutors said they had found evidence of fraud and a\" lack of truthfulness\" on his part. Mr. Cohen wants his lawyers to be able to review the files and withhold privileged material before prosecutors can see them. As an alternative, he asked that an independent lawyer be allowed to review the files first. A judge scheduled a follow-up hearing for Monday and ordered Mr. Cohen to attend. The judge, Kimba M. Wood, was upset that he was not in court Friday. Federal agents seized documents that dated back years, some of which are related to payments to two women who have said they had affairs with Mr. Trump. Other documents seized included information about the role of The National Enquirer in silencing one of the women, people briefed on the investigation have said. Communications between lawyers and their clients are normally off limits to prosecutors, but there are exceptions, including when the materials are considered part of a continuing crime. Mr. Trump has viewed any investigation of his business and private life to be off limits to prosecutors, but the search warrants make clear that investigators consider those topics part of their case. Agents sought information about Karen McDougal, a former Playboy model who claims she had a nearly yearlong affair with Mr. Trump shortly after the birth of his youngest son in 2006. American Media Inc., which owns The Enquirer, paid Ms. McDougal $ 150, 000. The company's chief executive is a friend of Mr. Trump's. Agents also demanded information related to Stephanie Clifford, better known as Stormy Daniels, a pornographic film actress. Ms. Clifford has said she had sex with Mr. Trump while he was married. Mr. Cohen has acknowledged paying Ms. Clifford $ 130, 000 as part of a nondisclosure agreement to secure her silence days before Election Day. Mr. Trump recently told reporters he knew nothing about the agreement. Credit : MATT APUZZO, MICHAEL S. SCHMIDT, MAGGIE HABERMAN and EILEEN SULLIVAN ; Benjamin Weiser and William K. Rashbaum contributed reporting from New York.\n"
     ]
    }
   ],
   "source": [
    "sample_article_text = NYT_article_data.loc[:, 'source_text'].iloc[0]\n",
    "print(sample_article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_input_tokens = tokenizer.encode_plus(sample_article_text)\n",
    "# print(len(sample_article_ids['input_ids']))\n",
    "import torch\n",
    "device_name = 'cuda:2'\n",
    "model.to(device_name)\n",
    "with torch.no_grad():\n",
    "    test_input_ids = torch.LongTensor(test_input_tokens['input_ids']).reshape(1,-1)\n",
    "    test_attention = torch.LongTensor(test_input_tokens['attention_mask']).reshape(1,-1)\n",
    "    test_input_ids = test_input_ids.to(device_name)\n",
    "    test_attention = test_attention.to(device_name)\n",
    "    test_output = model.generate(test_input_ids)\n",
    "    test_input_ids = test_input_ids.to('cpu')\n",
    "    test_attention = test_attention.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1516])\n",
      "<s>WASHINGTON -- President Trump's advisers have concluded that a wide-ranging corruption investigation into his personal lawyer poses a greater and more imminent threat to the president than even the special counsel's investigation, according to several people close to Mr. Trump. As his lawyers went to court in New York on Friday to try to block prosecutors from reading files that were seized from the personal lawyer, Michael D. Cohen, this week, Mr. Trump found himself increasingly isolated in mounting a response. He continued to struggle to hire a new criminal lawyer, and some of his own aides were reluctant to advise him about a response for fear of being dragged into a criminal investigation themselves. The raids on Mr. Cohen came as part of a monthslong federal investigation based in New York, court records show, and were sweeping in their breadth. In addition to searching his home, office and hotel room, F. B. I. agents seized material from Mr. Cohen's cellphones, tablet, laptop and safe deposit box, according to people briefed on the warrants. Prosecutors revealed in court documents that they had already secretly obtained many of Mr. Cohen's emails. Mr. Trump called Mr. Cohen on Friday to\" check in,\" according to two people briefed on the call. Depending on what else was discussed, the call could be problematic, as lawyers typically advise their clients against discussing investigations. Mr. Cohen has publicly declared that he would defend the president to the end, but court documents show that prosecutors are building a significant case that could put pressure on him to cooperate and tell investigators what he knows. The documents seized by prosecutors could shed light on the president's relationship with a lawyer who has helped navigate some of Mr. Trump's thorniest personal and business dilemmas. Mr. Cohen served for more than a decade as a trusted fixer and, during the campaign, helped tamp down brewing scandals about women who claimed to have carried on affairs with Mr. Trump. Mr. Trump, Mr. Cohen and their teams were still scrambling on Friday to assess the damage from the raid early Monday morning. They remained unsure what had been taken, an uncertainty that has heightened the unease around Mr. Trump. Although his lawyers had projected confidence in their dealings with the special counsel, Robert S. Mueller III, they were caught flat-footed by the New York raids. The lawyers fear that Mr. Cohen will not be forthcoming with them about what was in his files, leaving them girding for the unknown. Mr. Cohen and Mr. Trump, through their lawyers, argued in federal court on Friday that many of the seized records were protected by attorney-client privilege. They asked for an order temporarily prohibiting prosecutors from reading the documents until the matter could be litigated. Mr. Cohen argued that he or an independent lawyer should be allowed to review the documents first.\" Those searches have been executed, and the evidence is locked down,\" Joanna C. Hendon, a lawyer for Mr. Trump, said in court.\" I'm not trying to delay. I'm just trying to ensure that it's done scrupulously.\" Mr. Cohen's lawyer, Stephen Ryan, wrote in a court filing that the search\" creates constitutional concerns regarding officers of the executive branch rummaging through the private and privileged papers of the president.\" Prosecutors argued that the previously seized emails revealed that Mr. Cohen was\" performing little to no legal work, and that zero emails were exchanged with President Trump.\" They said their investigation was focused on Mr. Cohen's business dealings, not his work as a lawyer. But it is difficult to extract Mr. Cohen from his work for Mr. Trump. For more than a decade, Mr. Trump has unleashed Mr. Cohen on his foes -- investigative journalists, business rivals and potential litigants. And the New York search warrant makes clear that the authorities are interested in his unofficial role in the campaign. Prosecutors demanded all communication with the campaign -- and in particular two advisers, Corey Lewandowski and Hope Hicks, according to two people briefed on the warrants. Prosecutors also seized recordings of conversations that Mr. Cohen had secretly made, but he told people in recent days that he did not tape his conversations with Mr. Trump. Mr. Cohen frequently taped conversations with adversaries and opposing lawyers, according to the two people briefed. The raids on Mr. Cohen surprised and angered the president, who has been frustrated with the special counsel investigation into Russia's 2016 election interference, the Kremlin's possible coordination with Trump associates and whether the president has tried to obstruct those inquiries. In response to the raids, Mr. Trump has considered firing Mr. Mueller, Attorney General Jeff Sessions and the deputy attorney general, Rod J. Rosenstein. On Friday, Mr. Trump's spirits were frayed in the morning as his lawyer battled in the Manhattan courtroom. But he grew cheerier as the day went on, an adviser said, buoyed by a report by the Justice Department's inspector general that was damning about a former F. B. I. official, Andrew G. McCabe, who he believed had tried to undermine him. Mr. Cohen's lawyers have called the raids of his offices and hotel room an overreach of the law. Prosecutors said on Friday that they had used a search warrant, rather than a subpoena, because they had evidence that Mr. Cohen's files might be permanently deleted -- by whom, the documents did not say. Many details in the documents were redacted, but prosecutors said they had found evidence of fraud and a\" lack of truthfulness\" on his part. Mr. Cohen wants his lawyers to be able to review the files and withhold privileged material before prosecutors can see them. As an alternative, he asked that an independent lawyer be allowed to review the files first. A judge scheduled a follow-up hearing for Monday and ordered Mr. Cohen to attend. The judge, Kimba M. Wood, was upset that he was not in court Friday. Federal agents seized documents that dated back years, some of which are related to payments to two women who have said they had affairs with Mr. Trump. Other documents seized included information about the role of The National Enquirer in silencing one of the women, people briefed on the investigation have said. Communications between lawyers and their clients are normally off limits to prosecutors, but there are exceptions, including when the materials are considered part of a continuing crime. Mr. Trump has viewed any investigation of his business and private life to be off limits to prosecutors, but the search warrants make clear that investigators consider those topics part of their case. Agents sought information about Karen McDougal, a former Playboy model who claims she had a nearly yearlong affair with Mr. Trump shortly after the birth of his youngest son in 2006. American Media Inc., which owns The Enquirer, paid Ms. McDougal $ 150, 000. The company's chief executive is a friend of Mr. Trump's. Agents also demanded information related to Stephanie Clifford, better known as Stormy Daniels, a pornographic film actress. Ms. Clifford has said she had sex with Mr. Trump while he was married. Mr. Cohen has acknowledged paying Ms. Clifford $ 130, 000 as part of a nondisclosure agreement to secure her silence days before Election Day. Mr. Trump recently told reporters he knew nothing about the agreement. Credit : MATT APUZZO, MICHAEL S. SCHMIDT, MAGGIE HABERMAN and EILEEN SULLIVAN ; Benjamin Weiser and William K. Rashbaum contributed reporting from New York.</s>\n",
      "<s>WASHINGTON -- President Trump's advisers have concluded that a wide-ranging corruption investigation into his personal lawyer poses a greater and more imminent threat to the president than even the special counsel's investigation, according to several people close to Mr. Trump. As his lawyers went to court in New York on Friday to try to block prosecutors from reading files that were seized from the personal lawyer, Michael D. Cohen, this week, Mr. Trump found himself increasingly isolated in mounting a response. He continued to struggle to hire a new criminal lawyer, and some of his own aides were reluctant to advise him about a response for fear of being dragged into a criminal investigation themselves. The raids on Mr. Cohen came as part of a monthslong federal investigation based in New York, court records show, and were sweeping in their breadth. In addition to searching his home, office and hotel room, F. B. I. agents seized material from Mr. Cohen's cellphones, tablet, laptop and safe deposit box, according to people briefed on the warrants. Prosecutors revealed in court documents that they had already secretly obtained many of Mr. Cohen's emails. Mr. Trump called Mr. Cohen on Friday to\" check in,\" according to two people briefed on the call. Depending on what else was discussed, the call could be problematic, as lawyers typically advise their clients against discussing investigations. Mr. Cohen has publicly declared that he would defend the president to the end, but court documents show that prosecutors are building a significant case that could put pressure on him to cooperate and tell investigators what he knows. The documents seized by prosecutors could shed light on the president's relationship with a lawyer who has helped navigate some of Mr. Trump's thorniest personal and business dilemmas. Mr. Cohen served for more than a decade as a trusted fixer and, during the campaign, helped tamp down brewing scandals about women who claimed to have carried on affairs with Mr. Trump. Mr. Trump, Mr. Cohen and their teams were still scrambling on Friday to assess the damage from the raid early Monday morning. They remained unsure what had been taken, an uncertainty that has heightened the unease around Mr. Trump. Although his lawyers had projected confidence in their dealings with the special counsel, Robert S. Mueller III, they were caught flat-footed by the New York raids. The lawyers fear that Mr. Cohen will not be forthcoming with them about what was in his files, leaving them girding for the unknown. Mr. Cohen and Mr. Trump, through their lawyers, argued in federal court on Friday that many of the seized records were protected by attorney-client privilege. They asked for an order temporarily prohibiting prosecutors from reading the documents until the matter could be litigated. Mr. Cohen argued that he or an independent lawyer should be allowed to review the documents first.\" Those searches have been executed, and the evidence is locked down,\" Joanna C. Hendon, a lawyer for Mr. Trump, said in court.\" I'm not trying to delay. I'm just trying to ensure that it's done scrupulously.\" Mr. Cohen's lawyer, Stephen Ryan, wrote in a court filing that the search\" creates constitutional concerns regarding officers of the executive branch rummaging through the private and privileged papers of the president.\" Prosecutors argued that the previously seized emails revealed that Mr. Cohen was\" performing little to no legal work, and that zero emails were exchanged with President Trump.\" They said their investigation was focused on Mr. Cohen's business dealings, not his work as a lawyer. But it is difficult to extract Mr. Cohen from his work for Mr. Trump. For more than a decade, Mr. Trump has unleashed Mr. Cohen on his foes -- investigative journalists, business rivals and potential litigants. And the New York search warrant makes clear that the authorities are interested in his unofficial role in the campaign. Prosecutors demanded all communication with the campaign -- and in particular two advisers, Corey Lewandowski and Hope Hicks, according to two people briefed on the warrants. Prosecutors also seized recordings of conversations that Mr. Cohen had secretly made, but he told people in recent days that he did not tape his conversations with Mr. Trump. Mr. Cohen frequently taped conversations with adversaries and opposing lawyers, according to the two people briefed. The raids on Mr. Cohen surprised and angered the president, who has been frustrated with the special counsel investigation into Russia's 2016 election interference, the Kremlin's possible coordination with Trump associates and whether the president has tried to obstruct those inquiries. In response to the raids, Mr. Trump has considered firing Mr. Mueller, Attorney General Jeff Sessions and the deputy attorney general, Rod J. Rosenstein. On Friday, Mr. Trump's spirits were frayed in the morning as his lawyer battled in the Manhattan courtroom. But he grew cheerier as the day went on, an adviser said, buoyed by a report by the Justice Department's inspector general that was damning about a former F. B. I. official, Andrew G. McCabe, who he believed had tried to undermine him. Mr. Cohen's lawyers have called the raids of his offices and hotel room an overreach of the law. Prosecutors said on Friday that they had used a search warrant, rather than a subpoena, because they had evidence that Mr. Cohen's files might be permanently deleted -- by whom, the documents did not say. Many details in the documents were redacted, but prosecutors said they had found evidence of fraud and a\" lack of truthfulness\" on his part. Mr. Cohen wants his lawyers to be able to review the files and withhold privileged material before prosecutors can see them. As an alternative, he asked that an independent lawyer be allowed to review the files first. A judge scheduled a follow-up hearing for Monday and ordered Mr. Cohen to attend. The judge, Kimba M. Wood, was upset that he was not in court Friday. Federal agents seized documents that dated back years, some of which are related to payments to two women who have said they had affairs with Mr. Trump. Other documents seized included information about the role of The National Enquirer in silencing one of the women, people briefed on the investigation have said. Communications between lawyers and their clients are normally off limits to prosecutors, but there are exceptions, including when the materials are considered part of a continuing crime. Mr. Trump has viewed any investigation of his business and private life to be off limits to prosecutors, but the search warrants make clear that investigators consider those topics part of their case. Agents sought information about Karen McDougal, a former Playboy model who claims she had a nearly yearlong affair with Mr. Trump shortly after the birth of his youngest son in 2006. American Media Inc., which owns The Enquirer, paid Ms. McDougal $ 150, 000. The company's chief executive is a friend of Mr. Trump's. Agents also demanded information related to Stephanie Clifford, better known as Stormy Daniels, a pornographic film actress. Ms. Clifford has said she had sex with Mr. Trump while he was married. Mr. Cohen has acknowledged paying Ms. Clifford $ 130, 000 as part of a nondisclosure agreement to secure her silence days before Election Day. Mr. Trump recently told reporters he knew nothing about the agreement. Credit : MATT APUZZO, MICHAEL S. SCHMIDT, MAGGIE HABERMAN and EILEEN SULLIVAN ; Benjamin Weiser and William K. Rashbaum contributed reporting from New York.</s>\n"
     ]
    }
   ],
   "source": [
    "print(test_output.shape)\n",
    "print(tokenizer.decode(test_input_ids[0, :]))\n",
    "print(tokenizer.decode(test_output[0, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! It seems that the Longformer doesn't actually generate text, it just copies it.\n",
    "\n",
    "Let's try to use the model but with the `BART` base, which is a known encoder/decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a136fcb91e2e433a98fd7047ddfcca51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=647693783.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "longformer_enc_dec_model = AutoModelForSeq2SeqLM.from_pretrained('allenai/led-base-16384', cache_dir='../../data/longformer_cache/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "longformer_enc_dec_model.config.max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abda30b417e0485da26957e362330a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=898822.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66467881413d4b98b7329fbddbd5f6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=456318.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "longformer_enc_dec_tokenizer = AutoTokenizer.from_pretrained('allenai/led-base-16384', cache_dir='../../data/longformer_cache/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WASHINGTON -- President Trump's advisers have concluded that a wide-ranging corruption investigation into his personal lawyer poses a greater and more imminent threat to the president than even the special counsel's investigation, according to several people close to Mr. Trump. As his lawyers went to court in New York on Friday to try to block prosecutors from reading files that were seized from the personal lawyer, Michael D. Cohen, this week, Mr. Trump found himself increasingly isolated in mounting a response. He continued to struggle to hire a new criminal lawyer, and some of his own aides were reluctant to advise him about a response for fear of being dragged into a criminal investigation themselves. The raids on Mr. Cohen came as part of a monthslong federal investigation based in New York, court records show, and were sweeping in their breadth. In addition to searching his home, office and hotel room, F. B. I. agents seized material from Mr. Cohen's cellphones, tablet, laptop and safe deposit box, according to people briefed on the warrants. Prosecutors revealed in court documents that they had already secretly obtained many of Mr. Cohen's emails. Mr. Trump called Mr. Cohen on Friday to\" check in,\" according to two people briefed on the call. Depending on what else was discussed, the call could be problematic, as lawyers typically advise their clients against discussing investigations. Mr. Cohen has publicly declared that he would defend the president to the end, but court documents show that prosecutors are building a significant case that could put pressure on him to cooperate and tell investigators what he knows. The documents seized by prosecutors could shed light on the president's relationship with a lawyer who has helped navigate some of Mr. Trump's thorniest personal and business dilemmas. Mr. Cohen served for more than a decade as a trusted fixer and, during the campaign, helped tamp down brewing scandals about women who claimed to have carried on affairs with Mr. Trump. Mr. Trump, Mr. Cohen and their teams were still scrambling on Friday to assess the damage from the raid early Monday morning. They remained unsure what had been taken, an uncertainty that has heightened the unease around Mr. Trump. Although his lawyers had projected confidence in their dealings with the special counsel, Robert S. Mueller III, they were caught flat-footed by the New York raids. The lawyers fear that Mr. Cohen will not be forthcoming with them about what was in his files, leaving them girding for the unknown. Mr. Cohen and Mr. Trump, through their lawyers, argued in federal court on Friday that many of the seized records were protected by attorney-client privilege. They asked for an order temporarily prohibiting prosecutors from reading the documents until the matter could be litigated. Mr. Cohen argued that he or an independent lawyer should be allowed to review the documents first.\" Those searches have been executed, and the evidence is locked down,\" Joanna C. Hendon, a lawyer for Mr. Trump, said in court.\" I'm not trying to delay. I'm just trying to ensure that it's done scrupulously.\" Mr. Cohen's lawyer, Stephen Ryan, wrote in a court filing that the search\" creates constitutional concerns regarding officers of the executive branch rummaging through the private and privileged papers of the president.\" Prosecutors argued that the previously seized emails revealed that Mr. Cohen was\" performing little to no legal work, and that zero emails were exchanged with President Trump.\" They said their investigation was focused on Mr. Cohen's business dealings, not his work as a lawyer. But it is difficult to extract Mr. Cohen from his work for Mr. Trump. For more than a decade, Mr. Trump has unleashed Mr. Cohen on his foes -- investigative journalists, business rivals and potential litigants. And the New York search warrant makes clear that the authorities are interested in his unofficial role in the campaign. Prosecutors demanded all communication with the campaign -- and in particular two advisers, Corey Lewandowski and Hope Hicks, according to two people briefed on the warrants. Prosecutors also seized recordings of conversations that Mr. Cohen had secretly made, but he told people in recent days that he did not tape his conversations with Mr. Trump. Mr. Cohen frequently taped conversations with adversaries and opposing lawyers, according to the two people briefed. The raids on Mr. Cohen surprised and angered the president, who has been frustrated with the special counsel investigation into Russia's 2016 election interference, the Kremlin's possible coordination with Trump associates and whether the president has tried to obstruct those inquiries. In response to the raids, Mr. Trump has considered firing Mr. Mueller, Attorney General Jeff Sessions and the deputy attorney general, Rod J. Rosenstein. On Friday, Mr. Trump's spirits were frayed in the morning as his lawyer battled in the Manhattan courtroom. But he grew cheerier as the day went on, an adviser said, buoyed by a report by the Justice Department's inspector general that was damning about a former F. B. I. official, Andrew G. McCabe, who he believed had tried to undermine him. Mr. Cohen's lawyers have called the raids of his offices and hotel room an overreach of the law. Prosecutors said on Friday that they had used a search warrant, rather than a subpoena, because they had evidence that Mr. Cohen's files might be permanently deleted -- by whom, the documents did not say. Many details in the documents were redacted, but prosecutors said they had found evidence of fraud and a\" lack of truthfulness\" on his part. Mr. Cohen wants his lawyers to be able to review the files and withhold privileged material before prosecutors can see them. As an alternative, he asked that an independent lawyer be allowed to review the files first. A judge scheduled a follow-up hearing for Monday and ordered Mr. Cohen to attend. The judge, Kimba M. Wood, was upset that he was not in court Friday. Federal agents seized documents that dated back years, some of which are related to payments to two women who have said they had affairs with Mr. Trump. Other documents seized included information about the role of The National Enquirer in silencing one of the women, people briefed on the investigation have said. Communications between lawyers and their clients are normally off limits to prosecutors, but there are exceptions, including when the materials are considered part of a continuing crime. Mr. Trump has viewed any investigation of his business and private life to be off limits to prosecutors, but the search warrants make clear that investigators consider those topics part of their case. Agents sought information about Karen McDougal, a former Playboy model who claims she had a nearly yearlong affair with Mr. Trump shortly after the birth of his youngest son in 2006. American Media Inc., which owns The Enquirer, paid Ms. McDougal $ 150, 000. The company's chief executive is a friend of Mr. Trump's. Agents also demanded information related to Stephanie Clifford, better known as Stormy Daniels, a pornographic film actress. Ms. Clifford has said she had sex with Mr. Trump while he was married. Mr. Cohen has acknowledged paying Ms. Clifford $ 130, 000 as part of a nondisclosure agreement to secure her silence days before Election Day. Mr. Trump recently told reporters he knew nothing about the agreement. Credit : MATT APUZZO, MICHAEL S. SCHMIDT, MAGGIE HABERMAN and EILEEN SULLIVAN ; Benjamin Weiser and William K. Rashbaum contributed reporting from New York.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LEDForConditionalGeneration(\n",
       "  (led): LEDModel(\n",
       "    (shared): Embedding(50265, 768, padding_idx=1)\n",
       "    (encoder): LEDEncoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): LEDLearnedPositionalEmbedding(16384, 768, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): LEDDecoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): LEDLearnedPositionalEmbedding(1024, 768, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_article_text = NYT_article_data.loc[:, 'source_text'].iloc[0]\n",
    "print(sample_article_text)\n",
    "test_input_tokens = longformer_enc_dec_tokenizer.encode_plus(sample_article_text)\n",
    "# print(len(sample_article_ids['input_ids']))\n",
    "import torch\n",
    "device_name = 'cuda:2'\n",
    "longformer_enc_dec_model.to(device_name)\n",
    "with torch.no_grad():\n",
    "    test_input_ids = torch.LongTensor(test_input_tokens['input_ids']).reshape(1,-1)\n",
    "    test_attention = torch.LongTensor(test_input_tokens['attention_mask']).reshape(1,-1)\n",
    "    test_input_ids = test_input_ids.to(device_name)\n",
    "    test_attention = test_attention.to(device_name)\n",
    "    test_output = longformer_enc_dec_model.generate(test_input_ids, num_beams=8, temperature=1.0)\n",
    "    test_input_ids = test_input_ids.to('cpu')\n",
    "    test_attention = test_attention.to('cpu')\n",
    "    test_output = test_output.to('cpu')\n",
    "longformer_enc_dec_model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1516])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s><s>WASHINGTON -- President Trump's advisers have called the raid of his offices and hotel room an overreach of the law. Prosecutors said on Friday that they had used a search warrant, rather than a subpoena, because they had evidence that Mr. Cohen's files might be permanently deleted -- by whom, the documents did not say. Many details in the documents were redacted, but prosecutors said they had found evidence of fraud and a\" lack of truthfulness\" on his part. Mr. Cohen wants his lawyers to be able to review the files and withhold privileged material before prosecutors can see them. As an alternative, he asked that an independent lawyer be allowed to review the files first. A judge scheduled a follow-up hearing for Monday and ordered Mr. Cohen to attend. The judge, Kimba M. Wood, was upset that he was not in court Friday. Federal agents seized documents that dated back years, some of which are related to payments to two women who have said they had affairs with Mr. Trump. Other documents seized included information about the role of The National Enquirer in silencing one of the women, people briefed on the investigation have said. Communications between lawyers and their clients are normally off limits to prosecutors, but there are exceptions, including when the materials are considered part of a continuing crime. Mr. Trump has viewed any investigation of his business and private life to be off limits to prosecutors, but the search warrants make clear that investigators consider those topics part of their case. Agents sought information about Mr. Cohen's communications with Mr. Trump. The documents seized included information about the role of The National Enquirer in silencing one of the women, people briefed on the investigation have said. Communications between lawyers and their clients are normally off limits to prosecutors, but there are exceptions, including when the materials are considered part of a continuing crime. Mr. Trump has viewed any investigation of his business and private life to be off limits to prosecutors, but the search warrants make clear that investigators consider those topics part of their case. Agents sought information about Karen McDougal, a former Playboy model who claims she had a nearly yearlong affair with Mr. Trump shortly after the birth of his youngest son in 2006. American Media Inc., which owns The Enquirer, paid Ms. McDougal $ 150, 000. The company's chief executive is a friend of Mr. Trump's. Agents also demanded information related to Stephanie Clifford, better known as Stormy Daniels, a pornographic film actress. Ms. Clifford has said she had sex with\n"
     ]
    }
   ],
   "source": [
    "print(longformer_enc_dec_tokenizer.decode(torch.LongTensor(test_output[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! We see that the model generally copies the input data without really \"processing\" it. This means that there's lots of room for improvement with training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with LongFormer\n",
    "Next, let's adapt the model that we built from scratch [here](reader_aware_question_generation_tests.ipynb) and change it to work with the `LongFormer` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 1 GPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## arguments\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
    "    )\n",
    "    freeze_encoder: bool = field(default=False, metadata={\"help\": \"Whether tp freeze the encoder.\"})\n",
    "    freeze_embeds: bool = field(default=False, metadata={\"help\": \"Whether  to freeze the embeddings.\"})\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "    data_dir: str = field(\n",
    "        metadata={\"help\": \"The input data dir. Should contain the .tsv files (or other data files) for the task.\"}\n",
    "    )\n",
    "    task: Optional[str] = field(\n",
    "        default=\"summarization\",\n",
    "        metadata={\"help\": \"Task name, summarization (or summarization_{dataset} for pegasus) or translation\"},\n",
    "    )\n",
    "    max_source_length: Optional[int] = field(\n",
    "        default=1024,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    max_target_length: Optional[int] = field(\n",
    "        default=128,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total sequence length for target text after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    val_max_target_length: Optional[int] = field(\n",
    "        default=142,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total sequence length for validation target text after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded. \"\n",
    "            \"This argument is also used to override the ``max_length`` param of ``model.generate``, which is used \"\n",
    "            \"during ``evaluate`` and ``predict``.\"\n",
    "        },\n",
    "    )\n",
    "    test_max_target_length: Optional[int] = field(\n",
    "        default=142,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total sequence length for test target text after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    n_train: Optional[int] = field(default=-1, metadata={\"help\": \"# training examples. -1 means use all.\"})\n",
    "    n_val: Optional[int] = field(default=-1, metadata={\"help\": \"# validation examples. -1 means use all.\"})\n",
    "    n_test: Optional[int] = field(default=-1, metadata={\"help\": \"# test examples. -1 means use all.\"})\n",
    "    src_lang: Optional[str] = field(default=None, metadata={\"help\": \"Source language id for translation.\"})\n",
    "    tgt_lang: Optional[str] = field(default=None, metadata={\"help\": \"Target language id for translation.\"})\n",
    "    eval_beams: Optional[int] = field(default=None, metadata={\"help\": \"# num_beams to use for evaluation.\"})\n",
    "    ignore_pad_token_for_loss: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"If only pad tokens should be ignored. This assumes that `config.pad_token_id` is defined.\"},\n",
    "    )\n",
    "        \n",
    "from transformers.training_args import TrainingArguments\n",
    "@dataclass\n",
    "class Seq2SeqTrainingArguments(TrainingArguments):\n",
    "    \"\"\"\n",
    "    sortish_sampler (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
    "        Whether to use a `sortish sampler` or not. Only possible if the underlying datasets are `Seq2SeqDataset` for\n",
    "        now but will become generally available in the near future.\n",
    "        It sorts the inputs according to lengths in order to minimize the padding size, with a bit of randomness for\n",
    "        the training set.\n",
    "    predict_with_generate (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
    "        Whether to use generate to calculate generative metrics (ROUGE, BLEU).\n",
    "    \"\"\"\n",
    "\n",
    "    sortish_sampler: bool = field(default=False, metadata={\"help\": \"Whether to use SortishSampler or not.\"})\n",
    "    predict_with_generate: bool = field(\n",
    "        default=False, metadata={\"help\": \"Whether to use generate to calculate generative metrics (ROUGE, BLEU).\"}\n",
    "    )\n",
    "## training\n",
    "from transformers import Trainer, PreTrainedModel\n",
    "from torch import nn\n",
    "from typing import Union, Any\n",
    "from transformers.configuration_utils import PretrainedConfig\n",
    "class FSMTConfig(PretrainedConfig):\n",
    "    r\"\"\"\n",
    "    This is the configuration class to store the configuration of a :class:`~transformers.FSMTModel`. It is used to\n",
    "    instantiate a FSMT model according to the specified arguments, defining the model architecture.\n",
    "    Configuration objects inherit from :class:`~transformers.PretrainedConfig` and can be used to control the model\n",
    "    outputs. Read the documentation from :class:`~transformers.PretrainedConfig` for more information.\n",
    "    Args:\n",
    "        langs (:obj:`List[str]`):\n",
    "            A list with source language and target_language (e.g., ['en', 'ru']).\n",
    "        src_vocab_size (:obj:`int`):\n",
    "            Vocabulary size of the encoder. Defines the number of different tokens that can be represented by the\n",
    "            :obj:`inputs_ids` passed to the forward method in the encoder.\n",
    "        tgt_vocab_size (:obj:`int`):\n",
    "            Vocabulary size of the decoder. Defines the number of different tokens that can be represented by the\n",
    "            :obj:`inputs_ids` passed to the forward method in the decoder.\n",
    "        d_model (:obj:`int`, `optional`, defaults to 1024):\n",
    "            Dimensionality of the layers and the pooler layer.\n",
    "        encoder_layers (:obj:`int`, `optional`, defaults to 12):\n",
    "            Number of encoder layers.\n",
    "        decoder_layers (:obj:`int`, `optional`, defaults to 12):\n",
    "            Number of decoder layers.\n",
    "        encoder_attention_heads (:obj:`int`, `optional`, defaults to 16):\n",
    "            Number of attention heads for each attention layer in the Transformer encoder.\n",
    "        decoder_attention_heads (:obj:`int`, `optional`, defaults to 16):\n",
    "            Number of attention heads for each attention layer in the Transformer decoder.\n",
    "        decoder_ffn_dim (:obj:`int`, `optional`, defaults to 4096):\n",
    "            Dimensionality of the \"intermediate\" (often named feed-forward) layer in decoder.\n",
    "        encoder_ffn_dim (:obj:`int`, `optional`, defaults to 4096):\n",
    "            Dimensionality of the \"intermediate\" (often named feed-forward) layer in decoder.\n",
    "        activation_function (:obj:`str` or :obj:`Callable`, `optional`, defaults to :obj:`\"relu\"`):\n",
    "            The non-linear activation function (function or string) in the encoder and pooler. If string,\n",
    "            :obj:`\"gelu\"`, :obj:`\"relu\"`, :obj:`\"silu\"` and :obj:`\"gelu_new\"` are supported.\n",
    "        dropout (:obj:`float`, `optional`, defaults to 0.1):\n",
    "            The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.\n",
    "        attention_dropout (:obj:`float`, `optional`, defaults to 0.0):\n",
    "            The dropout ratio for the attention probabilities.\n",
    "        activation_dropout (:obj:`float`, `optional`, defaults to 0.0):\n",
    "            The dropout ratio for activations inside the fully connected layer.\n",
    "        max_position_embeddings (:obj:`int`, `optional`, defaults to 1024):\n",
    "            The maximum sequence length that this model might ever be used with. Typically set this to something large\n",
    "            just in case (e.g., 512 or 1024 or 2048).\n",
    "        init_std (:obj:`float`, `optional`, defaults to 0.02):\n",
    "            The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n",
    "        scale_embedding (:obj:`bool`, `optional`, defaults to :obj:`True`):\n",
    "            Scale embeddings by diving by sqrt(d_model).\n",
    "        bos_token_id (:obj:`int`, `optional`, defaults to 0)\n",
    "            Beginning of stream token id.\n",
    "        pad_token_id (:obj:`int`, `optional`, defaults to 1)\n",
    "            Padding token id.\n",
    "        eos_token_id (:obj:`int`, `optional`, defaults to 2)\n",
    "            End of stream token id.\n",
    "        decoder_start_token_id (:obj:`int`, `optional`):\n",
    "            This model starts decoding with :obj:`eos_token_id`\n",
    "        encoder_layerdrop: (:obj:`float`, `optional`, defaults to 0.0):\n",
    "            Google \"layerdrop arxiv\", as its not explainable in one line.\n",
    "        decoder_layerdrop: (:obj:`float`, `optional`, defaults to 0.0):\n",
    "            Google \"layerdrop arxiv\", as its not explainable in one line.\n",
    "        is_encoder_decoder (:obj:`bool`, `optional`, defaults to :obj:`True`):\n",
    "            Whether this is an encoder/decoder model.\n",
    "        tie_word_embeddings (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
    "            Whether to tie input and output embeddings.\n",
    "        num_beams (:obj:`int`, `optional`, defaults to 5)\n",
    "            Number of beams for beam search that will be used by default in the :obj:`generate` method of the model. 1\n",
    "            means no beam search.\n",
    "        length_penalty (:obj:`float`, `optional`, defaults to 1)\n",
    "            Exponential penalty to the length that will be used by default in the :obj:`generate` method of the model.\n",
    "        early_stopping (:obj:`bool`, `optional`, defaults to :obj:`False`)\n",
    "            Flag that will be used by default in the :obj:`generate` method of the model. Whether to stop the beam\n",
    "            search when at least ``num_beams`` sentences are finished per batch or not.\n",
    "        use_cache (:obj:`bool`, `optional`, defaults to :obj:`True`):\n",
    "            Whether or not the model should return the last key/values attentions (not used by all models).\n",
    "        Examples::\n",
    "            >>> from transformers import FSMTConfig, FSMTModel\n",
    "            >>> config = FSMTConfig.from_pretrained('facebook/wmt19-en-ru')\n",
    "            >>> model = FSMTModel(config)\n",
    "    \"\"\"\n",
    "    model_type = \"fsmt\"\n",
    "\n",
    "    # update the defaults from config file\n",
    "    def __init__(\n",
    "        self,\n",
    "        langs=[\"en\", \"de\"],\n",
    "        src_vocab_size=42024,\n",
    "        tgt_vocab_size=42024,\n",
    "        activation_function=\"relu\",\n",
    "        d_model=1024,\n",
    "        max_length=200,\n",
    "        max_position_embeddings=1024,\n",
    "        encoder_ffn_dim=4096,\n",
    "        encoder_layers=12,\n",
    "        encoder_attention_heads=16,\n",
    "        encoder_layerdrop=0.0,\n",
    "        decoder_ffn_dim=4096,\n",
    "        decoder_layers=12,\n",
    "        decoder_attention_heads=16,\n",
    "        decoder_layerdrop=0.0,\n",
    "        attention_dropout=0.0,\n",
    "        dropout=0.1,\n",
    "        activation_dropout=0.0,\n",
    "        init_std=0.02,\n",
    "        decoder_start_token_id=2,\n",
    "        is_encoder_decoder=True,\n",
    "        scale_embedding=True,\n",
    "        tie_word_embeddings=False,\n",
    "        num_beams=5,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=False,\n",
    "        use_cache=True,\n",
    "        pad_token_id=1,\n",
    "        bos_token_id=0,\n",
    "        eos_token_id=2,\n",
    "        **common_kwargs\n",
    "    ):\n",
    "        if \"hidden_size\" in common_kwargs:\n",
    "            raise ValueError(\"hidden size is called d_model\")\n",
    "        super().__init__(\n",
    "            pad_token_id=pad_token_id,\n",
    "            bos_token_id=bos_token_id,\n",
    "            eos_token_id=eos_token_id,\n",
    "            decoder_start_token_id=decoder_start_token_id,\n",
    "            is_encoder_decoder=is_encoder_decoder,\n",
    "            tie_word_embeddings=tie_word_embeddings,\n",
    "            **common_kwargs,\n",
    "        )\n",
    "        self.langs = langs\n",
    "        self.src_vocab_size = src_vocab_size\n",
    "        self.tgt_vocab_size = tgt_vocab_size\n",
    "        self.d_model = d_model  # encoder_embed_dim and decoder_embed_dim\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.encoder_ffn_dim = encoder_ffn_dim\n",
    "        self.encoder_layers = self.num_hidden_layers = encoder_layers\n",
    "        self.encoder_attention_heads = encoder_attention_heads\n",
    "        self.encoder_layerdrop = encoder_layerdrop\n",
    "        self.decoder_layerdrop = decoder_layerdrop\n",
    "        self.decoder_ffn_dim = decoder_ffn_dim\n",
    "        self.decoder_layers = decoder_layers\n",
    "        self.decoder_attention_heads = decoder_attention_heads\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.init_std = init_std  # Normal(0, this parameter)\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "        self.num_beams = num_beams\n",
    "        self.length_penalty = length_penalty\n",
    "        self.early_stopping = early_stopping\n",
    "\n",
    "        self.decoder = DecoderConfig(vocab_size=tgt_vocab_size, bos_token_id=eos_token_id)\n",
    "\n",
    "        self.scale_embedding = scale_embedding  # scale factor will be sqrt(d_model) if True\n",
    "\n",
    "        # 3 Types of Dropout\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.activation_dropout = activation_dropout\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.use_cache = use_cache\n",
    "\n",
    "    @property\n",
    "    def num_attention_heads(self) -> int:\n",
    "        return self.encoder_attention_heads\n",
    "\n",
    "    @property\n",
    "    def hidden_size(self) -> int:\n",
    "        return self.d_model\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"\n",
    "        Serializes this instance to a Python dictionary. Override the default `to_dict()` from `PretrainedConfig`.\n",
    "        Returns:\n",
    "            :obj:`Dict[str, any]`: Dictionary of all the attributes that make up this configuration instance,\n",
    "        \"\"\"\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        output[\"decoder\"] = self.decoder.to_dict()\n",
    "        output[\"model_type\"] = self.__class__.model_type\n",
    "        return output\n",
    "import torch\n",
    "from typing import Callable, Dict, Tuple, List\n",
    "from enum import Enum\n",
    "from transformers.file_utils import is_torch_tpu_available\n",
    "from torch.utils.data import DistributedSampler, RandomSampler\n",
    "from transformers.optimization import Adafactor, get_constant_schedule, get_constant_schedule_with_warmup, get_cosine_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup, get_linear_schedule_with_warmup, get_polynomial_decay_schedule_with_warmup\n",
    "class ParallelMode(Enum):\n",
    "    NOT_PARALLEL = \"not_parallel\"\n",
    "    NOT_DISTRIBUTED = \"not_distributed\"\n",
    "    DISTRIBUTED = \"distributed\"\n",
    "    TPU = \"tpu\"\n",
    "arg_to_scheduler = {\n",
    "    \"linear\": get_linear_schedule_with_warmup,\n",
    "    \"cosine\": get_cosine_schedule_with_warmup,\n",
    "    \"cosine_w_restarts\": get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "    \"polynomial\": get_polynomial_decay_schedule_with_warmup,\n",
    "    \"constant\": get_constant_schedule,\n",
    "    \"constant_w_warmup\": get_constant_schedule_with_warmup,\n",
    "}\n",
    "class Seq2SeqTrainer(Trainer):\n",
    "    def __init__(self, config=None, data_args=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        if config is None:\n",
    "            assert isinstance(\n",
    "                self.model, PreTrainedModel\n",
    "            ), f\"If no `config` is passed the model to be trained has to be of type `PreTrainedModel`, but is {self.model.__class__}\"\n",
    "            self.config = self._actual_model(self.model).config\n",
    "        else:\n",
    "            self.config = config\n",
    "\n",
    "        self.data_args = data_args\n",
    "        self.vocab_size = self.config.tgt_vocab_size if isinstance(self.config, FSMTConfig) else self.config.vocab_size\n",
    "\n",
    "        if self.args.label_smoothing != 0 or (self.data_args is not None and self.data_args.ignore_pad_token_for_loss):\n",
    "            assert (\n",
    "                self.config.pad_token_id is not None\n",
    "            ), \"Make sure that `config.pad_token_id` is correcly defined when ignoring `pad_token` for loss calculation or doing label smoothing.\"\n",
    "\n",
    "        if self.config.pad_token_id is None and self.config.eos_token_id is not None:\n",
    "            logger.warn(\n",
    "                f\"The `config.pad_token_id` is `None`. Using `config.eos_token_id` = {self.config.eos_token_id} for padding..\"\n",
    "            )\n",
    "\n",
    "        if self.args.label_smoothing == 0:\n",
    "            self.loss_fn = torch.nn.CrossEntropyLoss(ignore_index=self.config.pad_token_id)\n",
    "        else:\n",
    "            # dynamically import label_smoothed_nll_loss\n",
    "            from utils import label_smoothed_nll_loss\n",
    "\n",
    "            self.loss_fn = label_smoothed_nll_loss\n",
    "\n",
    "    def create_optimizer_and_scheduler(self, num_training_steps: int):\n",
    "        \"\"\"\n",
    "        Setup the optimizer and the learning rate scheduler.\n",
    "        We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the\n",
    "        Trainer's init through :obj:`optimizers`, or subclass and override this method in a subclass.\n",
    "        \"\"\"\n",
    "        if self.optimizer is None:\n",
    "            no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "            optimizer_grouped_parameters = [\n",
    "                {\n",
    "                    \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                    \"weight_decay\": self.args.weight_decay,\n",
    "                },\n",
    "                {\n",
    "                    \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                    \"weight_decay\": 0.0,\n",
    "                },\n",
    "            ]\n",
    "            optimizer_cls = Adafactor if self.args.adafactor else AdamW\n",
    "            if self.args.adafactor:\n",
    "                optimizer_cls = Adafactor\n",
    "                optimizer_kwargs = {\"scale_parameter\": False, \"relative_step\": False}\n",
    "            else:\n",
    "                optimizer_cls = AdamW\n",
    "                optimizer_kwargs = {\n",
    "                    \"betas\": (self.args.adam_beta1, self.args.adam_beta2),\n",
    "                    \"eps\": self.args.adam_epsilon,\n",
    "                }\n",
    "            optimizer_kwargs[\"lr\"] = self.args.learning_rate\n",
    "            if self.sharded_dpp:\n",
    "                self.optimizer = OSS(\n",
    "                    params=optimizer_grouped_parameters,\n",
    "                    optim=optimizer_cls,\n",
    "                    **optimizer_kwargs,\n",
    "                )\n",
    "            else:\n",
    "                self.optimizer = optimizer_cls(optimizer_grouped_parameters, **optimizer_kwargs)\n",
    "\n",
    "        if self.lr_scheduler is None:\n",
    "            self.lr_scheduler = self._get_lr_scheduler(num_training_steps)\n",
    "        else:  # ignoring --lr_scheduler\n",
    "            logger.warn(\"scheduler is passed to `Seq2SeqTrainer`, `--lr_scheduler` arg is ignored.\")\n",
    "\n",
    "    def _get_lr_scheduler(self, num_training_steps):\n",
    "        schedule_func = arg_to_scheduler[self.args.lr_scheduler]\n",
    "        if self.args.lr_scheduler == \"constant\":\n",
    "            scheduler = schedule_func(self.optimizer)\n",
    "        elif self.args.lr_scheduler == \"constant_w_warmup\":\n",
    "            scheduler = schedule_func(self.optimizer, num_warmup_steps=self.args.warmup_steps)\n",
    "        else:\n",
    "            scheduler = schedule_func(\n",
    "                self.optimizer, num_warmup_steps=self.args.warmup_steps, num_training_steps=num_training_steps\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    def _get_train_sampler(self) -> Optional[torch.utils.data.sampler.Sampler]:\n",
    "        if isinstance(self.train_dataset, torch.utils.data.IterableDataset):\n",
    "            return None\n",
    "        elif is_torch_tpu_available():\n",
    "            return get_tpu_sampler(self.train_dataset)\n",
    "        else:\n",
    "            if self.args.sortish_sampler:\n",
    "                self.train_dataset.make_sortish_sampler(\n",
    "                    self.args.per_device_train_batch_size,\n",
    "                    distributed=(self.args.parallel_mode == ParallelMode.DISTRIBUTED),\n",
    "                )\n",
    "\n",
    "            return (\n",
    "                RandomSampler(self.train_dataset)\n",
    "                if self.args.local_rank == -1\n",
    "                else DistributedSampler(self.train_dataset)\n",
    "            )\n",
    "\n",
    "    def _compute_loss(self, model, inputs, labels):\n",
    "        if self.args.label_smoothing == 0:\n",
    "            if self.data_args is not None and self.data_args.ignore_pad_token_for_loss:\n",
    "                # force training to ignore pad token\n",
    "                logits = model(**inputs, use_cache=False)[0]\n",
    "                loss = self.loss_fn(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "            else:\n",
    "                # compute usual loss via models\n",
    "                loss, logits = model(**inputs, labels=labels, use_cache=False)[:2]\n",
    "        else:\n",
    "            # compute label smoothed loss\n",
    "            logits = model(**inputs, use_cache=False)[0]\n",
    "            lprobs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "            loss, _ = self.loss_fn(lprobs, labels, self.args.label_smoothing, ignore_index=self.config.pad_token_id)\n",
    "        return loss, logits\n",
    "\n",
    "    def compute_loss(self, model, inputs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        loss, _ = self._compute_loss(model, inputs, labels)\n",
    "        return loss\n",
    "\n",
    "    def prediction_step(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        inputs: Dict[str, Union[torch.Tensor, Any]],\n",
    "        prediction_loss_only: bool,\n",
    "        ignore_keys: Optional[List[str]] = None,\n",
    "    ) -> Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Perform an evaluation step on :obj:`model` using obj:`inputs`.\n",
    "        Subclass and override to inject custom behavior.\n",
    "        Args:\n",
    "            model (:obj:`nn.Module`):\n",
    "                The model to evaluate.\n",
    "            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "                The inputs and targets of the model.\n",
    "                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
    "                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n",
    "            prediction_loss_only (:obj:`bool`):\n",
    "                Whether or not to return the loss only.\n",
    "        Return:\n",
    "            Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "            A tuple with the loss, logits and labels (each being optional).\n",
    "        \"\"\"\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "\n",
    "        gen_kwargs = {\n",
    "            \"max_length\": self.data_args.val_max_target_length\n",
    "            if self.data_args is not None\n",
    "            else self.config.max_length,\n",
    "        }\n",
    "\n",
    "        if self.args.predict_with_generate and not self.args.prediction_loss_only:\n",
    "            generated_tokens = self.model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                **gen_kwargs,\n",
    "            )\n",
    "            # in case the batch is shorter than max length, the output should be padded\n",
    "            if generated_tokens.shape[-1] < gen_kwargs[\"max_length\"]:\n",
    "                generated_tokens = self._pad_tensors_to_max_len(generated_tokens, gen_kwargs[\"max_length\"])\n",
    "\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        with torch.no_grad():\n",
    "            # compute loss on predict data\n",
    "            loss, logits = self._compute_loss(model, inputs, labels)\n",
    "\n",
    "        loss = loss.mean().detach()\n",
    "        if self.args.prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "\n",
    "        logits = generated_tokens if self.args.predict_with_generate else logits\n",
    "\n",
    "        if labels.shape[-1] < gen_kwargs[\"max_length\"]:\n",
    "            labels = self._pad_tensors_to_max_len(labels, gen_kwargs[\"max_length\"])\n",
    "\n",
    "        return (loss, logits, labels)\n",
    "\n",
    "    def _pad_tensors_to_max_len(self, tensor, max_length):\n",
    "        # If PAD token is not defined at least EOS token has to be defined\n",
    "        pad_token_id = self.config.pad_token_id if self.config.pad_token_id is not None else self.config.eos_token_id\n",
    "\n",
    "        if pad_token_id is None:\n",
    "            raise ValueError(\n",
    "                f\"Make sure that either `config.pad_token_id` or `config.eos_token_id` is defined if tensor has to be padded to `max_length`={max_length}\"\n",
    "            )\n",
    "\n",
    "        padded_tensor = pad_token_id * torch.ones(\n",
    "            (tensor.shape[0], max_length), dtype=tensor.dtype, device=tensor.device\n",
    "        )\n",
    "        padded_tensor[:, : tensor.shape[-1]] = tensor\n",
    "        return padded_tensor\n",
    "def convert_ids_to_clean_str(token_ids, tokenizer):\n",
    "    tokens = tokenizer.convert_ids_to_tokens(token_ids, skip_special_tokens=True)\n",
    "    token_str = tokenizer.convert_tokens_to_string(tokens)\n",
    "    return token_str\n",
    "from transformers import BartTokenizer\n",
    "class Seq2SeqDataCollator:\n",
    "    def __init__(self, tokenizer, data_args, tpu_num_cores=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        assert (\n",
    "            self.pad_token_id is not None\n",
    "        ), f\"pad_token_id is not defined for ({self.tokenizer.__class__.__name__}), it must be defined.\"\n",
    "        self.data_args = data_args\n",
    "        self.tpu_num_cores = tpu_num_cores\n",
    "        self.dataset_kwargs = {\"add_prefix_space\": True} if isinstance(tokenizer, BartTokenizer) else {}\n",
    "        if data_args.src_lang is not None:\n",
    "            self.dataset_kwargs[\"src_lang\"] = data_args.src_lang\n",
    "        if data_args.tgt_lang is not None:\n",
    "            self.dataset_kwargs[\"tgt_lang\"] = data_args.tgt_lang\n",
    "\n",
    "    def __call__(self, batch) -> Dict[str, torch.Tensor]:\n",
    "        if hasattr(self.tokenizer, \"prepare_seq2seq_batch\"):\n",
    "            batch = self._encode(batch)\n",
    "            input_ids, attention_mask, labels = (\n",
    "                batch[\"input_ids\"],\n",
    "                batch[\"attention_mask\"],\n",
    "                batch[\"labels\"],\n",
    "            )\n",
    "        else:\n",
    "            input_ids = torch.stack([x[\"input_ids\"] for x in batch])\n",
    "            attention_mask = torch.stack([x[\"attention_mask\"] for x in batch])\n",
    "            labels = torch.stack([x[\"labels\"] for x in batch])\n",
    "\n",
    "            labels = trim_batch(labels, self.pad_token_id)\n",
    "            input_ids, attention_mask = trim_batch(input_ids, self.pad_token_id, attention_mask=attention_mask)\n",
    "\n",
    "        batch = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    def _shift_right_t5(self, input_ids):\n",
    "        # shift inputs to the right\n",
    "        shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "        shifted_input_ids[..., 1:] = input_ids[..., :-1].clone()\n",
    "        shifted_input_ids[..., 0] = self.pad_token_id\n",
    "        return shifted_input_ids\n",
    "\n",
    "    def _encode(self, batch) -> Dict[str, torch.Tensor]:\n",
    "        batch_encoding = self.tokenizer.prepare_seq2seq_batch(\n",
    "#             [x[\"source_text\"] for x in batch],\n",
    "#             tgt_texts=[x[\"target_text\"] for x in batch],\n",
    "            [convert_ids_to_clean_str(x['source_ids'], self.tokenizer) for x in batch],\n",
    "            tgt_texts=[convert_ids_to_clean_str(x['target_ids'], self.tokenizer) for x in batch],\n",
    "            max_length=self.data_args.max_source_length,\n",
    "            max_target_length=self.data_args.max_target_length,\n",
    "            padding=\"max_length\" if self.tpu_num_cores is not None else \"longest\",  # TPU hack\n",
    "            return_tensors=\"pt\",\n",
    "            **self.dataset_kwargs,\n",
    "        )\n",
    "        return batch_encoding.data\n",
    "## evaluation\n",
    "from transformers import PreTrainedTokenizer, EvalPrediction\n",
    "from sacrebleu import corpus_bleu\n",
    "import numpy as np\n",
    "def calculate_bleu(output_lns, refs_lns, **kwargs) -> dict:\n",
    "    \"\"\"Uses sacrebleu's corpus_bleu implementation.\"\"\"\n",
    "    return {\"bleu\": round(corpus_bleu(output_lns, [refs_lns], **kwargs).score, 4)}\n",
    "def build_compute_metrics_fn(task_name: str, tokenizer: PreTrainedTokenizer) -> Callable[[EvalPrediction], Dict]:\n",
    "    def non_pad_len(tokens: np.ndarray) -> int:\n",
    "        return np.count_nonzero(tokens != tokenizer.pad_token_id)\n",
    "\n",
    "    def decode_pred(pred: EvalPrediction) -> Tuple[List[str], List[str]]:\n",
    "        pred_str = tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)\n",
    "        label_str = tokenizer.batch_decode(pred.label_ids, skip_special_tokens=True)\n",
    "        pred_str = lmap(str.strip, pred_str)\n",
    "        label_str = lmap(str.strip, label_str)\n",
    "        return pred_str, label_str\n",
    "\n",
    "    def summarization_metrics(pred: EvalPrediction) -> Dict:\n",
    "        pred_str, label_str = decode_pred(pred)\n",
    "        rouge: Dict = calculate_rouge(pred_str, label_str)\n",
    "        summ_len = np.round(np.mean(lmap(non_pad_len, pred.predictions)), 1)\n",
    "        rouge.update({\"gen_len\": summ_len})\n",
    "        return rouge\n",
    "\n",
    "    def translation_metrics(pred: EvalPrediction) -> Dict:\n",
    "        pred_str, label_str = decode_pred(pred)\n",
    "        bleu: Dict = calculate_bleu(pred_str, label_str)\n",
    "        gen_len = np.round(np.mean(lmap(non_pad_len, pred.predictions)), 1)\n",
    "        bleu.update({\"gen_len\": gen_len})\n",
    "        return bleu\n",
    "\n",
    "    compute_metrics_fn = summarization_metrics if \"summarization\" in task_name else translation_metrics\n",
    "    return compute_metrics_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import HfArgumentParser\n",
    "# parser = HfArgumentParser((ModelArguments, DataTrainingArguments, Seq2SeqTrainingArguments))\n",
    "# model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "# NYT author data\n",
    "data_args = DataTrainingArguments('../../data/nyt_comments/author_data_model/')\n",
    "training_args = Seq2SeqTrainingArguments('../../data/nyt_comments/debug_model/')\n",
    "# BART config\n",
    "model_args = ModelArguments('../../data/nyt_comments/author_data_model/question_generation_model/config.json')\n",
    "# LongFormer config\n",
    "\n",
    "# CNN data\n",
    "# data_args = DataTrainingArguments('../../data/CNN_articles/cnn/')\n",
    "# training_args = Seq2SeqTrainingArguments('../../data/CNN_articles/cnn/debug_model/')\n",
    "# model_args = ModelArguments('../../data/CNN_articles/cnn/question_generation_model/config.json')\n",
    "## add extra args\n",
    "training_args.local_rank = -1\n",
    "training_args.seed = 123\n",
    "# training_args.model_name_or_path = 'facebook/bart-base'\n",
    "# NYT author data\n",
    "training_args.tokenizer_name = '../../data/nyt_comments/author_data_model/BART_tokenizer.pt'\n",
    "training_args.cache_dir = '../../data/nyt_comments/model_cache/'\n",
    "# CNN data\n",
    "# training_args.tokenizer_name = '../../data/CNN_articles/cnn/BART_tokenizer.pt'\n",
    "# training_args.cache_dir = '../../data/CNN_articles/cnn/model_cache/'\n",
    "training_args.label_smoothing = 0.\n",
    "training_args.tpu_num_cores = 0.\n",
    "training_args.parallel_mode = 'not_parallel'\n",
    "training_args.adafactor = True\n",
    "training_args.lr_scheduler = 'linear'\n",
    "training_args.per_device_train_batch_size = 2\n",
    "training_args.per_device_eval_batch_size = 2\n",
    "training_args.do_eval = True\n",
    "training_args.evaluate_during_training = True\n",
    "training_args.evaluation_strategy = 'steps'\n",
    "# training_args.eval_steps = 100\n",
    "# NYT comments => less data means more training\n",
    "training_args.num_train_epochs = 6\n",
    "# CNN comments\n",
    "# training_args.num_train_epochs = 3\n",
    "training_args.save_total_limit = 2\n",
    "data_args.max_source_length = 1024\n",
    "data_args.max_target_length = 64\n",
    "data_args.task = 'summarization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train\n",
    "import logging\n",
    "from transformers import set_seed, AutoConfig, AutoModelForSeq2SeqLM\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n",
    "    )\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.warning(\n",
    "    \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "    training_args.local_rank,\n",
    "    training_args.device,\n",
    "    training_args.n_gpu,\n",
    "    bool(training_args.parallel_mode == ParallelMode.DISTRIBUTED),\n",
    "    training_args.fp16,\n",
    ")\n",
    "transformers.utils.logging.set_verbosity_info()\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "logger.info(\"Training/evaluation parameters %s\", training_args)\n",
    "set_seed(training_args.seed)\n",
    "# author-type data\n",
    "model_path = '../../data/nyt_comments/debug_model/question_generation_model/'\n",
    "# CNN baseline data\n",
    "# model_path = '../../data/CNN_articles/cnn/debug_model/'\n",
    "config = AutoConfig.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "    )\n",
    "extra_model_params = (\"encoder_layerdrop\", \"decoder_layerdrop\", \"dropout\", \"attention_dropout\")\n",
    "for p in extra_model_params:\n",
    "    if getattr(training_args, p, None):\n",
    "        assert hasattr(config, p), f\"({config.__class__.__name__}) doesn't have a `{p}` attribute\"\n",
    "        setattr(config, p, getattr(training_args, p))\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_path,\n",
    "    from_tf=\".ckpt\" in model_args.model_name_or_path,\n",
    "    config=config,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "\n",
    "import torch\n",
    "# author-type data\n",
    "tokenizer = torch.load('../../data/nyt_comments/author_data_model/BART_tokenizer.pt')\n",
    "## author-type data: full\n",
    "train_dataset = torch.load('../../data/nyt_comments/author_data_model/author_type_NYT_question_data_train_data.pt')\n",
    "eval_dataset = torch.load('../../data/nyt_comments/author_data_model/author_type_NYT_question_data_val_data.pt')\n",
    "## author-type data: mini\n",
    "# train_dataset = torch.load('../../data/nyt_comments/debug_model/mini_data/author_type_NYT_question_data_train_data.pt')\n",
    "# eval_dataset = torch.load('../../data/nyt_comments/debug_model/mini_data/author_type_NYT_question_data_val_data.pt')\n",
    "# CNN baseline data\n",
    "# tokenizer = torch.load('../../data/CNN_articles/cnn/BART_tokenizer.pt')\n",
    "# train_dataset = torch.load('../../data/CNN_articles/cnn/article_question_generation_train_data.pt')\n",
    "# eval_dataset = torch.load('../../data/CNN_articles/cnn/article_question_generation_val_data.pt')\n",
    "compute_metrics_fn = build_compute_metrics_fn(data_args.task, tokenizer)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "train_dataset = train_dataset['train']\n",
    "eval_dataset = eval_dataset['train']\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=Seq2SeqDataCollator(tokenizer, data_args, training_args.tpu_num_cores),\n",
    "    compute_metrics=compute_metrics_fn,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.sharded_dpp = False\n",
    "\n",
    "logger.info(\"*** Train ***\")\n",
    "\n",
    "train_result = trainer.train(\n",
    "    model_path=model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "num_beams = 8\n",
    "temperature = 1.0\n",
    "pred_text = []\n",
    "with torch.no_grad():\n",
    "    for data_i in tqdm(eval_dataset):\n",
    "    #     trainer.prediction_step(data_i, )\n",
    "        source_i = data_i['source_ids'].to(model.device).reshape(1,-1)\n",
    "        attention_i = data_i['attention_mask'].to(model.device).reshape(1,-1)\n",
    "        pred_i = model.generate(input_ids=source_i, \n",
    "                                attention_mask=attention_i,\n",
    "                                num_beams=num_beams, \n",
    "                                temperature=temperature)\n",
    "        pred_i = pred_i.to('cpu')\n",
    "        pred_text_i = tokenizer.decode(pred_i[0], skip_special_tokens=True)\n",
    "        pred_text.append(pred_text_i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3] *",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
