{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute data summary statistics\n",
    "Now that we've organized and cleaned the question data, let's compute some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730620 total questions\n",
      "270694 total posts\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "# data = pd.read_csv('../../data/reddit_data/combined_data_question_data.gz', sep='\\t', compression='gzip')\n",
    "comment_data = pd.read_csv('../../data/reddit_data/advice_subreddit_filter_comment_question_data.gz', sep='\\t', compression='gzip')\n",
    "post_data = pd.read_csv('../../data/reddit_data/subreddit_submissions_2018-01_2019-12.gz', sep='\\t', compression='gzip', index_col=False, usecols=['id', 'selftext'])\n",
    "post_data.rename(columns={'selftext' : 'article_text', 'id' : 'parent_id'}, inplace=True)\n",
    "data = pd.merge(comment_data, post_data, on=['parent_id'], how='left')\n",
    "print(f'{data.shape[0]} total questions')\n",
    "print(f'{data.loc[:, \"parent_id\"].nunique()} total posts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 730620/730620 [02:00<00:00, 6081.07it/s] \n",
      "100%|██████████| 730620/730620 [00:19<00:00, 38435.29it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "word_tokenizer = WordPunctTokenizer()\n",
    "data = data.assign(**{\n",
    "    'post_tokens' : data.loc[:, 'article_text'].progress_apply(lambda x: word_tokenizer.tokenize(x)),\n",
    "    'question_tokens' : data.loc[:, 'question'].progress_apply(lambda x: word_tokenizer.tokenize(x)),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean post length = 304.33780487804876 +/- 220.58549234310797\n",
      "mean question length = 13.888070405956585 +/- 8.079854409405339\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "post_len = data.loc[:, \"post_tokens\"].apply(lambda x: len(x)).values\n",
    "question_len = data.loc[:, \"question_tokens\"].apply(lambda x: len(x)).values\n",
    "print(f'mean post length = {np.mean(post_len)} +/- {np.std(post_len)}')\n",
    "print(f'mean question length = {np.mean(question_len)} +/- {np.std(question_len)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author data\n",
    "What % of the data includes metadata about authors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ianbstew/miniconda3/envs/py3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3418: DtypeWarning: Columns (1,2,8,9,10,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date_day</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>expert_pct</th>\n",
       "      <th>relative_time</th>\n",
       "      <th>expert_pct_bin</th>\n",
       "      <th>relative_time_bin</th>\n",
       "      <th>age</th>\n",
       "      <th>location_self_id</th>\n",
       "      <th>location</th>\n",
       "      <th>location_region</th>\n",
       "      <th>subreddit_country</th>\n",
       "      <th>date_day_bin</th>\n",
       "      <th>text_embed</th>\n",
       "      <th>subreddit_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>talosguideu</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>Advice</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>6.247118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "      <td>US</td>\n",
       "      <td>UNK</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>[0.22358277440071106, 0.28246960043907166, -0....</td>\n",
       "      <td>[16.383529609746823, 11.534988324393423, 4.245...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talosguideu</td>\n",
       "      <td>2019-03-02</td>\n",
       "      <td>Advice</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>6.265348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "      <td>US</td>\n",
       "      <td>UNK</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>[0.22358277440071106, 0.28246960043907166, -0....</td>\n",
       "      <td>[16.383529609746823, 11.534988324393423, 4.245...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>talosguideu</td>\n",
       "      <td>2019-03-30</td>\n",
       "      <td>Advice</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>6.247118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "      <td>US</td>\n",
       "      <td>UNK</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>[0.22358277440071106, 0.28246960043907166, -0....</td>\n",
       "      <td>[16.383529609746823, 11.534988324393423, 4.245...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>talosguideu</td>\n",
       "      <td>2019-05-18</td>\n",
       "      <td>Advice</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>6.247118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "      <td>US</td>\n",
       "      <td>UNK</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>[0.22358277440071106, 0.28246960043907166, -0....</td>\n",
       "      <td>[16.383529609746823, 11.534988324393423, 4.245...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>talosguideu</td>\n",
       "      <td>2019-05-24</td>\n",
       "      <td>Advice</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>6.247118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "      <td>US</td>\n",
       "      <td>UNK</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>[0.22358277440071106, 0.28246960043907166, -0....</td>\n",
       "      <td>[16.383529609746823, 11.534988324393423, 4.245...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author    date_day subreddit  expert_pct  relative_time  \\\n",
       "0  talosguideu  2019-06-05    Advice    0.010000       6.247118   \n",
       "1  talosguideu  2019-03-02    Advice    0.010101       6.265348   \n",
       "2  talosguideu  2019-03-30    Advice    0.010000       6.247118   \n",
       "3  talosguideu  2019-05-18    Advice    0.010000       6.247118   \n",
       "4  talosguideu  2019-05-24    Advice    0.010000       6.247118   \n",
       "\n",
       "   expert_pct_bin  relative_time_bin  age location_self_id location  \\\n",
       "0             0.0                0.0 -1.0               us       us   \n",
       "1             0.0                0.0 -1.0               us       us   \n",
       "2             0.0                0.0 -1.0               us       us   \n",
       "3             0.0                0.0 -1.0               us       us   \n",
       "4             0.0                0.0 -1.0               us       us   \n",
       "\n",
       "  location_region subreddit_country         date_day_bin  \\\n",
       "0              US               UNK  2019-01-01 00:00:00   \n",
       "1              US               UNK  2019-01-01 00:00:00   \n",
       "2              US               UNK  2019-01-01 00:00:00   \n",
       "3              US               UNK  2019-01-01 00:00:00   \n",
       "4              US               UNK  2019-01-01 00:00:00   \n",
       "\n",
       "                                          text_embed  \\\n",
       "0  [0.22358277440071106, 0.28246960043907166, -0....   \n",
       "1  [0.22358277440071106, 0.28246960043907166, -0....   \n",
       "2  [0.22358277440071106, 0.28246960043907166, -0....   \n",
       "3  [0.22358277440071106, 0.28246960043907166, -0....   \n",
       "4  [0.22358277440071106, 0.28246960043907166, -0....   \n",
       "\n",
       "                                     subreddit_embed  \n",
       "0  [16.383529609746823, 11.534988324393423, 4.245...  \n",
       "1  [16.383529609746823, 11.534988324393423, 4.245...  \n",
       "2  [16.383529609746823, 11.534988324393423, 4.245...  \n",
       "3  [16.383529609746823, 11.534988324393423, 4.245...  \n",
       "4  [16.383529609746823, 11.534988324393423, 4.245...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "author_data = pd.read_csv('../../data/reddit_data/author_data/combined_author_prior_comment_data.gz', sep='\\t', compression='gzip')\n",
    "# fix date var\n",
    "from datetime import datetime\n",
    "author_data = author_data.assign(**{'date_day_bin' : pd.Series(author_data.loc[:, 'date_day_bin'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d')).values, dtype='object')})\n",
    "# author_data = author_data.assign(**{'date_day_bin' : author_data.loc[:, 'date_day_bin'].apply(lambda x: x.to_pydatetime()).values})\n",
    "display(author_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.36338999753633% questions can be connected to an author with some kind of data\n"
     ]
    }
   ],
   "source": [
    "valid_authors = set(author_data.loc[:, 'author'].unique())\n",
    "valid_author_data = data[data.loc[:, 'author'].isin(valid_authors)]\n",
    "print(f'{valid_author_data.shape[0]/data.shape[0]*100}% questions can be connected to an author with some kind of data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any difference for discrete and continuous representation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.91191043223564% questions can be connected to an author with a discrete representation\n",
      "50.71035558840437% questions can be connected to an author with a continuous representation\n"
     ]
    }
   ],
   "source": [
    "discrete_vars = ['expert_pct_bin', 'location']\n",
    "continuous_vars = ['text_embed', 'subreddit_embed']\n",
    "valid_discrete_var_authors = set(author_data.dropna(subset=discrete_vars, how='all').loc[:, 'author'].unique())\n",
    "valid_continuous_var_authors = set(author_data.dropna(subset=continuous_vars, how='all').loc[:, 'author'].unique())\n",
    "discrete_var_author_data = data[data.loc[:, 'author'].isin(valid_discrete_var_authors)]\n",
    "continuous_var_author_data = data[data.loc[:, 'author'].isin(valid_continuous_var_authors)]\n",
    "print(f'{discrete_var_author_data.shape[0]/data.shape[0]*100}% questions can be connected to an author with a discrete representation')\n",
    "print(f'{continuous_var_author_data.shape[0]/data.shape[0]*100}% questions can be connected to an author with a continuous representation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subreddit stats\n",
    "What is the distribution of posts/questions in each subreddit?\n",
    "\n",
    "Let's make this into a nice bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_subreddit_post_counts = data.drop_duplicates('parent_id').loc[:, 'subreddit'].value_counts().reset_index(name='Count').rename(columns={'index' : 'Subreddit'})\n",
    "per_subreddit_question_counts = data.loc[:, 'subreddit'].value_counts().reset_index(name='Count').rename(columns={'index' : 'Subreddit'})\n",
    "per_subreddit_post_counts = per_subreddit_post_counts.assign(**{'Data Type' : 'post'})\n",
    "per_subreddit_question_counts = per_subreddit_question_counts.assign(**{'Data Type' : 'question'})\n",
    "per_subreddit_counts = pd.concat([per_subreddit_post_counts, per_subreddit_question_counts], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Data Type</th>\n",
       "      <th>post</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Advice</th>\n",
       "      <td>48858</td>\n",
       "      <td>87592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmItheAsshole</th>\n",
       "      <td>61857</td>\n",
       "      <td>331345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legaladvice</th>\n",
       "      <td>53577</td>\n",
       "      <td>92737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcmasterrace</th>\n",
       "      <td>31657</td>\n",
       "      <td>47613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personalfinance</th>\n",
       "      <td>74745</td>\n",
       "      <td>171333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Data Type         post  question\n",
       "Subreddit                       \n",
       "Advice           48858     87592\n",
       "AmItheAsshole    61857    331345\n",
       "legaladvice      53577     92737\n",
       "pcmasterrace     31657     47613\n",
       "personalfinance  74745    171333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.pivot(per_subreddit_counts, index='Subreddit', columns=['Data Type'], values='Count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "ordered_subreddits = list(sorted(per_subreddit_counts.loc[:, 'Subreddit'].unique()))\n",
    "sns.barplot(data=per_subreddit_counts, y='Subreddit', x='Count', hue='Data Type', order=ordered_subreddits)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text+author data\n",
    "What is the representation of authors in the text data?\n",
    "\n",
    "We want % of comments with each reader group and embedding type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## get author+text data from cleaned generation data\n",
    "import torch\n",
    "train_data = torch.load('../../data/reddit_data/combined_data_train_data.pt')\n",
    "test_data = torch.load('../../data/reddit_data/combined_data_val_data.pt')\n",
    "# convert to dataframe because it's easier to combine\n",
    "train_data_df = train_data.data.to_pandas()\n",
    "test_data_df = test_data.data.to_pandas()\n",
    "import pandas as pd\n",
    "author_vars = ['reader_token_str', 'author_has_subreddit_embed', 'author_has_text_embed', 'article_id']\n",
    "post_author_data = pd.concat([\n",
    "    train_data_df.loc[:, author_vars], \n",
    "    test_data_df.loc[:, author_vars], \n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add subreddit data\n",
    "submission_data = pd.read_csv('../../data/reddit_data/subreddit_submissions_2018-01_2019-12.gz', sep='\\t', compression='gzip', usecols=['id', 'subreddit'])\n",
    "submission_data.rename(columns={'id' : 'article_id'}, inplace=True)\n",
    "if('subreddit' not in post_author_data.columns):\n",
    "    post_author_data = pd.merge(post_author_data, submission_data, on='article_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pct = 0.25\n",
    "## reader groups\n",
    "def get_reader_group_counts(data):\n",
    "    reader_group_counts = data.loc[:, 'reader_token_str'].value_counts()\n",
    "    est_reader_group_counts = reader_group_counts / sample_pct\n",
    "    reader_group_pct = reader_group_counts / reader_group_counts.sum()\n",
    "    reader_group_count_data = pd.concat([reader_group_pct, est_reader_group_counts], axis=1)\n",
    "    reader_group_count_data.columns = ['reader_group_pct', 'reader_group_count']\n",
    "    reader_group_count_data.sort_index(inplace=True)\n",
    "    # get embed counts\n",
    "    reader_embed_counts = pd.Series([\n",
    "        data.loc[:, 'author_has_subreddit_embed'].sum(),\n",
    "        data.loc[:, 'author_has_text_embed'].sum(),\n",
    "    ])\n",
    "    est_reader_embed_counts = reader_embed_counts / sample_pct\n",
    "    reader_embed_pct = reader_embed_counts / data.shape[0]\n",
    "    reader_embed_count_data = pd.concat([reader_embed_pct, est_reader_embed_counts], axis=1)\n",
    "    reader_embed_count_data.columns = ['reader_group_pct', 'reader_group_count']\n",
    "    reader_embed_count_data.index = ['subreddit_embed', 'text_embed']\n",
    "    reader_count_data = pd.concat([reader_group_count_data, reader_embed_count_data], axis=0)\n",
    "    return reader_count_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          reader_group_pct  reader_group_count\n",
      "<EXPERT_PCT_0_AUTHOR>             0.252125            257188.0\n",
      "<EXPERT_PCT_1_AUTHOR>             0.010391             10600.0\n",
      "<NONUS_AUTHOR>                    0.012811             13068.0\n",
      "<RESPONSE_TIME_0_AUTHOR>          0.089918             91724.0\n",
      "<RESPONSE_TIME_1_AUTHOR>          0.172598            176064.0\n",
      "<US_AUTHOR>                       0.018638             19012.0\n",
      "UNK                               0.443518            452424.0\n",
      "subreddit_embed                   0.094902             96808.0\n",
      "text_embed                        0.097137             99088.0\n"
     ]
    }
   ],
   "source": [
    "reader_count_data = get_reader_group_counts(post_author_data)\n",
    "print(reader_count_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** subreddit=Advice ****\n",
      "                          reader_group_pct  reader_group_count\n",
      "<EXPERT_PCT_0_AUTHOR>             0.321220             44480.0\n",
      "<EXPERT_PCT_1_AUTHOR>             0.019441              2692.0\n",
      "<NONUS_AUTHOR>                    0.022329              3092.0\n",
      "<RESPONSE_TIME_0_AUTHOR>          0.094142             13036.0\n",
      "<RESPONSE_TIME_1_AUTHOR>          0.246519             34136.0\n",
      "<US_AUTHOR>                       0.023109              3200.0\n",
      "UNK                               0.273239             37836.0\n",
      "subreddit_embed                   0.159021             22020.0\n",
      "text_embed                        0.163383             22624.0\n",
      "**** subreddit=AmItheAsshole ****\n",
      "                          reader_group_pct  reader_group_count\n",
      "<EXPERT_PCT_0_AUTHOR>             0.179153             74448.0\n",
      "<EXPERT_PCT_1_AUTHOR>             0.007912              3288.0\n",
      "<NONUS_AUTHOR>                    0.011541              4796.0\n",
      "<RESPONSE_TIME_0_AUTHOR>          0.103553             43032.0\n",
      "<RESPONSE_TIME_1_AUTHOR>          0.083512             34704.0\n",
      "<US_AUTHOR>                       0.013842              5752.0\n",
      "UNK                               0.600487            249536.0\n",
      "subreddit_embed                   0.046203             19200.0\n",
      "text_embed                        0.047454             19720.0\n",
      "**** subreddit=legaladvice ****\n",
      "                          reader_group_pct  reader_group_count\n",
      "<EXPERT_PCT_0_AUTHOR>             0.336616             49908.0\n",
      "<EXPERT_PCT_1_AUTHOR>             0.010360              1536.0\n",
      "<NONUS_AUTHOR>                    0.017320              2568.0\n",
      "<RESPONSE_TIME_0_AUTHOR>          0.093968             13932.0\n",
      "<RESPONSE_TIME_1_AUTHOR>          0.253008             37512.0\n",
      "<US_AUTHOR>                       0.021907              3248.0\n",
      "UNK                               0.266821             39560.0\n",
      "subreddit_embed                   0.139697             20712.0\n",
      "text_embed                        0.142260             21092.0\n",
      "**** subreddit=pcmasterrace ****\n",
      "                          reader_group_pct  reader_group_count\n",
      "<EXPERT_PCT_0_AUTHOR>             0.344218             26228.0\n",
      "<EXPERT_PCT_1_AUTHOR>             0.013124              1000.0\n",
      "<NONUS_AUTHOR>                    0.016746              1276.0\n",
      "<RESPONSE_TIME_0_AUTHOR>          0.047404              3612.0\n",
      "<RESPONSE_TIME_1_AUTHOR>          0.309938             23616.0\n",
      "<US_AUTHOR>                       0.011182               852.0\n",
      "UNK                               0.257389             19612.0\n",
      "subreddit_embed                   0.133288             10156.0\n",
      "text_embed                        0.136963             10436.0\n",
      "**** subreddit=personalfinance ****\n",
      "                          reader_group_pct  reader_group_count\n",
      "<EXPERT_PCT_0_AUTHOR>             0.257144             62124.0\n",
      "<EXPERT_PCT_1_AUTHOR>             0.008626              2084.0\n",
      "<NONUS_AUTHOR>                    0.005530              1336.0\n",
      "<RESPONSE_TIME_0_AUTHOR>          0.074969             18112.0\n",
      "<RESPONSE_TIME_1_AUTHOR>          0.190801             46096.0\n",
      "<US_AUTHOR>                       0.024670              5960.0\n",
      "UNK                               0.438260            105880.0\n",
      "subreddit_embed                   0.102321             24720.0\n",
      "text_embed                        0.104374             25216.0\n"
     ]
    }
   ],
   "source": [
    "## per-subreddit coverage\n",
    "for subreddit_i, data_i in post_author_data.groupby('subreddit'):\n",
    "    print(f'**** subreddit={subreddit_i} ****')\n",
    "    reader_count_data_i = get_reader_group_counts(data_i)\n",
    "    print(reader_count_data_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `LOCATION`: skewed representation in `personalfinance`\n",
    "- `EXPERT`: fewer \"experts\" in `AmItheAsshole`, `personalfinance`\n",
    "- `RESPONSE`: more \"short\" responders in `AmItheAsshole` (more first-time posters?)\n",
    "- `embeds`: less embed coverage in `AmItheAsshole`, `personalfinance` (more first-time posters?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# buggy code to convert raw data to post+author data\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "# import pytz\n",
    "# post_author_data = pd.read_csv('../../data/reddit_data/combined_data_question_data.gz', \n",
    "#                                sep='\\t', index_col=False, compression='gzip',\n",
    "#                                usecols=['article_id', 'created_utc', 'id', 'author'])\n",
    "# post_author_data = post_author_data.assign(**{'date' : post_author_data.loc[:, 'created_utc'].apply(lambda x: datetime.fromtimestamp(x, tz=pytz.utc).replace(tzinfo=None))})\n",
    "# ## convert to date day bins\n",
    "# from importlib import reload\n",
    "# import data_helpers\n",
    "# reload(data_helpers)\n",
    "# from data_helpers import assign_date_bin\n",
    "# import numpy as np\n",
    "# author_date_bins = author_data.loc[:, 'date_day_bin'].unique()\n",
    "# author_date_bins = np.array(list(map(lambda x: x.timestamp(), author_date_bins)))\n",
    "# post_author_data = post_author_data.assign(**{\n",
    "#     'date_day_bin' : post_author_data.loc[:, 'date'].apply(lambda x: assign_date_bin(x.timestamp(), author_date_bins, convert_timezone=False))\n",
    "# })\n",
    "# display(post_author_data.head())\n",
    "# dynamic_author_vars = ['relative_time_bin', 'expert_pct_bin', 'text_embed', 'subreddit_embed']\n",
    "# static_author_vars = ['location_region']\n",
    "# combined_author_post_data = post_author_data.copy()\n",
    "# for dynamic_author_var_i in dynamic_author_vars:\n",
    "#     combined_author_post_data = pd.merge(combined_author_post_data, author_data.loc[:, [dynamic_author_var_i, 'author', 'date_day_bin']], on=['author', 'date_day_bin'], how='left')\n",
    "# for static_var_i in static_author_vars:\n",
    "#     combined_author_post_data = pd.merge(combined_author_post_data, author_data.loc[:, [static_author_var_i, 'author']], on='author', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split\n",
    "Let's look at the total counts for train/val/test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155396 51774 53080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "train_data = torch.load('../../data/reddit_data/combined_data_train_train_data.pt')\n",
    "val_data = torch.load('../../data/reddit_data/combined_data_train_val_data.pt')\n",
    "test_data = torch.load('../../data/reddit_data/combined_data_test_data.pt')\n",
    "print(len(train_data), len(val_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug: joining with embedding data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are we losing so many of the embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## where are all the embeddings going?\n",
    "from datetime import datetime\n",
    "tmp_author_data = author_data.drop(['subreddit_embed', 'text_embed'], axis=1)\n",
    "tmp_author_data = tmp_author_data.assign(**{\n",
    "    'date_day' : tmp_author_data.loc[:, 'date_day'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "})\n",
    "from ast import literal_eval\n",
    "from importlib import reload\n",
    "import data_helpers\n",
    "reload(data_helpers)\n",
    "from data_helpers import assign_date_bin\n",
    "author_embeddings_data_file = '../../data/reddit_data/author_data/author_date_embeddings_type=subreddit.gz'\n",
    "author_embeddings_data = pd.read_csv(author_embeddings_data_file, sep='\\t', compression='gzip', index_col=False)\n",
    "embed_var = list(filter(lambda x: x.endswith('_embed'), author_embeddings_data.columns))[0]\n",
    "author_embeddings_data = author_embeddings_data.assign(**{embed_var : author_embeddings_data.loc[:, embed_var].apply(lambda x: literal_eval(x))})\n",
    "author_embeddings_data = author_embeddings_data.assign(**{'date_day_bin' : author_embeddings_data.loc[:, 'date_day_bin'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))})\n",
    "## join w/ author data via date\n",
    "embedding_date_bins = author_embeddings_data.loc[:, 'date_day_bin'].apply(lambda x: x.timestamp()).unique()\n",
    "tmp_author_data = tmp_author_data.assign(**{\n",
    "    'date_day_bin' : tmp_author_data.loc[:, 'date_day'].apply(lambda x: assign_date_bin(x.timestamp(), embedding_date_bins))\n",
    "})\n",
    "tmp_author_data = pd.merge(tmp_author_data, author_embeddings_data.loc[:, ['author', 'date_day_bin', embed_var]], on=['author', 'date_day_bin'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22148/55609 authors retained\n"
     ]
    }
   ],
   "source": [
    "print(f'{tmp_author_data.dropna(subset=[\"subreddit_embed\"], axis=0).loc[:, \"author\"].nunique()}/{author_embeddings_data.loc[:, \"author\"].nunique()} authors retained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-01 00:00:00+00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "2018-01-01 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "# display(tmp_author_data.loc[:, 'date_day_bin'].head())\n",
    "# display(author_embeddings_data.loc[:, 'date_day_bin'].head())\n",
    "x = tmp_author_data.loc[:, 'date_day_bin'].iloc[0]\n",
    "y = author_embeddings_data.loc[:, 'date_day_bin'].iloc[0]\n",
    "print(x)\n",
    "print(type(x))\n",
    "print(y)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5147648e+09 1.5304032e+09 1.5463008e+09 1.5619392e+09]\n",
      "2018-01-01 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import data_helpers\n",
    "reload(data_helpers)\n",
    "from data_helpers import assign_date_bin\n",
    "embedding_date_bin = author_embeddings_data.loc[:, 'date_day_bin'].apply(lambda x: x.timestamp()).unique()\n",
    "test_date = datetime.strptime('2018-03-01', '%Y-%m-%d')\n",
    "test_date = test_date.timestamp()\n",
    "# print(dir(test_date))\n",
    "test_bin_date = assign_date_bin(test_date, embedding_date_bin)\n",
    "print(embedding_date_bins)\n",
    "print(test_bin_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 1, 1, 0, 0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strptime(test_bin_date.strftime('%Y-%m-%d'), '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-01 00:00:00\n",
      "2018-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from pytz import utc\n",
    "test_date_bin = author_embeddings_data.loc[:, 'date_day_bin'].iloc[0]\n",
    "print(test_date_bin)\n",
    "print(datetime.fromtimestamp(test_date_bin.timestamp(), tz=utc).replace(tzinfo=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "timestamp() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f80cc13146b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# timezone(datetime.timedelta(seceonds=0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_date_bin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtzinfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: timestamp() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "# from datetime import timezone\n",
    "from datetime import tzinfo\n",
    "from datetime import timedelta\n",
    "# timezone(datetime.timedelta(seceonds=0))\n",
    "datetime.fromtimestamp(test_date_bin.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function fromtimestamp:\n",
      "\n",
      "fromtimestamp(...) method of builtins.type instance\n",
      "    timestamp[, tz] -> tz's local time from POSIX timestamp.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(datetime.fromtimestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tmp testing for evaluation\n",
    "import gzip\n",
    "import torch\n",
    "text_data_1 = list(map(lambda x: x.strip(), gzip.open('../../data/reddit_data/text_only_model/test_data_sample_top_p=0.9_temperature=1.0_output_text.gz', 'rt')))\n",
    "text_data_2 = list(map(lambda x: x.strip(), gzip.open('../../data/reddit_data/author_text_data/test_data_sample_top_p=0.9_temperature=1.0_output_text.gz', 'rt')))\n",
    "test_data = torch.load('../../data/reddit_data/combined_data_test_data.pt')\n",
    "test_text = test_data['target_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56097it [00:00, 145210.74it/s]\n",
      "56097it [00:00, 129438.86it/s]\n",
      "56097it [00:00, 185751.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from tqdm import tqdm\n",
    "word_tokenizer = WordPunctTokenizer()\n",
    "text_data_tokens_1 = list(tqdm(map(word_tokenizer.tokenize, text_data_1)))\n",
    "text_data_tokens_2 = list(tqdm(map(word_tokenizer.tokenize, text_data_2)))\n",
    "test_data_tokens = list(tqdm(map(word_tokenizer.tokenize, test_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/ianbstew/miniconda3/envs/py3/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/ianbstew/miniconda3/envs/py3/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/ianbstew/miniconda3/envs/py3/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "56097it [00:06, 8260.88it/s]\n",
      "56097it [00:06, 8340.45it/s]\n"
     ]
    }
   ],
   "source": [
    "## compute all BLEU scores etc.\n",
    "import sys\n",
    "if('..' not in sys.path):\n",
    "    sys.path.append('..')\n",
    "from models.model_helpers import compute_text_bleu\n",
    "bleu_weights = [1.0, 0., 0., 0.]\n",
    "text_data_bleu_1 = list(tqdm(map(lambda x: compute_text_bleu(x[0], x[1], weights=bleu_weights), zip(text_data_tokens_1, test_data_tokens))))\n",
    "text_data_bleu_2 = list(tqdm(map(lambda x: compute_text_bleu(x[0], x[1], weights=bleu_weights), zip(text_data_tokens_2, test_data_tokens))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "med diff = 0.000E+00; test stat = 2.098E+08 (p=1.194E-01)\n"
     ]
    }
   ],
   "source": [
    "## paired sign test\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "med_diff = np.median(np.array(text_data_bleu_1) - np.array(text_data_bleu_2))\n",
    "mean_diff = np.mean(np.array(text_data_bleu_1) - np.array(text_data_bleu_2))\n",
    "test_stat, p_val = wilcoxon(text_data_bleu_1, text_data_bleu_2)\n",
    "print(f'med diff = {\"{:.3E}\".format(med_diff)}; test stat = {\"{:.3E}\".format(test_stat)} (p={\"{:.3E}\".format(p_val)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 193.08it/s]\n"
     ]
    }
   ],
   "source": [
    "## bootstrap\n",
    "np.random.seed(123)\n",
    "bootstrap_iters = 1000\n",
    "sample_size = 1000\n",
    "data_idx = list(range(len(test_data)))\n",
    "sample_diffs = []\n",
    "for i in tqdm(range(bootstrap_iters)):\n",
    "    idx_i = np.random.choice(data_idx, sample_size, replace=False)\n",
    "    bleu_1_i = np.array([text_data_bleu_1[j] for j in idx_i])\n",
    "    bleu_2_i = np.array([text_data_bleu_2[j] for j in idx_i])\n",
    "    median_diff_i = np.mean(bleu_1_i - bleu_2_i)\n",
    "    sample_diffs.append(median_diff_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29119"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(np.array(text_data_bleu_1)!=np.array(text_data_bleu_2))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sample_diffs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5026245753681418\n",
      "0.024997895148220435\n"
     ]
    }
   ],
   "source": [
    "## Z-norm observed mean diff\n",
    "from scipy.stats import norm\n",
    "norm_mean_diff = (mean_diff - np.mean(sample_diffs)) / np.std(sample_diffs)\n",
    "print(1-norm.cdf(norm_mean_diff))\n",
    "print(norm.cdf(-1.96))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3] *",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
