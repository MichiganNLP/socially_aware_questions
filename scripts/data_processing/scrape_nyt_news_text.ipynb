{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium news scrape\n",
    "Let's try to collect news data from an internet database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(\"http://www.python.org\")\n",
    "assert \"Python\" in driver.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proquest_command_file = '/Users/istewart/Documents/tools/selenium/proquest_search.side'\n",
    "import json\n",
    "user_cred_file = '../../data/umich_cred.json'\n",
    "user_cred = json.load(open(user_cred_file, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "target_site = 'https://search-proquest-com.proxy.lib.umich.edu/advanced?accountid=14667'\n",
    "driver.get(target_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_title = \"dr. fauci sees 'terribly painful' months ahead\"\n",
    "news_publisher_title = 'new york times'\n",
    "text_field_1 = driver.find_element_by_id('queryTermField')\n",
    "text_field_1.send_keys(article_title)\n",
    "text_field_2 = driver.find_element_by_id('queryTermField_0')\n",
    "text_field_2.send_keys(news_publisher_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify date\n",
    "from selenium.webdriver.support.ui import Select\n",
    "date = 'November 20 2020'\n",
    "date_month, date_day, date_year = date.split(' ')\n",
    "date_menu = Select(driver.find_element_by_id('select_multiDateRange'))\n",
    "date_menu.select_by_visible_text('On this date...')\n",
    "month_date_menu = Select(driver.find_element_by_id('month2'))\n",
    "day_date_menu = Select(driver.find_element_by_id('day2'))\n",
    "year_input = driver.find_element_by_id('year2')\n",
    "month_date_menu.select_by_visible_text(date_month)\n",
    "day_date_menu.select_by_visible_text(date_day)\n",
    "year_input.send_keys(date_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## submit query!!\n",
    "submit_button = driver.find_element_by_id('searchToResultPage')\n",
    "submit_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recovered link <selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"9a6eefe2-1037-cc49-b9a6-d29390d6f1fe\", element=\"098580cc-dcd6-7f4a-8c73-90f6f2110224\")>\n"
     ]
    }
   ],
   "source": [
    "## get first result with full text\n",
    "result_item_txt_link = None\n",
    "result_item_list = driver.find_element_by_class_name('resultItems')\n",
    "result_items = driver.find_elements_by_id('mlditem1')\n",
    "for result_item in result_items:\n",
    "    result_item_txt_link = result_item.find_element_by_id('addFlashPageParameterformat_fulltext')\n",
    "    if(result_item_txt_link is not None):\n",
    "        break\n",
    "print(f'recovered link {result_item_txt_link}')\n",
    "if(result_item_txt_link is not None):\n",
    "    result_item_txt_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## get page content\n",
    "# article id\n",
    "import re\n",
    "article_ID_matcher = re.compile('(?<=fulltext/)[0-9A-Za-z]+(?=/)')\n",
    "article_ID = article_ID_matcher.search(driver.current_url).group(0)\n",
    "# article title\n",
    "result_title = driver.find_element_by_id('documentTitle')\n",
    "result_title_txt = result_title.text\n",
    "# article authors\n",
    "result_authors = driver.find_element_by_class_name('titleAuthorETC')\n",
    "result_author_links = result_authors.find_elements_by_css_selector('a')\n",
    "result_author_txt = list(map(lambda x: x.text, result_author_links))\n",
    "# article text\n",
    "result_text_zone = driver.find_element_by_id('fullTextZone')\n",
    "result_text_paragraphs = result_text_zone.find_elements_by_css_selector('p')\n",
    "result_paragraph_text = ' '.join(list(map(lambda x: x.text, result_text_paragraphs)))\n",
    "## combine, write to file\n",
    "import pandas as pd\n",
    "import os\n",
    "result_df = pd.DataFrame([article_ID, result_title_txt, result_author_txt, result_paragraph_text], index=['id', 'title', 'authors', 'text']).transpose()\n",
    "out_dir = '../../data/NYT_scrape/'\n",
    "if(not os.path.exists(out_dir)):\n",
    "    os.mkdir(out_dir)\n",
    "out_file = os.path.join(out_dir, f'{article_ID}_data.tsv')\n",
    "result_df.to_csv(out_file, sep='\\t', index=False)\n",
    "# print(result_df)\n",
    "# print(result_text_zone.find_elements_by('p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run scraping on several articles\n",
    "Now that we've gotten scraping \"right\", let's try to run it on some sample NYT articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import Select\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "def scrape_article(article_title, article_date, article_publisher, \n",
    "                   target_site, driver,\n",
    "                   RESULT_LOAD_TIME=15):\n",
    "#     print(f'getting target site {target_site}')\n",
    "    # set default article data\n",
    "    article_ID = None\n",
    "    result_title_txt = None\n",
    "    result_author_txt = None\n",
    "    result_paragraph_text = None\n",
    "    driver.get(target_site)\n",
    "    # let site load\n",
    "    site_load_time_const = RESULT_LOAD_TIME / 3.\n",
    "    site_load_time = site_load_time_const + np.random.random()*(site_load_time_const)\n",
    "    sleep(site_load_time)\n",
    "#     article_title = \"dr. fauci sees 'terribly painful' months ahead\"\n",
    "    ## specify title and publication\n",
    "    # set title\n",
    "    text_field_1 = driver.find_element_by_id('queryTermField')\n",
    "    text_field_1.clear()\n",
    "    text_field_1.send_keys(article_title)\n",
    "    text_selection_menu_1 = Select(driver.find_element_by_id('fieldsSelect'))\n",
    "    text_selection_menu_1.select_by_value('ti')\n",
    "    # set publication\n",
    "    text_field_2 = driver.find_element_by_id('queryTermField_0')\n",
    "    text_field_2.clear()\n",
    "    text_field_2.send_keys(article_publisher)\n",
    "    text_selection_menu_2 = Select(driver.find_element_by_id('fieldsSelect_0'))\n",
    "    text_selection_menu_2.select_by_value('pub')\n",
    "    ## specify date\n",
    "    ## date range: [publish date, publish date + X]\n",
    "    # compute end date\n",
    "    MAX_DATE_DAYS = 2\n",
    "    date_fmt = '%B %d %Y'\n",
    "    article_date_time = datetime.strptime(article_date, date_fmt)\n",
    "    end_date = article_date_time + timedelta(days=MAX_DATE_DAYS)\n",
    "    end_date_str = datetime.strftime(end_date, date_fmt)\n",
    "    ## extract from date format: November 20 2020\n",
    "    start_date_month, start_date_day, start_date_year = article_date.split(' ')\n",
    "    end_date_month, end_date_day, end_date_year = end_date_str.split(' ')\n",
    "    # get date menus\n",
    "    date_menu = Select(driver.find_element_by_id('select_multiDateRange'))\n",
    "#     date_menu.select_by_visible_text('On this date...')\n",
    "    date_menu.select_by_value('RANGE')\n",
    "    # start date\n",
    "    start_month_date_menu = Select(driver.find_element_by_id('month2'))\n",
    "    start_day_date_menu = Select(driver.find_element_by_id('day2'))\n",
    "    start_year_input = driver.find_element_by_id('year2')\n",
    "    start_month_date_menu.select_by_visible_text(start_date_month)\n",
    "    start_day_date_menu.select_by_visible_text(start_date_day)\n",
    "    start_year_input.send_keys(start_date_year)\n",
    "    # end date\n",
    "    end_month_date_menu = Select(driver.find_element_by_id('month2_0'))\n",
    "    end_day_date_menu = Select(driver.find_element_by_id('day2_0'))\n",
    "    end_year_input = driver.find_element_by_id('year2_0')\n",
    "    end_month_date_menu.select_by_visible_text(end_date_month)\n",
    "    end_day_date_menu.select_by_visible_text(end_date_day)\n",
    "    end_year_input.send_keys(end_date_year)\n",
    "    ## submit query!!\n",
    "    submit_button = driver.find_element_by_id('searchToResultPage')\n",
    "    submit_button.click()\n",
    "    sleep(RESULT_LOAD_TIME)\n",
    "    ## get first result with full text\n",
    "    # if bad search, skip to next article\n",
    "    result_item_txt_link = None\n",
    "    result_item_list = None\n",
    "    try:\n",
    "        result_item_list = driver.find_element_by_class_name('resultItems')\n",
    "#         print(f'result item list {result_item_list}')\n",
    "    except Exception as e:\n",
    "        print(f'error {e}')\n",
    "        pass\n",
    "    no_results = result_item_list is None\n",
    "    if(not no_results):\n",
    "        result_items = driver.find_elements_by_id('mlditem1')\n",
    "        for result_item in result_items:\n",
    "            result_item_txt_link = None\n",
    "            try:\n",
    "                result_item_txt_link = result_item.find_element_by_id('addFlashPageParameterformat_fulltext')\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            if(result_item_txt_link is not None):\n",
    "                break\n",
    "#         print(f'recovered link {result_item_txt_link}')\n",
    "        if(result_item_txt_link is not None):\n",
    "            result_item_txt_link.click()\n",
    "            # wait to load\n",
    "            sleep(RESULT_LOAD_TIME)\n",
    "            ## get page content\n",
    "            # article id\n",
    "            article_ID_matcher = re.compile('(?<=fulltext/)[0-9A-Za-z]+(?=/)')\n",
    "            print(f'extracting ID from URL {driver.current_url}')\n",
    "            article_ID = article_ID_matcher.search(driver.current_url).group(0)\n",
    "            # article title\n",
    "            result_title = driver.find_element_by_id('documentTitle')\n",
    "            result_title_txt = result_title.text\n",
    "            # article authors\n",
    "            result_authors = driver.find_element_by_class_name('titleAuthorETC')\n",
    "            result_author_links = result_authors.find_elements_by_css_selector('a')\n",
    "            result_author_txt = list(map(lambda x: x.text, result_author_links))\n",
    "            # article text\n",
    "            result_text_zone = driver.find_element_by_id('fullTextZone')\n",
    "            result_text_paragraphs = result_text_zone.find_elements_by_css_selector('p')\n",
    "            result_paragraph_text = ' '.join(list(map(lambda x: x.text, result_text_paragraphs)))\n",
    "    ## combine, write to file\n",
    "    result_df = pd.DataFrame([article_ID, result_title_txt, result_author_txt, result_paragraph_text], index=['id', 'title', 'authors', 'text']).transpose()\n",
    "    return result_df\n",
    "#     out_dir = '../../data/NYT_scrape/'\n",
    "#     if(not os.path.exists(out_dir)):\n",
    "#         os.mkdir(out_dir)\n",
    "#     out_file = os.path.join(out_dir, f'{article_ID}_data.tsv')\n",
    "#     result_df.to_csv(out_file, sep='\\t', index=False)\n",
    "    # print(result_df)\n",
    "    # print(result_text_zone.find_elements_by('p'))\n",
    "from time import sleep\n",
    "def scrape_write_article(article_title, article_date, article_publisher, original_article_id, target_site, driver, out_dir):\n",
    "    \"\"\"\n",
    "    Scrape article data and write to file.\n",
    "    \"\"\"\n",
    "    result_data = scrape_article(article_title, article_date, article_publisher, target_site, driver)\n",
    "    out_file = os.path.join(out_dir, f'article_{original_article_id}.tsv')\n",
    "    result_data.to_csv(out_file, sep='\\t', index=False)\n",
    "import numpy as np\n",
    "def scrape_write_all_articles(article_data, article_publisher, target_site, driver, out_dir, SLEEP_TIME=15, verbose=True):\n",
    "    \"\"\"\n",
    "    Scrape and write all articles to file. Sleep between scrapes.\n",
    "    \"\"\"\n",
    "    rand_sleep_time_scale = SLEEP_TIME / 3.\n",
    "    # first thing: login\n",
    "    driver.get(target_site)\n",
    "    LOGIN_TIME=30\n",
    "    login_time_i = LOGIN_TIME + np.random.random() * (LOGIN_TIME / 10)\n",
    "    time.sleep(login_time_i)\n",
    "    for i, (idx_i, data_i) in enumerate(article_data.iterrows()):\n",
    "        article_title_i = data_i.loc['title']\n",
    "        article_date_i = data_i.loc['date']\n",
    "        article_id_i = data_i.loc['articleID']\n",
    "        if(verbose):\n",
    "            print(f'mining article {article_id_i}')\n",
    "        out_file = os.path.join(out_dir, f'article_{article_id_i}.tsv')\n",
    "        if(not os.path.exists(out_file)):\n",
    "            scrape_write_article(article_title_i, article_date_i, article_publisher, \n",
    "                                 article_id_i, target_site, driver, out_dir)\n",
    "            sleep_time_i = SLEEP_TIME + np.random.random() * (rand_sleep_time_scale)\n",
    "            sleep(sleep_time_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1214 articles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>title</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>date_time</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>April 24 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
       "      <td>2018-04-24 17:11:21</td>\n",
       "      <td>2018-04-24 17:11:21</td>\n",
       "      <td>April 24 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5adf4626068401528a2aa628</td>\n",
       "      <td>The New Noma, Explained</td>\n",
       "      <td>2018-04-24 14:58:44</td>\n",
       "      <td>2018-04-24 14:58:44</td>\n",
       "      <td>April 24 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5adf2108068401528a2aa5b3</td>\n",
       "      <td>How a Bag of Texas Dirt  Became a Times Tradition</td>\n",
       "      <td>2018-04-24 12:20:21</td>\n",
       "      <td>2018-04-24 12:20:21</td>\n",
       "      <td>April 24 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5adedaa8068401528a2aa4e6</td>\n",
       "      <td>Is School a Place for Self-Expression?</td>\n",
       "      <td>2018-04-24 11:21:04</td>\n",
       "      <td>2018-04-24 11:21:04</td>\n",
       "      <td>April 24 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID  \\\n",
       "0  5adf6684068401528a2aa69b   \n",
       "1  5adf653f068401528a2aa697   \n",
       "2  5adf4626068401528a2aa628   \n",
       "8  5adf2108068401528a2aa5b3   \n",
       "9  5adedaa8068401528a2aa4e6   \n",
       "\n",
       "                                               title              pubDate  \\\n",
       "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...  2018-04-24 17:16:49   \n",
       "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...  2018-04-24 17:11:21   \n",
       "2                            The New Noma, Explained  2018-04-24 14:58:44   \n",
       "8  How a Bag of Texas Dirt  Became a Times Tradition  2018-04-24 12:20:21   \n",
       "9             Is School a Place for Self-Expression?  2018-04-24 11:21:04   \n",
       "\n",
       "            date_time           date  \n",
       "0 2018-04-24 17:16:49  April 24 2018  \n",
       "1 2018-04-24 17:11:21  April 24 2018  \n",
       "2 2018-04-24 14:58:44  April 24 2018  \n",
       "8 2018-04-24 12:20:21  April 24 2018  \n",
       "9 2018-04-24 11:21:04  April 24 2018  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load comment data\n",
    "import pandas as pd\n",
    "# comment_data = pd.read_csv('../../data/nyt_comments/CommentsApril2018.csv', sep=',', index_col=False, usecols=['articleID', ''])\n",
    "article_data = pd.read_csv('../../data/nyt_comments/ArticlesApril2018.csv', sep=',', index_col=False, usecols=['articleID', 'headline', 'pubDate'])\n",
    "article_data.rename(columns={'headline' : 'title'}, inplace=True)\n",
    "article_data = article_data[article_data.loc[:, 'title'] != 'Unknown']\n",
    "print('%d articles'%(article_data.shape[0]))\n",
    "# simplify date\n",
    "from datetime import datetime\n",
    "date_fmt = '%Y-%m-%d %H:%M:%S'\n",
    "article_data = article_data.assign(**{\n",
    "    'date_time' : article_data.loc[:, 'pubDate'].apply(lambda x: datetime.strptime(x, date_fmt))\n",
    "})\n",
    "clean_date_fmt = '%B %d %Y'\n",
    "article_data = article_data.assign(**{\n",
    "    'date' : article_data.loc[:, 'date_time'].apply(lambda x: datetime.strftime(x, clean_date_fmt))\n",
    "})\n",
    "# get sample to mine\n",
    "sample_size = 250\n",
    "sample_article_data = article_data.head(sample_size)\n",
    "display(sample_article_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mining article 5adf6684068401528a2aa69b\n",
      "mining article 5adf653f068401528a2aa697\n",
      "mining article 5adf4626068401528a2aa628\n",
      "mining article 5adf2108068401528a2aa5b3\n",
      "mining article 5adedaa8068401528a2aa4e6\n",
      "mining article 5adf0063068401528a2aa552\n",
      "mining article 5adef237068401528a2aa532\n",
      "mining article 5adef237068401528a2aa531\n",
      "mining article 5adef230068401528a2aa527\n",
      "mining article 5adef233068401528a2aa52c\n",
      "mining article 5adef22f068401528a2aa525\n",
      "mining article 5adef226068401528a2aa51f\n",
      "mining article 5adef221068401528a2aa517\n",
      "mining article 5adef221068401528a2aa516\n",
      "mining article 5adef218068401528a2aa514\n",
      "mining article 5aded6a7068401528a2aa4e0\n",
      "mining article 5adec85b068401528a2aa4c1\n",
      "mining article 5adeae5b068401528a2aa48c\n",
      "mining article 5adea843068401528a2aa47a\n",
      "mining article 5ade8fa4068401528a2aa465\n",
      "mining article 5ade8c22068401528a2aa460\n",
      "mining article 5ade8a5b068401528a2aa45d\n",
      "mining article 5ade7af0068401528a2aa44b\n",
      "mining article 5ade7940068401528a2aa448\n",
      "mining article 5ade7448068401528a2aa443\n",
      "mining article 5ade70ca068401528a2aa43f\n",
      "mining article 5ade6ca1068401528a2aa43a\n",
      "mining article 5ade6193068401528a2aa41e\n",
      "mining article 5ade5afd068401528a2aa40f\n",
      "mining article 5ade5764068401528a2aa406\n",
      "mining article 5ade43f3068401528a2aa3d6\n",
      "mining article 5ade33d3068401528a2aa3b1\n",
      "mining article 5ade301d068401528a2aa3a7\n",
      "mining article 5ade2db2068401528a2aa3a3\n",
      "mining article 5ade2860068401528a2aa38f\n",
      "mining article 5ade1cb8068401528a2aa371\n",
      "mining article 5ade101e068401528a2aa344\n",
      "mining article 5ade05c2068401528a2aa32c\n",
      "mining article 5ade0309068401528a2aa322\n",
      "mining article 5ade0308068401528a2aa320\n",
      "mining article 5addfc74068401528a2aa317\n",
      "mining article 5addf0dc068401528a2aa2f0\n",
      "mining article 5adde6e8068401528a2aa2cb\n",
      "mining article 5addd18c068401528a2aa292\n",
      "mining article 5addaea7068401528a2aa23a\n",
      "mining article 5addaea4068401528a2aa239\n",
      "mining article 5addaeb3068401528a2aa23b\n",
      "mining article 5addab21068401528a2aa22f\n",
      "mining article 5addab22068401528a2aa230\n",
      "mining article 5adda79b068401528a2aa22b\n",
      "mining article 5adda09c068401528a2aa217\n",
      "mining article 5adda09b068401528a2aa215\n",
      "mining article 5adda099068401528a2aa214\n",
      "mining article 5adda094068401528a2aa211\n",
      "mining article 5adda093068401528a2aa210\n",
      "mining article 5add91e9068401528a2aa1ee\n",
      "mining article 5add8477068401528a2aa1d6\n",
      "mining article 5add8477068401528a2aa1d5\n",
      "mining article 5add8224068401528a2aa1d1\n",
      "mining article 5add76db068401528a2aa1b6\n",
      "mining article 5add56c8068401528a2aa181\n",
      "mining article 5add510f068401528a2aa17d\n",
      "mining article 5add4c34068401528a2aa178\n",
      "mining article 5add41aa068401528a2aa172\n",
      "mining article 5add3aa6068401528a2aa16b\n",
      "mining article 5add3aa5068401528a2aa16a\n",
      "mining article 5add2004068401528a2aa14b\n",
      "mining article 5add1d6d068401528a2aa149\n",
      "mining article 5add197f068401528a2aa147\n",
      "mining article 5add152e068401528a2aa141\n",
      "mining article 5add13c7068401528a2aa13d\n",
      "mining article 5add1387068401528a2aa13b\n",
      "mining article 5add08b6068401528a2aa12d\n",
      "mining article 5add05e5068401528a2aa128\n",
      "mining article 5add05e5068401528a2aa129\n",
      "mining article 5adcec5a068401528a2aa10d\n",
      "mining article 5adcdb2e068401528a2aa0f6\n",
      "mining article 5adcc006068401528a2aa0c2\n",
      "mining article 5adcb974068401528a2aa0b6\n",
      "mining article 5adcaffc068401528a2aa0ad\n",
      "mining article 5adc24eb068401528a2aa01d\n",
      "mining article 5adbd7d3068401528a2a9fd0\n",
      "mining article 5adb9370068401528a2a9f8c\n",
      "mining article 5adb8334068401528a2a9f74\n",
      "mining article 5adb8331068401528a2a9f70\n",
      "mining article 5adb8330068401528a2a9f6f\n",
      "mining article 5adb8330068401528a2a9f6d\n",
      "mining article 5adb8330068401528a2a9f6e\n",
      "mining article 5adb832f068401528a2a9f6c\n",
      "mining article 5adb832c068401528a2a9f6b\n",
      "mining article 5adb6007068401528a2a9f44\n",
      "mining article 5adb5fe8068401528a2a9f43\n",
      "mining article 5adb5363068401528a2a9f2f\n",
      "mining article 5adb535d068401528a2a9f2e\n",
      "mining article 5adb43e9068401528a2a9f19\n",
      "mining article 5ada9b24068401528a2a9e88\n",
      "mining article 5ada9064068401528a2a9e80\n",
      "mining article 5ada8fda068401528a2a9e7f\n",
      "mining article 5ada8875068401528a2a9e7c\n",
      "mining article 5ada7dfc068401528a2a9e6c\n",
      "mining article 5ada7cea068401528a2a9e6b\n",
      "mining article 5ada4fb1068401528a2a9e05\n",
      "mining article 5ada363c068401528a2a9dc8\n",
      "mining article 5ada2dc4068401528a2a9daf\n",
      "mining article 5ada228a068401528a2a9d91\n",
      "mining article 5ada1068068401528a2a9d57\n",
      "mining article 5ada0b32068401528a2a9d3d\n",
      "mining article 5ada0944068401528a2a9d2f\n",
      "mining article 5ada0827068401528a2a9d29\n",
      "mining article 5ad9f268068401528a2a9ceb\n",
      "mining article 5ad9efb1068401528a2a9ce1\n",
      "mining article 5ad9edcc068401528a2a9cd8\n",
      "mining article 5ad9e45c068401528a2a9cb9\n",
      "mining article 5ad9d182068401528a2a9c85\n",
      "mining article 5ad9ba24068401528a2a9c3b\n",
      "mining article 5ad9b881068401528a2a9c35\n",
      "mining article 5ad9b6a9068401528a2a9c31\n",
      "mining article 5ad9b6a2068401528a2a9c2f\n",
      "mining article 5ad9b32e068401528a2a9c25\n",
      "mining article 5ad9b0eb068401528a2a9c23\n",
      "mining article 5ad9ac98068401528a2a9c19\n",
      "mining article 5ad9ac27068401528a2a9c07\n",
      "mining article 5ad9ac20068401528a2a9c00\n",
      "mining article 5ad9ac1f068401528a2a9bff\n",
      "mining article 5ad9ac1b068401528a2a9bfc\n",
      "mining article 5ad9a7a4068401528a2a9bf0\n",
      "mining article 5ad9a2b2068401528a2a9bde\n",
      "mining article 5ad99ebd068401528a2a9bd7\n",
      "mining article 5ad990a8068401528a2a9bc3\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027462174/fulltext/97D07920AE9D4388PQ/1?accountid=14667\n",
      "mining article 5ad983c6068401528a2a9b9f\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027424248/fulltext/3120957199284A11PQ/1?accountid=14667\n",
      "mining article 5ad981e8068401528a2a9b98\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027445622/fulltext/E05720373A9543ACPQ/1?accountid=14667\n",
      "mining article 5ad973d8068401528a2a9b7a\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027423869/fulltext/3C08F25B835E4E6BPQ/1?accountid=14667\n",
      "mining article 5ad94d33068401528a2a9b43\n",
      "error Message: Unable to locate element: .resultItems\n",
      "\n",
      "mining article 5ad94cea068401528a2a9b41\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027445480/fulltext/92A55B00AE294893PQ/1?accountid=14667\n",
      "mining article 5ad94622068401528a2a9b33\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027445468/fulltext/59C47BF6AEEB4833PQ/1?accountid=14667\n",
      "mining article 5ad93673068401528a2a9b1c\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027445691/fulltext/8067C34EA2824FA1PQ/1?accountid=14667\n",
      "mining article 5ad92194068401528a2a9af9\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027748040/fulltext/83415332743E4343PQ/1?accountid=14667\n",
      "mining article 5ad91e7b068401528a2a9aee\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027748016/fulltext/6F76B33CF15E4A3FPQ/1?accountid=14667\n",
      "mining article 5ad9117e068401528a2a9acb\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027262581/fulltext/3E23610E3DA6488FPQ/1?accountid=14667\n",
      "mining article 5ad90ff0068401528a2a9ac6\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027445409/fulltext/DE3A89490B2D4A3CPQ/1?accountid=14667\n",
      "mining article 5ad90b81068401528a2a9ab9\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027445596/fulltext/8C57781037A4400CPQ/1?accountid=14667\n",
      "mining article 5ad90a1e068401528a2a9ab4\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2028092365/fulltext/1974B922BB3A49ABPQ/1?accountid=14667\n",
      "mining article 5ad90793068401528a2a9aae\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027261612/fulltext/7E8998D8A4854FD9PQ/1?accountid=14667\n",
      "mining article 5ad90285068401528a2a9a98\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027263656/fulltext/7F880AB0670D4F05PQ/1?accountid=14667\n",
      "mining article 5ad8fd8b068401528a2a9a86\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027446408/fulltext/8D04761212047DFPQ/1?accountid=14667\n",
      "mining article 5ad8fa2b068401528a2a9a77\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027446260/fulltext/51103A938DEB4644PQ/1?accountid=14667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mining article 5ad8f68d068401528a2a9a70\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027209740/fulltext/58573DF1FE544BCDPQ/1?accountid=14667\n",
      "mining article 5ad8eca6068401528a2a9a48\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027445515/fulltext/EBC13E49346348FAPQ/1?accountid=14667\n",
      "mining article 5ad8e64d068401528a2a9a33\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027209622/fulltext/7510B82706C44E98PQ/1?accountid=14667\n",
      "mining article 5ad8c968068401528a2a99ec\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027170102/fulltext/DC45B875132C42FBPQ/1?accountid=14667\n",
      "mining article 5ad8c1b9068401528a2a99c8\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027446117/fulltext/8CB9A7ECF9694A9APQ/1?accountid=14667\n",
      "mining article 5ad8bd5b068401528a2a99ba\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027121983/fulltext/D05D24C6682E4CEAPQ/1?accountid=14667\n",
      "mining article 5ad8b6a9068401528a2a99a6\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027121984/fulltext/6315F90CDE214C5DPQ/1?accountid=14667\n",
      "mining article 5ad8b46c068401528a2a999c\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027445373/fulltext/33F4233AE9694BCCPQ/1?accountid=14667\n",
      "mining article 5ad8b369068401528a2a9994\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027122021/fulltext/384743306CEE4F91PQ/1?accountid=14667\n",
      "mining article 5ad8a0ec068401528a2a9948\n",
      "error Message: Unable to locate element: .resultItems\n",
      "\n",
      "mining article 5ad899dd068401528a2a992f\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027036319/fulltext/A7D00E182B094833PQ/1?accountid=14667\n",
      "mining article 5ad89906068401528a2a992d\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027446522/fulltext/AC74DD61104C4433PQ/1?accountid=14667\n",
      "mining article 5ad894e8068401528a2a9921\n",
      "error Message: Unable to locate element: .resultItems\n",
      "\n",
      "mining article 5ad87d23068401528a2a98d6\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027445387/fulltext/CB52AFE0E2464860PQ/1?accountid=14667\n",
      "mining article 5ad87c67068401528a2a98d2\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2026950924/fulltext/B2F4579C7AC84C98PQ/1?accountid=14667\n",
      "mining article 5ad87bd5068401528a2a98cf\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2026950896/fulltext/8F68198738D24B9EPQ/1?accountid=14667\n",
      "mining article 5ad87bb9068401528a2a98ce\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2026950947/fulltext/4530C605DCA84D2APQ/1?accountid=14667\n",
      "mining article 5ad868a7068401528a2a9894\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027446424/fulltext/963EDCFA6AF40ABPQ/1?accountid=14667\n",
      "mining article 5ad868a5068401528a2a9892\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2026880157/fulltext/D4AE50B74966483DPQ/1?accountid=14667\n",
      "mining article 5ad86523068401528a2a9889\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2026878378/fulltext/6838A2BC7D9C47D1PQ/1?accountid=14667\n",
      "mining article 5ad85aa1068401528a2a9874\n",
      "error Message: Unable to locate element: .resultItems\n",
      "\n",
      "mining article 5ad85aa0068401528a2a9872\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2026879289/fulltext/EA95E8309C4646A2PQ/1?accountid=14667\n",
      "mining article 5ad85a9d068401528a2a986c\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027446099/fulltext/50A42CA93A6E4578PQ/1?accountid=14667\n",
      "mining article 5ad85a9e068401528a2a986d\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027445388/fulltext/E5A1BEDD45204EC5PQ/1?accountid=14667\n",
      "mining article 5ad85a9d068401528a2a986a\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2026879220/fulltext/B6EBB055E1FF4C15PQ/1?accountid=14667\n",
      "mining article 5ad85a9c068401528a2a9869\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2026880040/fulltext/3F4C7BE9563542A2PQ/1?accountid=14667\n",
      "mining article 5ad85a9e068401528a2a986e\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2027376830/fulltext/5D30642522F045FFPQ/1?accountid=14667\n",
      "mining article 5ad8354a068401528a2a9825\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2026822757/fulltext/9CBE327D70C64783PQ/1?accountid=14667\n",
      "mining article 5ad3e696068401528a2a8d4b\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2025384707/fulltext/238E267D64FD425APQ/1?accountid=14667\n",
      "mining article 5ad3e37c068401528a2a8d47\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2025246799/fulltext/B9F5BEF2D90F41B4PQ/1?accountid=14667\n",
      "mining article 5ad3d97a068401528a2a8d41\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2025246923/fulltext/CE2C7EF0F3044D2EPQ/1?accountid=14667\n",
      "mining article 5ad3cb6a068401528a2a8d31\n",
      "extracting ID from URL https://search-proquest-com.proxy.lib.umich.edu/docview/2025024112/fulltext/B475F607AA2A4466PQ/1?accountid=14667\n"
     ]
    }
   ],
   "source": [
    "target_site = 'https://search-proquest-com.proxy.lib.umich.edu/advanced?accountid=14667'\n",
    "article_publisher = 'new york times'\n",
    "from selenium.webdriver import Firefox\n",
    "driver = Firefox()\n",
    "out_dir = '../../data/NYT_scrape/'\n",
    "# driver.get(target_site)\n",
    "scrape_write_all_articles(sample_article_data, article_publisher, target_site, driver, out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of the sample articles were we able to recover? This will give us an (imperfect) estimate of the overall coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/105 valid articles\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "out_dir = '../../data/NYT_scrape/'\n",
    "article_text_files = list(map(lambda x: os.path.join(out_dir, x), os.listdir(out_dir)))\n",
    "article_text_data = pd.concat(list(map(lambda x: pd.read_csv(x, sep='\\t', index_col=False), article_text_files)), axis=0)\n",
    "valid_article_text_data = article_text_data[~article_text_data.loc[:, 'id'].apply(lambda x: type(x) is not str and np.isnan(x))]\n",
    "print(f'{valid_article_text_data.shape[0]}/{article_text_data.shape[0]} valid articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! So we get ~85% recall which is impressive considering that headlines change so often in news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test question overlap\n",
    "For the articles whose text we recovered: how much overlap do we see between author questions and the article text?\n",
    "\n",
    "This will help us determine how much information different audiences request/reference about the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3] *",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
